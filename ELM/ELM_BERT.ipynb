{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: prettytable in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (1.0.1)\n",
      "Requirement already satisfied: wcwidth in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from prettytable) (0.1.7)\n",
      "Requirement already satisfied: setuptools in /mnt/disks/user/anaconda3/lib/python3.6/site-packages (from prettytable) (39.1.0)\n",
      "\u001b[33mYou are using pip version 18.0, however version 20.2.4 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import prettytable\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, hamming_loss\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READING THE BERT EMBEDDINGS AND Y MATRIX\n",
    "bert_embedding=np.load(\"embeddings.npz\")\n",
    "label_values=np.load(\"Y.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "type1_BERT_Embeddings=bert_embedding[\"t1\"]\n",
    "type2_BERT_Embeddings=bert_embedding[\"t2\"]\n",
    "label_values=label_values[\"arr_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_train_x, t1_test_x, t1_train_y, t1_test_y = train_test_split(type1_BERT_Embeddings, label_values, test_size=0.33, random_state=234)\n",
    "t2_train_x, t2_test_x, t2_train_y, t2_test_y = train_test_split(type2_BERT_Embeddings, label_values, test_size=0.33, random_state=230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape t1_train_x:  [[-0.36826527 -0.43821245 -0.15154007 ... -0.21317424  0.6740728\n",
      "  -0.89827394]\n",
      " [-0.25526345 -1.0361675   0.31187654 ... -0.41380176  0.23752367\n",
      "  -1.4694043 ]\n",
      " [-0.30190113 -0.6179864  -0.08102065 ...  0.07218534  0.40399817\n",
      "  -0.5914986 ]\n",
      " ...\n",
      " [-0.00596368 -0.52669936  0.2841632  ... -0.18374442  0.55380374\n",
      "  -0.50675297]\n",
      " [-0.48843777 -0.7013829  -0.20389749 ...  0.05295624  0.48787463\n",
      "  -0.24249634]\n",
      " [-0.4864386  -0.4691094  -0.20912297 ... -0.0936537   0.39957207\n",
      "  -0.4435219 ]]\n",
      "Shape t1_test_x:  [[-0.26130378 -0.69637364  0.16091792 ... -0.04362152  0.17829853\n",
      "  -0.9757811 ]\n",
      " [ 0.06757689 -0.1472328   0.07639776 ...  0.09480745  0.31186146\n",
      "  -1.1533178 ]\n",
      " [ 0.19800258 -0.887366    0.35757995 ... -0.4777546   0.3292356\n",
      "  -0.32011172]\n",
      " ...\n",
      " [-0.1094763  -0.43274575  0.5285199  ... -0.2149579   0.23089571\n",
      "  -0.5284223 ]\n",
      " [-0.14528538 -0.18008953  0.5997345  ... -0.39525276 -0.03062117\n",
      "  -0.47663215]\n",
      " [-0.46414566 -0.2350843  -0.38872486 ... -0.07529384  0.20886713\n",
      "  -0.28005672]]\n",
      "Shape t1_train_y:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Shape t1_test_y:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 1 0 0]\n",
      " ...\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Shape t2_train_x:  [[-0.12113115 -0.4721356   0.32802156 ... -0.01129055  0.22955656\n",
      "  -0.43235385]\n",
      " [-0.37490067 -0.10924493  0.20562199 ... -0.15478972  0.8272832\n",
      "   0.03282541]\n",
      " [-0.6756584  -0.37155265  0.37979376 ... -0.21698126  0.25919294\n",
      "  -0.07541876]\n",
      " ...\n",
      " [-0.65533835 -0.02729864  0.9285103  ... -0.532351    0.2994408\n",
      "  -0.3371567 ]\n",
      " [-0.14980441 -0.4930426   0.31083623 ... -0.00909521  0.16175531\n",
      "  -1.0065575 ]\n",
      " [ 0.20077105 -0.5476451   0.1454247  ... -0.27448085  0.25988725\n",
      "  -0.9119779 ]]\n",
      "Shape t2_test_x:  [[-0.71968806 -0.36738312  0.3997091  ... -0.64548594  0.51239526\n",
      "   0.0188057 ]\n",
      " [-0.5111096  -0.44507238  0.67590475 ... -0.35881698  0.42847353\n",
      "  -0.6184632 ]\n",
      " [-0.32719004 -0.38634512  0.51854366 ... -0.347214    0.64176226\n",
      "  -0.4653134 ]\n",
      " ...\n",
      " [ 0.08885844 -0.3623479   0.3193009  ... -0.07060965  0.15481278\n",
      "  -0.6156052 ]\n",
      " [-0.51937264 -0.4332677   0.4960333  ... -0.7791502   0.08809341\n",
      "  -0.24398422]\n",
      " [-0.32892975 -0.46162462  0.51651114 ... -0.3790055   0.54254913\n",
      "  -0.43450084]]\n",
      "Shape t2_train_y:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "Shape t2_test_y:  [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape t1_train_x: \", t1_train_x)\n",
    "print(\"Shape t1_test_x: \", t1_test_x)\n",
    "print(\"Shape t1_train_y: \", t1_train_y)\n",
    "print(\"Shape t1_test_y: \", t1_test_y)\n",
    "print(\"Shape t2_train_x: \", t2_train_x)\n",
    "print(\"Shape t2_test_x: \", t2_test_x)\n",
    "print(\"Shape t2_train_y: \", t2_train_y)\n",
    "print(\"Shape t2_test_y: \", t2_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Activation Functions\n",
    "\n",
    "# def _identity(x):\n",
    "#     return x\n",
    "# def _binary_step(x, threshold = 0):\n",
    "#     return 1 if x=threshold else 0\n",
    "# def _biploar_step(x ,threshold = 0):\n",
    "#     return 1 if x>=threshold else -1\n",
    "# def _binary_sigmoid(x):\n",
    "#     return 1. / (1. + np.exp(-x))\n",
    "# def _bipolar_sigmoid(x):\n",
    "#     return (1. - np.exp(-x))/(1. + np.exp(-x))\n",
    "# def _relu_function(x):\n",
    "#     return np.max(0, x)\n",
    "# def _relu_leaky(x):\n",
    "#     return np.max(0.01*x, x)\n",
    "\n",
    "\n",
    "_identity =np.vectorize(lambda x: x)\n",
    "_binary_step =np.vectorize(lambda x,t=0: 1 if x>t else 0)\n",
    "_biploar_step =np.vectorize(lambda x,t=0: 1 if x>t else -1)\n",
    "_binary_sigmoid=np.vectorize(lambda x: 1. / (1. + np.exp(-x)))\n",
    "_bipolar_sigmoid=np.vectorize(lambda x: (1. - np.exp(-x))/(1. + np.exp(-x)))\n",
    "_relu_function=np.vectorize(lambda x: np.max([0, x]))\n",
    "_relu_leaky=np.vectorize(lambda x: np.max([0.01*x, x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ELM_MultiLabel:\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, activation=\"_identity\", bias=True, random_gen=\"uniform\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_nodes ([integer]): Number of Input nodes\n",
    "            hidden_nodes ([integer]): Number of hidden nodes\n",
    "            output_nodes ([integer]): Number of output nodes\n",
    "            activation ([function]): The function name which will be used as the activation function in the hidden layer. Defaults to \"_identity\".\n",
    "                possible values: _binary_step, _biploar_step, _binary_sigmoid, _bipolar_sigmoid, _relu_function, _relu_leaky, _identity\n",
    "            bias ([boolean]): Flag to use bias, if True then randomly generate bias @random_gen else bias - 0.\n",
    "            random_gen (str, optional): The type way in which random weight are generated. Defaults to \"uniform\".\n",
    "        \"\"\"\n",
    "        self.__input_nodes = input_nodes\n",
    "        self.__hidden_nodes = hidden_nodes\n",
    "        self.__output_nodes = output_nodes\n",
    "\n",
    "        if random_gen == \"uniform\":\n",
    "            self.__beta = np.random.uniform(-1.,1.,size = (self.__hidden_nodes, self.__output_nodes))\n",
    "            self.__alpha = np.random.uniform(-1.,1.,size = (self.__input_nodes, self.__hidden_nodes))\n",
    "            self.__bias = np.random.uniform(size = (self.__hidden_nodes,))\n",
    "        else:\n",
    "            self.__beta = np.random.normal(-1.,1.,size=(self.__hidden_nodes, self.__output_nodes))\n",
    "            self.__alpha = np.random.normal(-1.,1.,size=(self.__input_nodes, self.__hidden_nodes))\n",
    "            self.__bias = np.random.normal(size=(self.__n_hidden_nodes,))\n",
    "        \n",
    "\n",
    "        if activation == \"_biploar_step\":\n",
    "            self.__activation = _biploar_step\n",
    "            print(\"SELECTED _biploar_step\")\n",
    "        elif activation == \"_bipolar_sigmoid\":\n",
    "            self.__activation = _bipolar_sigmoid\n",
    "            print(\"SELECTED _bipolar_sigmoid\")\n",
    "\n",
    "        elif activation == \"_relu_leaky\":\n",
    "            self.__activation =_relu_leaky\n",
    "            print(\"SELECTED _relu_leaky\")\n",
    "\n",
    "        elif activation == \"_binary_step\":\n",
    "            self.__activation =_binary_step\n",
    "            print(\"SELECTED _binary_step\")\n",
    "\n",
    "        elif activation == \"_binary_sigmoid\":\n",
    "            self.__activation =_binary_sigmoid\n",
    "            print(\"SELECTED _binary_sigmoid\")            \n",
    "        elif activation == \"_relu_function\":\n",
    "            self.__activation =_relu_function\n",
    "            print(\"SELECTED _relu_function\")\n",
    "        else:\n",
    "            self.__activation =_identity\n",
    "            print(\"SELECTED _identity\")\n",
    "    \n",
    "\n",
    "    def getInputNodes(self):\n",
    "        return  self.__input_nodes\n",
    "\n",
    "    def getHiddenNodes(self):\n",
    "        return  self.__hidden_nodes\n",
    "\n",
    "    def getOutputNodes(self):\n",
    "        return  self.__output_nodes\n",
    "    \n",
    "    def getBetaWeights(self):\n",
    "        return self.__beta\n",
    "    \n",
    "    def getAlphaWeight(self):\n",
    "        return self.__alphs\n",
    "    \n",
    "    def getBias(self):\n",
    "        return self.__bias\n",
    "\n",
    "    def __get_H_matrix(self, train_x, verbose=False):\n",
    "        # 1 Propagate data from Input to hidden Layer\n",
    "        if verbose:\n",
    "            print(\"Propagate data from Input to hidden Layer\")\n",
    "        inp = np.dot(train_x , self.__alpha)\n",
    "        if verbose:\n",
    "            print(inp)\n",
    "            print(\"Adding Biases\")\n",
    "        inp = inp  + self.__bias\n",
    "        if verbose:\n",
    "            print(inp)\n",
    "            print(\"Applyin activation function\")\n",
    "        inp_activation = np.apply_along_axis(self.__activation, 1, inp)\n",
    "        return inp_activation\n",
    "\n",
    "    def fit(self, train_x, train_y, verbose = False, show_metrics = True):\n",
    "        \"\"\"\n",
    "        This function calculates the Beta weights or the output weights\n",
    "        train_x : input matrix\n",
    "        train_y : output matrix to be predicted or learned upon unipolar\n",
    "\n",
    "        returns: if test_y is not given then\n",
    "                returns the predicted output\n",
    "                if test_y is given then returns predicted output and evaluation metrics dict \n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"train_x shape:\", train_x.shape)\n",
    "            print(\"train_y shape:\", train_y.shape)\n",
    "        inp_activation = self.__get_H_matrix(train_x, verbose)\n",
    "        # This is the H matrix getting its Moore Penrose Inverse\n",
    "        if verbose:\n",
    "            print(inp_activation)\n",
    "            print(\"Getting the Generalized Moore Penrose Inverse\")\n",
    "        generalizedInverse = np.linalg.pinv(inp_activation)\n",
    "        if verbose:\n",
    "            print(generalizedInverse)\n",
    "            print(\"Finding Beta, output weights\")\n",
    "        # Now find output weight matrix Beta \n",
    "        # convert input Y values according to the threshold using biploar step function\n",
    "        _bipolar_y=  np.apply_along_axis(_biploar_step, 1, train_y)\n",
    "        self.__beta = np.dot(generalizedInverse, _bipolar_y)\n",
    "        if verbose:\n",
    "            print(\"Beta Matrix Weights\")\n",
    "            print(self.__beta)\n",
    "\n",
    "        # print(\"Model Metrics, for Training :\")\n",
    "        return self.predict(train_x, train_y,verbose,show_metrics)\n",
    "    \n",
    "    def predict(self, test_x, test_y = None, verbose = False, show_metrics= True):\n",
    "        \"\"\"\n",
    "        preditcts the output for the input test data\n",
    "        call this after calling the fit.\n",
    "        test_data shape should be (batch_size,768 or input_nodes)\n",
    "        output_shape will be (batch_size, 71 or output_nodes)\n",
    "\n",
    "        returns: if test_y is not given then\n",
    "                returns the predicted output\n",
    "                if test_y is given then returns predicted output and evaluation metrics dict\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"Predicting outputs\")\n",
    "        inp_activation = self.__get_H_matrix(test_x, verbose)\n",
    "        output_predicted = np.dot(inp_activation, self.__beta)\n",
    "        # convert predicted according to the threshold using biploar step function\n",
    "        predicted_bipolar =  np.apply_along_axis(_biploar_step, 1, output_predicted)\n",
    "        predicted_binary = np.apply_along_axis(_binary_step, 1, predicted_bipolar)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"predicted output\")\n",
    "            print(output_predicted)\n",
    "            print(\"predicted_bipolar\")\n",
    "            print(predicted_bipolar)\n",
    "            print(\"predicted_binary\")\n",
    "            print(predicted_binary)\n",
    "            print(\"Original Binary\")\n",
    "            print(test_y)\n",
    "\n",
    "        eval_dict={}\n",
    "        if (test_y is not None):\n",
    "            eval_dict=self.__evaluate(test_y,predicted_binary, for_test=False)\n",
    "        if(test_y is not None):\n",
    "            return predicted_binary, eval_dict\n",
    "        else:\n",
    "            return predicted_binary\n",
    "\n",
    "    def __evaluate(self, real, predicted, for_test=True):\n",
    "        \"\"\"\n",
    "        real values as 0,1\n",
    "        predicted values as 0,1\n",
    "        \"\"\"\n",
    "        # Now we find accuracy, precision, recall, Hamming Loss and F1 Measure\n",
    "        accuracy = accuracy_score(real, predicted)\n",
    "        hamLoss = hamming_loss(real, predicted)\n",
    "        # element wise correctness\n",
    "        term_wise_accuracy=np.sum(np.logical_not(np.logical_xor(real, predicted)))/real.size\n",
    "\n",
    "        macro_precision = precision_score(real, predicted, average='macro')\n",
    "        macro_recall = recall_score(real, predicted, average='macro')\n",
    "        macro_f1 = f1_score(real, predicted, average='macro')\n",
    "\n",
    "        micro_precision = precision_score(real, predicted, average='micro')\n",
    "        micro_recall = recall_score(real, predicted, average='micro')\n",
    "        micro_f1 = f1_score(real, predicted, average='micro')\n",
    "        \n",
    "        metricTable=prettytable.PrettyTable()\n",
    "        metricTable.field_names = [\"Metric\", \"Macro Value\", \"Micro Value\"]\n",
    "        metricTable.add_row([\"Hamming Loss\",\"{0:.3f}\".format(hamLoss) ,\"\"])\n",
    "        metricTable.add_row([\"Term Wise Accuracy\",\"{0:.3f}\".format(term_wise_accuracy) ,\"\"])\n",
    "\n",
    "        metricTable.add_row([\"Accuracy\",\"{0:.3f}\".format(accuracy),\"\"])\n",
    "        metricTable.add_row([\"Precision\",\"{0:.3f}\".format(macro_precision),\"{0:.3f}\".format(micro_precision)])\n",
    "        metricTable.add_row([\"Recall\",\"{0:.3f}\".format(macro_recall),\"{0:.3f}\".format(micro_recall)])\n",
    "        metricTable.add_row([\"F1-measure\",\"{0:.3f}\".format(macro_f1),\"{0:.3f}\".format(micro_f1)])\n",
    "\n",
    "        print(metricTable)\n",
    "\n",
    "        #\n",
    "        # print(\"Metrics @ Literature\")\n",
    "        lit_accuracy, lit_precision, lit_recall, lit_f1 = self.get_eval_metrics(real,predicted)\n",
    "\n",
    "        return_dict = {\"HiddenNodes\": self.getHiddenNodes(),\n",
    "                \"lit_accuracy\": lit_accuracy,\n",
    "                \"lit_precision\": lit_precision,\n",
    "                \"lit_recall\": lit_recall,\n",
    "                \"lit_f1\": lit_f1,\n",
    "                \"sklearn_hamLoss\": hamLoss,\n",
    "                \"sklearn_accuracy\": accuracy,\n",
    "                \"term_wise_accuracy\": term_wise_accuracy,\n",
    "                \"sklearn_macro_precision\": macro_precision,\n",
    "                \"sklearn_micro_precision\": micro_precision,\n",
    "                \"sklearn_macro_recall\": macro_recall,\n",
    "                \"sklearn_micro_recall\": micro_recall,\n",
    "                \"sklearn_macro_f1\": macro_f1,\n",
    "                \"sklearn_micro_f1\": micro_f1,\n",
    "                }\n",
    "\n",
    "        return return_dict\n",
    "\n",
    "    def get_eval_metrics(self, real, predicted, verbose= False):\n",
    "        err_cnt_accuracy=0\n",
    "        err_cnt_precision=0\n",
    "        err_cnt_recall=0\n",
    "        if verbose:\n",
    "            print(real)\n",
    "            print(predicted)\n",
    "        for x in range(real.shape[0]):\n",
    "            err_and= np.logical_and(real[x],predicted[x])\n",
    "            err_or = np.logical_or(real[x],predicted[x])\n",
    "            # Accuracy\n",
    "            err_cnt_accuracy +=(sum(err_and)/sum(err_or))\n",
    "\n",
    "            # Precision\n",
    "            if sum(err_and) != 0:\n",
    "                err_cnt_precision += (sum(err_and) / sum(predicted[x]))\n",
    "            # Recall\n",
    "            err_cnt_recall += (sum(err_and) / sum(real[x]))\n",
    "            if verbose:\n",
    "                print(\"Iteration :\",x)\n",
    "                print((sum(err_and)/sum(err_or)))\n",
    "                print(err_and)\n",
    "                print(err_or)\n",
    "        \n",
    "        # err_count_hamming = np.zeros((real.shape))\n",
    "\n",
    "        # for i in range(real.shape[0]):\n",
    "        #     for j in range(real.shape[1]):\n",
    "        #         if real[i,j] != predicted[i,j]:\n",
    "        #             err_count_hamming[1,j] = err_count_hamming[1,j]+1\n",
    "\n",
    "        # sum_err = np.sum(err_count_hamming);\n",
    "        # HammingLoss = sum_err/real.size;\n",
    "        accuracy = err_cnt_accuracy / real.shape[0]\n",
    "        precision = err_cnt_precision / real.shape[0]\n",
    "        recall = err_cnt_recall / real.shape[0]\n",
    "        f1 = 2*((precision*recall)/(precision+recall))\n",
    "        if verbose:\n",
    "            print(\"Final: \")\n",
    "            # print(\"Hamming Loss: \", HammingLoss)\n",
    "            print(\"Accuracy: \",accuracy)\n",
    "            print(\"precision: \",precision)\n",
    "            print(\"recall: \",recall)\n",
    "            print(\"f1: \",f1)\n",
    "\n",
    "        # metricTable=prettytable.PrettyTable()\n",
    "        # metricTable.field_names = [\"Metric\", \"Value\"]\n",
    "        # metricTable.add_row([\" Literature Hamming Loss\",\"{0:.3f}\".format(HammingLoss)])\n",
    "        # metricTable.add_row([\"Literature Accuracy\",\"{0:.3f}\".format(accuracy)])\n",
    "\n",
    "        # metricTable.add_row([\"Literature Precision\",\"{0:.3f}\".format(precision)])\n",
    "        # metricTable.add_row([\"LiteratureRecall\",\"{0:.3f}\".format(recall)])\n",
    "        # metricTable.add_row([\"LiteratureF1-measure\",\"{0:.3f}\".format(f1)])\n",
    "\n",
    "        # # print(metricTable)\n",
    "\n",
    "        return accuracy,precision,recall,f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now The preprocessing and is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now We will run the model for all the three types data sets we have viz.\n",
    "- TRAIN X\n",
    "  - t1_train_x\n",
    "  - t2_train_x\n",
    "- TEST X\n",
    "  - t1_test_x\n",
    "  - t2_test_x\n",
    "- TRAIN Y\n",
    "  - t1_train_y\n",
    "  - t2_train_y\n",
    "- TEST Y\n",
    "  - t1_test_y\n",
    "  - t2_test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_models_hidden_nodes=[100,200, 300, 400, 500, 1000, 2000, 3000, 4000, 5000, 10000, 15000]#, 20000]\n",
    "\n",
    "INPUT_NODES= 768\n",
    "OUTPUT_NODES= 71\n",
    "activations= [\"_identity\",\"_biploar_step\",\"_bipolar_sigmoid\",\"_relu_leaky\",\"_binary_sigmoid\"]\n",
    "# activations= [\"_identity\"]\n",
    "\n",
    "randomizations =\"uniform\"\n",
    "datasets ={\"t1_bert\":(t1_train_x,t1_train_y,t1_test_x,t1_test_y),\"t2_bert\":(t2_train_x,t2_train_y,t2_test_x,t2_test_y)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict_list=[]\n",
    "\n",
    "def add_data_to_metric_list(eval_dict, activation, type, start, phase, end, metrics_dict_list=metrics_dict_list):\n",
    "    eval_dict[\"activation\"]=activation\n",
    "    eval_dict[\"type\"]=type\n",
    "    eval_dict[\"phase\"]=phase\n",
    "    eval_dict[\"total_time\"]=end-start\n",
    "\n",
    "    metrics_dict_list.append(eval_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the above function with a simple 50 hidden layer node model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to store the models\n",
    "model_dict={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAINING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1_bert_100__identity_uniform\n",
      "SELECTED _identity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/mnt/disks/user/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.040    |             |\n",
      "| Term Wise Accuracy |    0.960    |             |\n",
      "|      Accuracy      |    0.044    |             |\n",
      "|     Precision      |    0.056    |    0.623    |\n",
      "|       Recall       |    0.012    |    0.092    |\n",
      "|     F1-measure     |    0.015    |    0.160    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_100__biploar_step_uniform\n",
      "SELECTED _biploar_step\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.041    |             |\n",
      "| Term Wise Accuracy |    0.959    |             |\n",
      "|      Accuracy      |    0.031    |             |\n",
      "|     Precision      |    0.079    |    0.604    |\n",
      "|       Recall       |    0.009    |    0.072    |\n",
      "|     F1-measure     |    0.013    |    0.129    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_100__bipolar_sigmoid_uniform\n",
      "SELECTED _bipolar_sigmoid\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.041    |             |\n",
      "| Term Wise Accuracy |    0.959    |             |\n",
      "|      Accuracy      |    0.039    |             |\n",
      "|     Precision      |    0.135    |    0.613    |\n",
      "|       Recall       |    0.011    |    0.084    |\n",
      "|     F1-measure     |    0.015    |    0.148    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_100__relu_leaky_uniform\n",
      "SELECTED _relu_leaky\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.040    |             |\n",
      "| Term Wise Accuracy |    0.960    |             |\n",
      "|      Accuracy      |    0.039    |             |\n",
      "|     Precision      |    0.047    |    0.621    |\n",
      "|       Recall       |    0.011    |    0.087    |\n",
      "|     F1-measure     |    0.014    |    0.152    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_100__binary_sigmoid_uniform\n",
      "SELECTED _binary_sigmoid\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.041    |             |\n",
      "| Term Wise Accuracy |    0.959    |             |\n",
      "|      Accuracy      |    0.034    |             |\n",
      "|     Precision      |    0.055    |    0.597    |\n",
      "|       Recall       |    0.009    |    0.077    |\n",
      "|     F1-measure     |    0.012    |    0.136    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_200__identity_uniform\n",
      "SELECTED _identity\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.040    |             |\n",
      "| Term Wise Accuracy |    0.960    |             |\n",
      "|      Accuracy      |    0.051    |             |\n",
      "|     Precision      |    0.080    |    0.639    |\n",
      "|       Recall       |    0.014    |    0.106    |\n",
      "|     F1-measure     |    0.018    |    0.182    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_200__biploar_step_uniform\n",
      "SELECTED _biploar_step\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.040    |             |\n",
      "| Term Wise Accuracy |    0.960    |             |\n",
      "|      Accuracy      |    0.042    |             |\n",
      "|     Precision      |    0.053    |    0.618    |\n",
      "|       Recall       |    0.011    |    0.088    |\n",
      "|     F1-measure     |    0.015    |    0.154    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_200__bipolar_sigmoid_uniform\n",
      "SELECTED _bipolar_sigmoid\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.040    |             |\n",
      "| Term Wise Accuracy |    0.960    |             |\n",
      "|      Accuracy      |    0.044    |             |\n",
      "|     Precision      |    0.077    |    0.622    |\n",
      "|       Recall       |    0.012    |    0.091    |\n",
      "|     F1-measure     |    0.017    |    0.159    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_200__relu_leaky_uniform\n",
      "SELECTED _relu_leaky\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.040    |             |\n",
      "| Term Wise Accuracy |    0.960    |             |\n",
      "|      Accuracy      |    0.050    |             |\n",
      "|     Precision      |    0.119    |    0.636    |\n",
      "|       Recall       |    0.013    |    0.101    |\n",
      "|     F1-measure     |    0.017    |    0.175    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_200__binary_sigmoid_uniform\n",
      "SELECTED _binary_sigmoid\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.040    |             |\n",
      "| Term Wise Accuracy |    0.960    |             |\n",
      "|      Accuracy      |    0.044    |             |\n",
      "|     Precision      |    0.080    |    0.623    |\n",
      "|       Recall       |    0.012    |    0.093    |\n",
      "|     F1-measure     |    0.015    |    0.162    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_300__identity_uniform\n",
      "SELECTED _identity\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.040    |             |\n",
      "| Term Wise Accuracy |    0.960    |             |\n",
      "|      Accuracy      |    0.059    |             |\n",
      "|     Precision      |    0.087    |    0.654    |\n",
      "|       Recall       |    0.015    |    0.113    |\n",
      "|     F1-measure     |    0.020    |    0.193    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_300__biploar_step_uniform\n",
      "SELECTED _biploar_step\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.040    |             |\n",
      "| Term Wise Accuracy |    0.960    |             |\n",
      "|      Accuracy      |    0.048    |             |\n",
      "|     Precision      |    0.150    |    0.636    |\n",
      "|       Recall       |    0.013    |    0.096    |\n",
      "|     F1-measure     |    0.017    |    0.167    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_300__bipolar_sigmoid_uniform\n",
      "SELECTED _bipolar_sigmoid\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.040    |             |\n",
      "| Term Wise Accuracy |    0.960    |             |\n",
      "|      Accuracy      |    0.054    |             |\n",
      "|     Precision      |    0.151    |    0.650    |\n",
      "|       Recall       |    0.014    |    0.106    |\n",
      "|     F1-measure     |    0.019    |    0.182    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_300__relu_leaky_uniform\n",
      "SELECTED _relu_leaky\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.040    |             |\n",
      "| Term Wise Accuracy |    0.960    |             |\n",
      "|      Accuracy      |    0.057    |             |\n",
      "|     Precision      |    0.174    |    0.657    |\n",
      "|       Recall       |    0.016    |    0.114    |\n",
      "|     F1-measure     |    0.021    |    0.194    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_300__binary_sigmoid_uniform\n",
      "SELECTED _binary_sigmoid\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.040    |             |\n",
      "| Term Wise Accuracy |    0.960    |             |\n",
      "|      Accuracy      |    0.050    |             |\n",
      "|     Precision      |    0.093    |    0.636    |\n",
      "|       Recall       |    0.014    |    0.105    |\n",
      "|     F1-measure     |    0.018    |    0.180    |\n",
      "+--------------------+-------------+-------------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1_bert_400__identity_uniform\n",
      "SELECTED _identity\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.039    |             |\n",
      "| Term Wise Accuracy |    0.961    |             |\n",
      "|      Accuracy      |    0.064    |             |\n",
      "|     Precision      |    0.088    |    0.664    |\n",
      "|       Recall       |    0.017    |    0.125    |\n",
      "|     F1-measure     |    0.023    |    0.210    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_400__biploar_step_uniform\n",
      "SELECTED _biploar_step\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.040    |             |\n",
      "| Term Wise Accuracy |    0.960    |             |\n",
      "|      Accuracy      |    0.050    |             |\n",
      "|     Precision      |    0.123    |    0.645    |\n",
      "|       Recall       |    0.014    |    0.105    |\n",
      "|     F1-measure     |    0.018    |    0.181    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_400__bipolar_sigmoid_uniform\n",
      "SELECTED _bipolar_sigmoid\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.040    |             |\n",
      "| Term Wise Accuracy |    0.960    |             |\n",
      "|      Accuracy      |    0.061    |             |\n",
      "|     Precision      |    0.376    |    0.651    |\n",
      "|       Recall       |    0.017    |    0.116    |\n",
      "|     F1-measure     |    0.024    |    0.197    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_400__relu_leaky_uniform\n",
      "SELECTED _relu_leaky\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.040    |             |\n",
      "| Term Wise Accuracy |    0.960    |             |\n",
      "|      Accuracy      |    0.060    |             |\n",
      "|     Precision      |    0.169    |    0.655    |\n",
      "|       Recall       |    0.016    |    0.118    |\n",
      "|     F1-measure     |    0.022    |    0.200    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_400__binary_sigmoid_uniform\n",
      "SELECTED _binary_sigmoid\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.040    |             |\n",
      "| Term Wise Accuracy |    0.960    |             |\n",
      "|      Accuracy      |    0.057    |             |\n",
      "|     Precision      |    0.178    |    0.654    |\n",
      "|       Recall       |    0.016    |    0.114    |\n",
      "|     F1-measure     |    0.021    |    0.195    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_500__identity_uniform\n",
      "SELECTED _identity\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.039    |             |\n",
      "| Term Wise Accuracy |    0.961    |             |\n",
      "|      Accuracy      |    0.068    |             |\n",
      "|     Precision      |    0.120    |    0.668    |\n",
      "|       Recall       |    0.019    |    0.130    |\n",
      "|     F1-measure     |    0.026    |    0.218    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_500__biploar_step_uniform\n",
      "SELECTED _biploar_step\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.040    |             |\n",
      "| Term Wise Accuracy |    0.960    |             |\n",
      "|      Accuracy      |    0.058    |             |\n",
      "|     Precision      |    0.219    |    0.653    |\n",
      "|       Recall       |    0.016    |    0.115    |\n",
      "|     F1-measure     |    0.022    |    0.196    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_500__bipolar_sigmoid_uniform\n",
      "SELECTED _bipolar_sigmoid\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.039    |             |\n",
      "| Term Wise Accuracy |    0.961    |             |\n",
      "|      Accuracy      |    0.060    |             |\n",
      "|     Precision      |    0.145    |    0.662    |\n",
      "|       Recall       |    0.017    |    0.121    |\n",
      "|     F1-measure     |    0.022    |    0.205    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_500__relu_leaky_uniform\n",
      "SELECTED _relu_leaky\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.039    |             |\n",
      "| Term Wise Accuracy |    0.961    |             |\n",
      "|      Accuracy      |    0.069    |             |\n",
      "|     Precision      |    0.287    |    0.666    |\n",
      "|       Recall       |    0.019    |    0.128    |\n",
      "|     F1-measure     |    0.027    |    0.215    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_500__binary_sigmoid_uniform\n",
      "SELECTED _binary_sigmoid\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.039    |             |\n",
      "| Term Wise Accuracy |    0.961    |             |\n",
      "|      Accuracy      |    0.065    |             |\n",
      "|     Precision      |    0.361    |    0.656    |\n",
      "|       Recall       |    0.018    |    0.122    |\n",
      "|     F1-measure     |    0.025    |    0.205    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_1000__identity_uniform\n",
      "SELECTED _identity\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.038    |             |\n",
      "| Term Wise Accuracy |    0.962    |             |\n",
      "|      Accuracy      |    0.081    |             |\n",
      "|     Precision      |    0.235    |    0.693    |\n",
      "|       Recall       |    0.024    |    0.152    |\n",
      "|     F1-measure     |    0.034    |    0.249    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_1000__biploar_step_uniform\n",
      "SELECTED _biploar_step\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.038    |             |\n",
      "| Term Wise Accuracy |    0.962    |             |\n",
      "|      Accuracy      |    0.077    |             |\n",
      "|     Precision      |    0.473    |    0.699    |\n",
      "|       Recall       |    0.026    |    0.152    |\n",
      "|     F1-measure     |    0.038    |    0.249    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_1000__bipolar_sigmoid_uniform\n",
      "SELECTED _bipolar_sigmoid\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.038    |             |\n",
      "| Term Wise Accuracy |    0.962    |             |\n",
      "|      Accuracy      |    0.082    |             |\n",
      "|     Precision      |    0.459    |    0.702    |\n",
      "|       Recall       |    0.028    |    0.159    |\n",
      "|     F1-measure     |    0.041    |    0.259    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_1000__relu_leaky_uniform\n",
      "SELECTED _relu_leaky\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.038    |             |\n",
      "| Term Wise Accuracy |    0.962    |             |\n",
      "|      Accuracy      |    0.088    |             |\n",
      "|     Precision      |    0.518    |    0.712    |\n",
      "|       Recall       |    0.031    |    0.168    |\n",
      "|     F1-measure     |    0.046    |    0.272    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_1000__binary_sigmoid_uniform\n",
      "SELECTED _binary_sigmoid\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.038    |             |\n",
      "| Term Wise Accuracy |    0.962    |             |\n",
      "|      Accuracy      |    0.081    |             |\n",
      "|     Precision      |    0.444    |    0.700    |\n",
      "|       Recall       |    0.028    |    0.159    |\n",
      "|     F1-measure     |    0.040    |    0.259    |\n",
      "+--------------------+-------------+-------------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1_bert_2000__identity_uniform\n",
      "SELECTED _identity\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.038    |             |\n",
      "| Term Wise Accuracy |    0.962    |             |\n",
      "|      Accuracy      |    0.081    |             |\n",
      "|     Precision      |    0.235    |    0.693    |\n",
      "|       Recall       |    0.024    |    0.152    |\n",
      "|     F1-measure     |    0.034    |    0.249    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_2000__biploar_step_uniform\n",
      "SELECTED _biploar_step\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.035    |             |\n",
      "| Term Wise Accuracy |    0.965    |             |\n",
      "|      Accuracy      |    0.126    |             |\n",
      "|     Precision      |    0.735    |    0.771    |\n",
      "|       Recall       |    0.062    |    0.245    |\n",
      "|     F1-measure     |    0.095    |    0.371    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_2000__bipolar_sigmoid_uniform\n",
      "SELECTED _bipolar_sigmoid\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.034    |             |\n",
      "| Term Wise Accuracy |    0.966    |             |\n",
      "|      Accuracy      |    0.129    |             |\n",
      "|     Precision      |    0.774    |    0.773    |\n",
      "|       Recall       |    0.070    |    0.255    |\n",
      "|     F1-measure     |    0.109    |    0.383    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_2000__relu_leaky_uniform\n",
      "SELECTED _relu_leaky\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.034    |             |\n",
      "| Term Wise Accuracy |    0.966    |             |\n",
      "|      Accuracy      |    0.133    |             |\n",
      "|     Precision      |    0.832    |    0.782    |\n",
      "|       Recall       |    0.080    |    0.261    |\n",
      "|     F1-measure     |    0.127    |    0.391    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_2000__binary_sigmoid_uniform\n",
      "SELECTED _binary_sigmoid\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.035    |             |\n",
      "| Term Wise Accuracy |    0.965    |             |\n",
      "|      Accuracy      |    0.126    |             |\n",
      "|     Precision      |    0.761    |    0.770    |\n",
      "|       Recall       |    0.069    |    0.250    |\n",
      "|     F1-measure     |    0.108    |    0.378    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_3000__identity_uniform\n",
      "SELECTED _identity\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.038    |             |\n",
      "| Term Wise Accuracy |    0.962    |             |\n",
      "|      Accuracy      |    0.081    |             |\n",
      "|     Precision      |    0.235    |    0.693    |\n",
      "|       Recall       |    0.024    |    0.152    |\n",
      "|     F1-measure     |    0.034    |    0.249    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_3000__biploar_step_uniform\n",
      "SELECTED _biploar_step\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.030    |             |\n",
      "| Term Wise Accuracy |    0.970    |             |\n",
      "|      Accuracy      |    0.181    |             |\n",
      "|     Precision      |    0.933    |    0.832    |\n",
      "|       Recall       |    0.143    |    0.358    |\n",
      "|     F1-measure     |    0.222    |    0.501    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_3000__bipolar_sigmoid_uniform\n",
      "SELECTED _bipolar_sigmoid\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.029    |             |\n",
      "| Term Wise Accuracy |    0.971    |             |\n",
      "|      Accuracy      |    0.192    |             |\n",
      "|     Precision      |    0.965    |    0.839    |\n",
      "|       Recall       |    0.157    |    0.369    |\n",
      "|     F1-measure     |    0.245    |    0.512    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_3000__relu_leaky_uniform\n",
      "SELECTED _relu_leaky\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.029    |             |\n",
      "| Term Wise Accuracy |    0.971    |             |\n",
      "|      Accuracy      |    0.206    |             |\n",
      "|     Precision      |    0.963    |    0.845    |\n",
      "|       Recall       |    0.186    |    0.386    |\n",
      "|     F1-measure     |    0.287    |    0.530    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_3000__binary_sigmoid_uniform\n",
      "SELECTED _binary_sigmoid\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.029    |             |\n",
      "| Term Wise Accuracy |    0.971    |             |\n",
      "|      Accuracy      |    0.191    |             |\n",
      "|     Precision      |    0.922    |    0.838    |\n",
      "|       Recall       |    0.149    |    0.367    |\n",
      "|     F1-measure     |    0.230    |    0.510    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_4000__identity_uniform\n",
      "SELECTED _identity\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.038    |             |\n",
      "| Term Wise Accuracy |    0.962    |             |\n",
      "|      Accuracy      |    0.081    |             |\n",
      "|     Precision      |    0.235    |    0.693    |\n",
      "|       Recall       |    0.024    |    0.152    |\n",
      "|     F1-measure     |    0.034    |    0.249    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_4000__biploar_step_uniform\n",
      "SELECTED _biploar_step\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.023    |             |\n",
      "| Term Wise Accuracy |    0.977    |             |\n",
      "|      Accuracy      |    0.280    |             |\n",
      "|     Precision      |    0.983    |    0.889    |\n",
      "|       Recall       |    0.321    |    0.515    |\n",
      "|     F1-measure     |    0.463    |    0.652    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_4000__bipolar_sigmoid_uniform\n",
      "SELECTED _bipolar_sigmoid\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.022    |             |\n",
      "| Term Wise Accuracy |    0.978    |             |\n",
      "|      Accuracy      |    0.302    |             |\n",
      "|     Precision      |    0.984    |    0.895    |\n",
      "|       Recall       |    0.343    |    0.529    |\n",
      "|     F1-measure     |    0.489    |    0.665    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_4000__relu_leaky_uniform\n",
      "SELECTED _relu_leaky\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.022    |             |\n",
      "| Term Wise Accuracy |    0.978    |             |\n",
      "|      Accuracy      |    0.318    |             |\n",
      "|     Precision      |    0.984    |    0.897    |\n",
      "|       Recall       |    0.374    |    0.541    |\n",
      "|     F1-measure     |    0.525    |    0.675    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_4000__binary_sigmoid_uniform\n",
      "SELECTED _binary_sigmoid\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.022    |             |\n",
      "| Term Wise Accuracy |    0.978    |             |\n",
      "|      Accuracy      |    0.296    |             |\n",
      "|     Precision      |    0.983    |    0.895    |\n",
      "|       Recall       |    0.338    |    0.526    |\n",
      "|     F1-measure     |    0.483    |    0.662    |\n",
      "+--------------------+-------------+-------------+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1_bert_5000__identity_uniform\n",
      "SELECTED _identity\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.038    |             |\n",
      "| Term Wise Accuracy |    0.962    |             |\n",
      "|      Accuracy      |    0.081    |             |\n",
      "|     Precision      |    0.235    |    0.693    |\n",
      "|       Recall       |    0.024    |    0.152    |\n",
      "|     F1-measure     |    0.034    |    0.249    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_5000__biploar_step_uniform\n",
      "SELECTED _biploar_step\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.014    |             |\n",
      "| Term Wise Accuracy |    0.986    |             |\n",
      "|      Accuracy      |    0.460    |             |\n",
      "|     Precision      |    0.988    |    0.934    |\n",
      "|       Recall       |    0.640    |    0.717    |\n",
      "|     F1-measure     |    0.772    |    0.811    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_5000__bipolar_sigmoid_uniform\n",
      "SELECTED _bipolar_sigmoid\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.014    |             |\n",
      "| Term Wise Accuracy |    0.986    |             |\n",
      "|      Accuracy      |    0.466    |             |\n",
      "|     Precision      |    0.988    |    0.933    |\n",
      "|       Recall       |    0.631    |    0.713    |\n",
      "|     F1-measure     |    0.764    |    0.808    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_5000__relu_leaky_uniform\n",
      "SELECTED _relu_leaky\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.014    |             |\n",
      "| Term Wise Accuracy |    0.986    |             |\n",
      "|      Accuracy      |    0.479    |             |\n",
      "|     Precision      |    0.988    |    0.937    |\n",
      "|       Recall       |    0.622    |    0.707    |\n",
      "|     F1-measure     |    0.758    |    0.806    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_5000__binary_sigmoid_uniform\n",
      "SELECTED _binary_sigmoid\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.014    |             |\n",
      "| Term Wise Accuracy |    0.986    |             |\n",
      "|      Accuracy      |    0.469    |             |\n",
      "|     Precision      |    0.987    |    0.933    |\n",
      "|       Recall       |    0.635    |    0.714    |\n",
      "|     F1-measure     |    0.768    |    0.809    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_10000__identity_uniform\n",
      "SELECTED _identity\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.038    |             |\n",
      "| Term Wise Accuracy |    0.962    |             |\n",
      "|      Accuracy      |    0.081    |             |\n",
      "|     Precision      |    0.235    |    0.693    |\n",
      "|       Recall       |    0.024    |    0.152    |\n",
      "|     F1-measure     |    0.034    |    0.249    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_10000__biploar_step_uniform\n",
      "SELECTED _biploar_step\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.002    |             |\n",
      "| Term Wise Accuracy |    0.998    |             |\n",
      "|      Accuracy      |    0.934    |             |\n",
      "|     Precision      |    0.985    |    0.984    |\n",
      "|       Recall       |    0.963    |    0.968    |\n",
      "|     F1-measure     |    0.974    |    0.976    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_10000__bipolar_sigmoid_uniform\n",
      "SELECTED _bipolar_sigmoid\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.002    |             |\n",
      "| Term Wise Accuracy |    0.998    |             |\n",
      "|      Accuracy      |    0.935    |             |\n",
      "|     Precision      |    0.978    |    0.976    |\n",
      "|       Recall       |    0.970    |    0.976    |\n",
      "|     F1-measure     |    0.974    |    0.976    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_10000__relu_leaky_uniform\n",
      "SELECTED _relu_leaky\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.002    |             |\n",
      "| Term Wise Accuracy |    0.998    |             |\n",
      "|      Accuracy      |    0.934    |             |\n",
      "|     Precision      |    0.980    |    0.980    |\n",
      "|       Recall       |    0.968    |    0.972    |\n",
      "|     F1-measure     |    0.974    |    0.976    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_10000__binary_sigmoid_uniform\n",
      "SELECTED _binary_sigmoid\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.002    |             |\n",
      "| Term Wise Accuracy |    0.998    |             |\n",
      "|      Accuracy      |    0.934    |             |\n",
      "|     Precision      |    0.992    |    0.983    |\n",
      "|       Recall       |    0.955    |    0.968    |\n",
      "|     F1-measure     |    0.973    |    0.976    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_15000__identity_uniform\n",
      "SELECTED _identity\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.038    |             |\n",
      "| Term Wise Accuracy |    0.962    |             |\n",
      "|      Accuracy      |    0.081    |             |\n",
      "|     Precision      |    0.235    |    0.692    |\n",
      "|       Recall       |    0.024    |    0.152    |\n",
      "|     F1-measure     |    0.034    |    0.249    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_15000__biploar_step_uniform\n",
      "SELECTED _biploar_step\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.002    |             |\n",
      "| Term Wise Accuracy |    0.998    |             |\n",
      "|      Accuracy      |    0.934    |             |\n",
      "|     Precision      |    0.990    |    0.981    |\n",
      "|       Recall       |    0.958    |    0.971    |\n",
      "|     F1-measure     |    0.973    |    0.976    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_15000__bipolar_sigmoid_uniform\n",
      "SELECTED _bipolar_sigmoid\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.002    |             |\n",
      "| Term Wise Accuracy |    0.998    |             |\n",
      "|      Accuracy      |    0.934    |             |\n",
      "|     Precision      |    0.987    |    0.982    |\n",
      "|       Recall       |    0.961    |    0.969    |\n",
      "|     F1-measure     |    0.973    |    0.976    |\n",
      "+--------------------+-------------+-------------+\n",
      "t1_bert_15000__relu_leaky_uniform\n",
      "SELECTED _relu_leaky\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7ceb549c2f16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHIDDEN_NODES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrandomizations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mmodel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHIDDEN_NODES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrandomizations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mELM_MultiLabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mINPUT_NODES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHIDDEN_NODES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOUTPUT_NODES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                 \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHIDDEN_NODES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrandomizations\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                 \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-dd03c74dfd35>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_x, train_y, verbose, show_metrics)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_x shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train_y shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0minp_activation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_H_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;31m# This is the H matrix getting its Moore Penrose Inverse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-dd03c74dfd35>\u001b[0m in \u001b[0;36m__get_H_matrix\u001b[0;34m(self, train_x, verbose)\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Applyin activation function\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0minp_activation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__activation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minp_activation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/disks/user/anaconda3/lib/python3.6/site-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0mbuff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m         \u001b[0mbuff\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minarr_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/disks/user/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2753\u001b[0m             \u001b[0mvargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2755\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vectorize_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2757\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/disks/user/anaconda3/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_vectorize_call\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   2829\u001b[0m                       for a in args]\n\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2831\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2833\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-10bed686706b>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0m_bipolar_sigmoid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0m_relu_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0m_relu_leaky\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/disks/user/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m   2318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2319\u001b[0m     return _methods._amax(a, axis=axis,\n\u001b[0;32m-> 2320\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for dataset in datasets.keys():\n",
    "    for HIDDEN_NODES in list_of_models_hidden_nodes:\n",
    "        for activation in activations:\n",
    "                start = time.time()\n",
    "                print(dataset+\"_\"+str(HIDDEN_NODES)+\"_\"+activation+\"_\"+randomizations)\n",
    "                model_dict[dataset+\"_\"+str(HIDDEN_NODES)+\"_\"+activation+\"_\"+randomizations]= ELM_MultiLabel(input_nodes=INPUT_NODES,hidden_nodes=HIDDEN_NODES,output_nodes=OUTPUT_NODES, activation=activation)\n",
    "                predicted, eval_dict=model_dict[dataset+\"_\"+str(HIDDEN_NODES)+\"_\"+activation+\"_\"+randomizations].fit(datasets[dataset][0],datasets[dataset][1], verbose=False, show_metrics=True)\n",
    "\n",
    "                end =time.time()\n",
    "                add_data_to_metric_list(eval_dict, activation, dataset, start, \"train\", end)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TESTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets.keys():\n",
    "    for HIDDEN_NODES in list_of_models_hidden_nodes:\n",
    "        for activation in activations:\n",
    "                start = time.time()\n",
    "                print(dataset+\"_\"+str(HIDDEN_NODES)+\"_\"+activation+\"_\"+randomizations)\n",
    "                model_dict[dataset+\"_\"+str(HIDDEN_NODES)+\"_\"+activation+\"_\"+randomizations]\n",
    "                predicted, eval_dict=model_dict[dataset+\"_\"+str(HIDDEN_NODES)+\"_\"+activation+\"_\"+randomizations].predict(datasets[dataset][2],datasets[dataset][3], show_metrics=True)\n",
    "                end =time.time()\n",
    "                add_data_to_metric_list(eval_dict, activation, dataset, start, \"test\", end)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_metrics_df= pd.DataFrame(metrics_dict_list)\n",
    "_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WRITING METRICS DATA TO FILE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_metrics_df.to_csv(\"Final_ELM_Mertics_BERT.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**END**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
