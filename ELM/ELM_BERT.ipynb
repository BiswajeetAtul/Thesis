{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import prettytable\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, hamming_loss\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#READING THE BERT EMBEDDINGS AND Y MATRIX\n",
    "bert_embedding=np.load(\"embeddings.npz\")\n",
    "label_values=np.load(\"Y.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type1_BERT_Embeddings=bert_embedding[\"t1\"]\n",
    "type2_BERT_Embeddings=bert_embedding[\"t2\"]\n",
    "label_values=label_values[\"arr_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape BERT embeddings: \",type1_BERT_Embeddings.shape)\n",
    "print(\"Shape Labels: \",label_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_train_x, t1_test_x, t1_train_y, t1_test_y = train_test_split(type1_BERT_Embeddings, label_values, test_size=0.33, random_state=234)\n",
    "t2_train_x, t2_test_x, t2_train_y, t2_test_y = train_test_split(type2_BERT_Embeddings, label_values, test_size=0.33, random_state=230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"t1_train_x: \", t1_train_x)\n",
    "print(\"Shape t1_train_x: \", t1_train_x.shape)\n",
    "print(\"t1_test_x: \", t1_test_x)\n",
    "print(\"Shape t1_test_x: \", t1_test_x.shape)\n",
    "print(\"t1_train_y: \", t1_train_y)\n",
    "print(\"Shape t1_train_y: \", t1_train_y.shape)\n",
    "print(\"t1_test_y: \", t1_test_y)\n",
    "print(\"Shape t1_test_y: \", t1_test_y.shape)\n",
    "print(\"t2_train_x: \", t2_train_x)\n",
    "print(\"Shape t2_train_x: \", t2_train_x.shape)\n",
    "print(\"t2_test_x: \", t2_test_x)\n",
    "print(\"Shape t2_test_x: \", t2_test_x.shape)\n",
    "print(\"t2_train_y: \", t2_train_y)\n",
    "print(\"Shape t2_train_y: \", t2_train_y.shape)\n",
    "print(\"t2_test_y: \", t2_test_y.shape)\n",
    "print(\"Shape t2_test_y: \", t2_test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # CHECKING IF THE METRICS ARE COORRECTLY WORKING\n",
    "\n",
    "# real = t2_test_y\n",
    "# predicted =t2_test_y\n",
    "\n",
    "# accuracy = accuracy_score(real, predicted)\n",
    "# hamLoss = hamming_loss(real, predicted)\n",
    "# # element wise correctness\n",
    "# term_wise_accuracy=np.sum(np.logical_not(np.logical_xor(real, predicted)))/real.size\n",
    "\n",
    "# macro_precision = precision_score(real, predicted, average='macro')\n",
    "# macro_recall = recall_score(real, predicted, average='macro')\n",
    "# macro_f1 = f1_score(real, predicted, average='macro')\n",
    "\n",
    "# micro_precision = precision_score(real, predicted, average='micro')\n",
    "# micro_recall = recall_score(real, predicted, average='micro')\n",
    "# micro_f1 = f1_score(real, predicted, average='micro')\n",
    "\n",
    "# metricTable=prettytable.PrettyTable()\n",
    "# metricTable.field_names = [\"Metric\", \"Macro Value\", \"Micro Value\"]\n",
    "# metricTable.add_row([\"Hamming Loss\",\"{0:.3f}\".format(hamLoss) ,\"\"])\n",
    "# metricTable.add_row([\"Term Wise Accuracy\",\"{0:.3f}\".format(term_wise_accuracy) ,\"\"])\n",
    "\n",
    "# metricTable.add_row([\"Accuracy\",\"{0:.3f}\".format(accuracy),\"\"])\n",
    "# metricTable.add_row([\"Precision\",\"{0:.3f}\".format(macro_precision),\"{0:.3f}\".format(micro_precision)])\n",
    "# metricTable.add_row([\"Recall\",\"{0:.3f}\".format(macro_recall),\"{0:.3f}\".format(micro_recall)])\n",
    "# metricTable.add_row([\"F1-measure\",\"{0:.3f}\".format(macro_f1),\"{0:.3f}\".format(micro_f1)])\n",
    "\n",
    "# print(metricTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Activation Functions\n",
    "\n",
    "# def _identity(x):\n",
    "#     return x\n",
    "# def _binary_step(x, threshold = 0):\n",
    "#     return 1 if x=threshold else 0\n",
    "# def _biploar_step(x ,threshold = 0):\n",
    "#     return 1 if x>=threshold else -1\n",
    "# def _binary_sigmoid(x):\n",
    "#     return 1. / (1. + np.exp(-x))\n",
    "# def _bipolar_sigmoid(x):\n",
    "#     return (1. - np.exp(-x))/(1. + np.exp(-x))\n",
    "# def _relu_function(x):\n",
    "#     return np.max(0, x)\n",
    "# def _relu_leaky(x):\n",
    "#     return np.max(0.01*x, x)\n",
    "\n",
    "\n",
    "_identity =np.vectorize(lambda x: x)\n",
    "_binary_step =np.vectorize(lambda x,t=0: 1 if x>t else 0)\n",
    "_biploar_step =np.vectorize(lambda x,t=0: 1 if x>t else -1)\n",
    "_binary_sigmoid=np.vectorize(lambda x: 1. / (1. + np.exp(-x)))\n",
    "_bipolar_sigmoid=np.vectorize(lambda x: (1. - np.exp(-x))/(1. + np.exp(-x)))\n",
    "_relu_function=np.vectorize(lambda x: np.max([0, x]))\n",
    "_relu_leaky=np.vectorize(lambda x: np.max([0.01*x, x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ELM_MultiLabel:\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, activation=\"_identity\", bias=True, random_gen=\"uniform\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_nodes ([integer]): Number of Input nodes\n",
    "            hidden_nodes ([integer]): Number of hidden nodes\n",
    "            output_nodes ([integer]): Number of output nodes\n",
    "            activation ([function]): The function name which will be used as the activation function in the hidden layer. Defaults to \"_identity\".\n",
    "                possible values: _binary_step, _biploar_step, _binary_sigmoid, _bipolar_sigmoid, _relu_function, _relu_leaky, _identity\n",
    "            bias ([boolean]): Flag to use bias, if True then randomly generate bias @random_gen else bias - 0.\n",
    "            random_gen (str, optional): The type way in which random weight are generated. Defaults to \"uniform\".\n",
    "        \"\"\"\n",
    "        self.__input_nodes = input_nodes\n",
    "        self.__hidden_nodes = hidden_nodes\n",
    "        self.__output_nodes = output_nodes\n",
    "\n",
    "        if random_gen == \"uniform\":\n",
    "            self.__beta = np.random.uniform(-1.,1.,size = (self.__hidden_nodes, self.__output_nodes))\n",
    "            self.__alpha = np.random.uniform(-1.,1.,size = (self.__input_nodes, self.__hidden_nodes))\n",
    "            self.__bias = np.random.uniform(size = (self.__hidden_nodes,))\n",
    "        else:\n",
    "            self.__beta = np.random.normal(-1.,1.,size=(self.__hidden_nodes, self.__output_nodes))\n",
    "            self.__alpha = np.random.normal(-1.,1.,size=(self.__input_nodes, self.__hidden_nodes))\n",
    "            self.__bias = np.random.normal(size=(self.__n_hidden_nodes,))\n",
    "        \n",
    "        if activation == \"_biploar_step\": #1\n",
    "            self.__activation = _biploar_step\n",
    "            self.__activation_name =1\n",
    "\n",
    "            print(\"SELECTED _biploar_step\")\n",
    "        elif activation == \"_bipolar_sigmoid\": #2\n",
    "            self.__activation = _bipolar_sigmoid\n",
    "            self.__activation_name =2\n",
    "\n",
    "            print(\"SELECTED _bipolar_sigmoid\")\n",
    "\n",
    "        elif activation == \"_relu_leaky\": #3\n",
    "            self.__activation =_relu_leaky\n",
    "            self.__activation_name =3\n",
    "            print(\"SELECTED _relu_leaky\")\n",
    "\n",
    "        elif activation == \"_binary_step\": #4\n",
    "            self.__activation =_binary_step\n",
    "            self.__activation_name =4\n",
    "            print(\"SELECTED _binary_step\")\n",
    "\n",
    "        elif activation == \"_binary_sigmoid\": #5\n",
    "            self.__activation =_binary_sigmoid\n",
    "            self.__activation_name =5\n",
    "            print(\"SELECTED _binary_sigmoid\")            \n",
    "        elif activation == \"_relu_function\": #6\n",
    "            self.__activation =_relu_function\n",
    "            self.__activation_name =6\n",
    "            print(\"SELECTED _relu_function\")\n",
    "        else: #0\n",
    "            self.__activation =_identity \n",
    "            self.__activation_name =0\n",
    "            print(\"SELECTED _identity\")\n",
    "    \n",
    "\n",
    "    def getInputNodes(self):\n",
    "        return  self.__input_nodes\n",
    "\n",
    "    def getHiddenNodes(self):\n",
    "        return  self.__hidden_nodes\n",
    "\n",
    "    def getOutputNodes(self):\n",
    "        return  self.__output_nodes\n",
    "    \n",
    "    def getBetaWeights(self):\n",
    "        return self.__beta\n",
    "    \n",
    "    def getAlphaWeight(self):\n",
    "        return self.__alpha\n",
    "    \n",
    "    def getBias(self):\n",
    "        return self.__bias\n",
    "\n",
    "    def getActivationFunc(self):\n",
    "        return self.__activation_name\n",
    "\n",
    "    def setInputNodes(self, inp):\n",
    "        self.__input_nodes = inp\n",
    "\n",
    "    def setHiddenNodes(self, inp):\n",
    "        self.__hidden_nodes =inp\n",
    "\n",
    "    def setOutputNodes(self, inp):\n",
    "        self.__output_nodes =inp\n",
    "    \n",
    "    def setBetaWeights(self, inp):\n",
    "        self.__beta= inp\n",
    "    \n",
    "    def setAlphaWeight(self, inp):\n",
    "        self.__alpha =inp\n",
    "    \n",
    "    def setBias(self, inp):\n",
    "        self.__bias= inp\n",
    "\n",
    "    def setActivationFunc(self, activation):\n",
    "        if activation == 1:\n",
    "            self.__activation = _biploar_step\n",
    "            self.__activation_name =1\n",
    "\n",
    "            print(\"SELECTED _biploar_step\")\n",
    "        elif activation == 2:\n",
    "            self.__activation = _bipolar_sigmoid\n",
    "            self.__activation_name =2\n",
    "\n",
    "            print(\"SELECTED _bipolar_sigmoid\")\n",
    "\n",
    "        elif activation == 3:\n",
    "            self.__activation =_relu_leaky\n",
    "            self.__activation_name =3\n",
    "            print(\"SELECTED _relu_leaky\")\n",
    "\n",
    "        elif activation == 4:\n",
    "            self.__activation =_binary_step\n",
    "            self.__activation_name =4\n",
    "            print(\"SELECTED _binary_step\")\n",
    "\n",
    "        elif activation == 5:\n",
    "            self.__activation =_binary_sigmoid\n",
    "            self.__activation_name =5\n",
    "            print(\"SELECTED _binary_sigmoid\")            \n",
    "        elif activation == 6:\n",
    "            self.__activation =_relu_function\n",
    "            self.__activation_name =6\n",
    "            print(\"SELECTED _relu_function\")\n",
    "        else: #0\n",
    "            self.__activation =_identity \n",
    "            self.__activation_name =0\n",
    "            print(\"SELECTED _identity\")\n",
    "\n",
    "    def saveModel(self, name):\n",
    "        \"\"\"\n",
    "        SAVES THE MODEL in NUMPY ARRAYS\n",
    "        Accepts the name for the file\n",
    "        \"\"\"\n",
    "        name = \"./Model_State/\"+name + \".npz\"\n",
    "        dims= np.array([self.getInputNodes(),self.getHiddenNodes(),self.getOutputNodes(), self.getActivationFunc()])\n",
    "        np.savez(name, bias =self.getBias(), alpha = self.getAlphaWeight(), beta= self.getBetaWeights(), dimensions= dims)\n",
    "        print(\"Saved! in:\", name)\n",
    "\n",
    "\n",
    "    def loadModel(self, name):\n",
    "        m_file = np.load(\"./Model_State/\"+name+\".npz\")\n",
    "        self.setInputNodes(m_file[\"dimensions\"][0])\n",
    "        self.setHiddenNodes(m_file[\"dimensions\"][1])\n",
    "        self.setOutputNodes(m_file[\"dimensions\"][2])\n",
    "        self.setBetaWeights(m_file[\"beta\"])\n",
    "        self.setAlphaWeight(m_file[\"alpha\"])\n",
    "        self.setBias(m_file[\"bias\"])\n",
    "        self.setActivationFunc(m_file[\"dimensions\"][3])\n",
    "        print(\"Loaded!\", name)\n",
    "\n",
    "    def __get_H_matrix(self, train_x, verbose=False):\n",
    "        # 1 Propagate data from Input to hidden Layer\n",
    "        if verbose:\n",
    "            print(\"Propagate data from Input to hidden Layer\")\n",
    "        inp = np.dot(train_x , self.__alpha)\n",
    "        if verbose:\n",
    "            print(inp)\n",
    "            print(\"Adding Biases\")\n",
    "        inp = inp  + self.__bias\n",
    "        if verbose:\n",
    "            print(inp)\n",
    "            print(\"Applyin activation function\")\n",
    "        inp_activation = np.apply_along_axis(self.__activation, 1, inp)\n",
    "        return inp_activation\n",
    "\n",
    "    def fit(self, train_x, train_y, verbose = False, show_metrics = True):\n",
    "        \"\"\"\n",
    "        This function calculates the Beta weights or the output weights\n",
    "        train_x : input matrix\n",
    "        train_y : output matrix to be predicted or learned upon unipolar\n",
    "\n",
    "        returns: if test_y is not given then\n",
    "                returns the predicted output\n",
    "                if test_y is given then returns predicted output and evaluation metrics dict \n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"train_x shape:\", train_x.shape)\n",
    "            print(\"train_y shape:\", train_y.shape)\n",
    "        inp_activation = self.__get_H_matrix(train_x, verbose)\n",
    "        # This is the H matrix getting its Moore Penrose Inverse\n",
    "        if verbose:\n",
    "            print(inp_activation)\n",
    "            print(\"Getting the Generalized Moore Penrose Inverse\")\n",
    "        generalizedInverse = np.linalg.pinv(inp_activation)\n",
    "        if verbose:\n",
    "            print(generalizedInverse)\n",
    "            print(\"Finding Beta, output weights\")\n",
    "        # Now find output weight matrix Beta \n",
    "        # convert input Y values according to the threshold using biploar step function\n",
    "        _bipolar_y=  np.apply_along_axis(_biploar_step, 1, train_y)\n",
    "        self.__beta = np.dot(generalizedInverse, _bipolar_y)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Beta Matrix Weights\")\n",
    "            print(self.__beta)\n",
    "\n",
    "        # print(\"Model Metrics, for Training :\")\n",
    "        return self.predict(train_x, train_y,verbose,show_metrics)\n",
    "    \n",
    "    def predict(self, test_x, test_y = None, verbose = False, show_metrics= True):\n",
    "        \"\"\"\n",
    "        preditcts the output for the input test data\n",
    "        call this after calling the fit.\n",
    "        test_data shape should be (batch_size,768 or input_nodes)\n",
    "        output_shape will be (batch_size, 71 or output_nodes)\n",
    "\n",
    "        returns: if test_y is not given then\n",
    "                returns the predicted output\n",
    "                if test_y is given then returns predicted output and evaluation metrics dict\n",
    "        \"\"\"\n",
    "        if verbose:\n",
    "            print(\"Predicting outputs\")\n",
    "        inp_activation = self.__get_H_matrix(test_x, verbose)\n",
    "        output_predicted = np.dot(inp_activation, self.__beta)\n",
    "        # convert predicted according to the threshold using biploar step function\n",
    "        predicted_bipolar =  np.apply_along_axis(_biploar_step, 1, output_predicted)\n",
    "        predicted_binary = np.apply_along_axis(_binary_step, 1, predicted_bipolar)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"predicted output\")\n",
    "            print(output_predicted)\n",
    "            print(\"predicted_bipolar\")\n",
    "            print(predicted_bipolar)\n",
    "            print(\"predicted_binary\")\n",
    "            print(predicted_binary)\n",
    "            print(\"Original Binary\")\n",
    "            print(test_y)\n",
    "\n",
    "        eval_dict={}\n",
    "        if (test_y is not None):\n",
    "            eval_dict=self.__evaluate(test_y,predicted_binary, for_test=False)\n",
    "        if(test_y is not None):\n",
    "            return predicted_binary, eval_dict\n",
    "        else:\n",
    "            return predicted_binary\n",
    "\n",
    "    def __evaluate(self, real, predicted, for_test=True):\n",
    "        \"\"\"\n",
    "        real values as 0,1\n",
    "        predicted values as 0,1\n",
    "        \"\"\"\n",
    "        # Now we find accuracy, precision, recall, Hamming Loss and F1 Measure\n",
    "        accuracy = accuracy_score(real, predicted)\n",
    "        hamLoss = hamming_loss(real, predicted)\n",
    "        # element wise correctness\n",
    "        term_wise_accuracy=np.sum(np.logical_not(np.logical_xor(real, predicted)))/real.size\n",
    "\n",
    "        macro_precision = precision_score(real, predicted, average='macro')\n",
    "        macro_recall = recall_score(real, predicted, average='macro')\n",
    "        macro_f1 = f1_score(real, predicted, average='macro')\n",
    "\n",
    "        micro_precision = precision_score(real, predicted, average='micro')\n",
    "        micro_recall = recall_score(real, predicted, average='micro')\n",
    "        micro_f1 = f1_score(real, predicted, average='micro')\n",
    "        \n",
    "        metricTable=prettytable.PrettyTable()\n",
    "        metricTable.field_names = [\"Metric\", \"Macro Value\", \"Micro Value\"]\n",
    "        metricTable.add_row([\"Hamming Loss\",\"{0:.3f}\".format(hamLoss) ,\"\"])\n",
    "        metricTable.add_row([\"Term Wise Accuracy\",\"{0:.3f}\".format(term_wise_accuracy) ,\"\"])\n",
    "\n",
    "        metricTable.add_row([\"Accuracy\",\"{0:.3f}\".format(accuracy),\"\"])\n",
    "        metricTable.add_row([\"Precision\",\"{0:.3f}\".format(macro_precision),\"{0:.3f}\".format(micro_precision)])\n",
    "        metricTable.add_row([\"Recall\",\"{0:.3f}\".format(macro_recall),\"{0:.3f}\".format(micro_recall)])\n",
    "        metricTable.add_row([\"F1-measure\",\"{0:.3f}\".format(macro_f1),\"{0:.3f}\".format(micro_f1)])\n",
    "\n",
    "        print(metricTable)\n",
    "\n",
    "        #\n",
    "        # print(\"Metrics @ Literature\")\n",
    "        lit_accuracy, lit_precision, lit_recall, lit_f1 = self.get_eval_metrics(real,predicted)\n",
    "\n",
    "        return_dict = {\"HiddenNodes\": self.getHiddenNodes(),\n",
    "                \"lit_accuracy\": lit_accuracy,\n",
    "                \"lit_precision\": lit_precision,\n",
    "                \"lit_recall\": lit_recall,\n",
    "                \"lit_f1\": lit_f1,\n",
    "                \"sklearn_hamLoss\": hamLoss,\n",
    "                \"sklearn_accuracy\": accuracy,\n",
    "                \"term_wise_accuracy\": term_wise_accuracy,\n",
    "                \"sklearn_macro_precision\": macro_precision,\n",
    "                \"sklearn_micro_precision\": micro_precision,\n",
    "                \"sklearn_macro_recall\": macro_recall,\n",
    "                \"sklearn_micro_recall\": micro_recall,\n",
    "                \"sklearn_macro_f1\": macro_f1,\n",
    "                \"sklearn_micro_f1\": micro_f1,\n",
    "                }\n",
    "\n",
    "        return return_dict\n",
    "\n",
    "    def get_eval_metrics(self, real, predicted, verbose= False):\n",
    "        err_cnt_accuracy=0\n",
    "        err_cnt_precision=0\n",
    "        err_cnt_recall=0\n",
    "        if verbose:\n",
    "            print(real)\n",
    "            print(predicted)\n",
    "        for x in range(real.shape[0]):\n",
    "            err_and= np.logical_and(real[x],predicted[x])\n",
    "            err_or = np.logical_or(real[x],predicted[x])\n",
    "            # Accuracy\n",
    "            err_cnt_accuracy +=(sum(err_and)/sum(err_or))\n",
    "\n",
    "            # Precision\n",
    "            if sum(err_and) != 0:\n",
    "                err_cnt_precision += (sum(err_and) / sum(predicted[x]))\n",
    "            # Recall\n",
    "            err_cnt_recall += (sum(err_and) / sum(real[x]))\n",
    "            if verbose:\n",
    "                print(\"Iteration :\",x)\n",
    "                print((sum(err_and)/sum(err_or)))\n",
    "                print(err_and)\n",
    "                print(err_or)\n",
    "        \n",
    "        # err_count_hamming = np.zeros((real.shape))\n",
    "\n",
    "        # for i in range(real.shape[0]):\n",
    "        #     for j in range(real.shape[1]):\n",
    "        #         if real[i,j] != predicted[i,j]:\n",
    "        #             err_count_hamming[1,j] = err_count_hamming[1,j]+1\n",
    "\n",
    "        # sum_err = np.sum(err_count_hamming);\n",
    "        # HammingLoss = sum_err/real.size;\n",
    "        accuracy = err_cnt_accuracy / real.shape[0]\n",
    "        precision = err_cnt_precision / real.shape[0]\n",
    "        recall = err_cnt_recall / real.shape[0]\n",
    "        f1 = 2*((precision*recall)/(precision+recall))\n",
    "        if verbose:\n",
    "            print(\"Final: \")\n",
    "            # print(\"Hamming Loss: \", HammingLoss)\n",
    "            print(\"Accuracy: \",accuracy)\n",
    "            print(\"precision: \",precision)\n",
    "            print(\"recall: \",recall)\n",
    "            print(\"f1: \",f1)\n",
    "\n",
    "        # metricTable=prettytable.PrettyTable()\n",
    "        # metricTable.field_names = [\"Metric\", \"Value\"]\n",
    "        # metricTable.add_row([\" Literature Hamming Loss\",\"{0:.3f}\".format(HammingLoss)])\n",
    "        # metricTable.add_row([\"Literature Accuracy\",\"{0:.3f}\".format(accuracy)])\n",
    "\n",
    "        # metricTable.add_row([\"Literature Precision\",\"{0:.3f}\".format(precision)])\n",
    "        # metricTable.add_row([\"LiteratureRecall\",\"{0:.3f}\".format(recall)])\n",
    "        # metricTable.add_row([\"LiteratureF1-measure\",\"{0:.3f}\".format(f1)])\n",
    "\n",
    "        # # print(metricTable)\n",
    "\n",
    "        return accuracy,precision,recall,f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now The preprocessing and is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now We will run the model for all the three types data sets we have viz.\n",
    "- TRAIN X\n",
    "  - t1_train_x\n",
    "  - t2_train_x\n",
    "- TEST X\n",
    "  - t1_test_x\n",
    "  - t2_test_x\n",
    "- TRAIN Y\n",
    "  - t1_train_y\n",
    "  - t2_train_y\n",
    "- TEST Y\n",
    "  - t1_test_y\n",
    "  - t2_test_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_models_hidden_nodes=[100,200, 300, 400, 500, 1000, 2000, 3000, 4000, 5000, 10000]#, 15000]#, 20000]\n",
    "\n",
    "INPUT_NODES= 768\n",
    "OUTPUT_NODES= 71\n",
    "activations= [\"_identity\",\"_biploar_step\",\"_bipolar_sigmoid\",\"_relu_leaky\",\"_binary_sigmoid\"]\n",
    "# activations= [\"_identity\"]\n",
    "\n",
    "randomizations =\"uniform\"\n",
    "datasets ={\"t1_bert\":(t1_train_x,t1_train_y,t1_test_x,t1_test_y),\"t2_bert\":(t2_train_x,t2_train_y,t2_test_x,t2_test_y)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict_list=[]\n",
    "\n",
    "def add_data_to_metric_list(eval_dict, activation, type, start, phase, end, model_name,metrics_dict_list=metrics_dict_list):\n",
    "    eval_dict[\"activation\"]=activation\n",
    "    eval_dict[\"type\"]=type\n",
    "    eval_dict[\"phase\"]=phase\n",
    "    eval_dict[\"total_time\"]=end-start\n",
    "    eval_dict[\"model_nm\"]=model_name\n",
    "\n",
    "\n",
    "    metrics_dict_list.append(eval_dict)\n",
    "\n",
    "def export_dataframe_to_file(datalist, filename):\n",
    "    df=pd.DataFrame(datalist)\n",
    "    filename=\"./EvaluationMetrics/\"+filename+\".csv\"\n",
    "    df.to_csv(filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the above function with a simple 50 hidden layer node model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to store the models\n",
    "model_dict={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TRAINING AND TESTING**\n",
    "The metrics will be saved in EvaluationMetrics Folder for further studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for dataset in datasets.keys():\n",
    "    for activation in activations:\n",
    "        metrics_dict_list_test=[]\n",
    "        metrics_dict_list_train=[]\n",
    "\n",
    "        for HIDDEN_NODES in list_of_models_hidden_nodes:\n",
    "            # region Model training\n",
    "            start = time.time()\n",
    "            model_name = dataset+\"_\"+str(HIDDEN_NODES)+\"_\"+activation+\"_\"+randomizations\n",
    "\n",
    "            print(model_name + \" TRAINING\\n\")\n",
    "            model_dict[model_name]= ELM_MultiLabel(input_nodes=INPUT_NODES,hidden_nodes=HIDDEN_NODES,output_nodes=OUTPUT_NODES, activation=activation)\n",
    "\n",
    "            predicted, eval_dict_train=model_dict[model_name].fit(datasets[dataset][0],datasets[dataset][1], show_metrics=True)\n",
    "\n",
    "            end =time.time()\n",
    "            add_data_to_metric_list(eval_dict_train, activation, dataset, start, \"train\", end, model_name,metrics_dict_list=metrics_dict_list_train )\n",
    "            # endregion\n",
    "\n",
    "            # region Model Testing\n",
    "            start = time.time()\n",
    "            print(model_name + \" TESTING\\n\")\n",
    "            \n",
    "            predicted, eval_dict_test=model_dict[model_name].predict(datasets[dataset][2],datasets[dataset][3], show_metrics=True)\n",
    "\n",
    "            end =time.time()\n",
    "            add_data_to_metric_list(eval_dict_test, activation, dataset, start, \"test\", end, model_name, metrics_dict_list=metrics_dict_list_test )\n",
    "            #model_dict[model_name].saveModel(model_name)\n",
    "            # endregion\n",
    "        train_file_name= \"TRAIN_\"+dataset+\"_\"+activation\n",
    "        test_file_name= \"TEST_\"+dataset+\"_\"+activation\n",
    "\n",
    "        export_dataframe_to_file(metrics_dict_list_train, train_file_name)\n",
    "        export_dataframe_to_file(metrics_dict_list_test, test_file_name)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**END**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('Thesis': conda)",
   "display_name": "Python 3.7.9 64-bit ('Thesis': conda)",
   "metadata": {
    "interpreter": {
     "hash": "870dc015ab544cf4fd4c91e2f8042f40253e24aac5eeb5e28336055566efd434"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}