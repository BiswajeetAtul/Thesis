{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prettytable\n",
    "import tensorflow as tf\n",
    "from keras import callbacks, initializers, optimizers, regularizers\n",
    "from keras.layers import (LSTM, Bidirectional, Concatenate, Conv1D, Dense,\n",
    "                          Dropout, Flatten, Input, MaxPooling1D,\n",
    "                          TimeDistributed)\n",
    "from keras.models import Model, Sequential\n",
    "from sklearn.metrics import (accuracy_score, f1_score, hamming_loss,\n",
    "                             precision_recall_curve, precision_score,\n",
    "                             recall_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Tensorboard Extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics Calculator Function\n",
    "def evaluate_model(real, predicted):\n",
    "    accuracy = accuracy_score(real, predicted)\n",
    "    hamLoss = hamming_loss(real, predicted)\n",
    "    # element wise correctness\n",
    "    term_wise_accuracy = np.sum(np.logical_not(\n",
    "        np.logical_xor(real, predicted)))/real.size\n",
    "\n",
    "    macro_precision = precision_score(real, predicted, average='macro')\n",
    "    macro_recall = recall_score(real, predicted, average='macro')\n",
    "    macro_f1 = f1_score(real, predicted, average='macro')\n",
    "\n",
    "    micro_precision = precision_score(real, predicted, average='micro')\n",
    "    micro_recall = recall_score(real, predicted, average='micro')\n",
    "    micro_f1 = f1_score(real, predicted, average='micro')\n",
    "\n",
    "    metricTable = prettytable.PrettyTable()\n",
    "    metricTable.field_names = [\"Metric\", \"Macro Value\", \"Micro Value\"]\n",
    "    metricTable.add_row([\"Hamming Loss\", \"{0:.3f}\".format(hamLoss), \"\"])\n",
    "    metricTable.add_row(\n",
    "        [\"Term Wise Accuracy\", \"{0:.3f}\".format(term_wise_accuracy), \"\"])\n",
    "\n",
    "    metricTable.add_row([\"Accuracy\", \"{0:.3f}\".format(accuracy), \"\"])\n",
    "    metricTable.add_row([\"Precision\", \"{0:.3f}\".format(\n",
    "        macro_precision), \"{0:.3f}\".format(micro_precision)])\n",
    "    metricTable.add_row([\"Recall\", \"{0:.3f}\".format(\n",
    "        macro_recall), \"{0:.3f}\".format(micro_recall)])\n",
    "    metricTable.add_row(\n",
    "        [\"F1-measure\", \"{0:.3f}\".format(macro_f1), \"{0:.3f}\".format(micro_f1)])\n",
    "\n",
    "    print(metricTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "  \n",
    "def initial_boost(epoch):\n",
    "    if epoch==0: return float(8.0)\n",
    "    elif epoch==1: return float(4.0)\n",
    "    elif epoch==2: return float(2.0)\n",
    "    elif epoch==3: return float(1.5)\n",
    "    else: return float(1.0)\n",
    "\n",
    "def step_cyclic(epoch):\n",
    "    try:\n",
    "        l_r, decay = 1.0, 0.0001\n",
    "        if epoch%33==0:multiplier = 10\n",
    "        else:multiplier = 1\n",
    "        rate = float(multiplier * l_r * 1/(1 + decay * epoch))\n",
    "        #print(\"Epoch\",epoch+1,\"- learning_rate\",rate)\n",
    "        return rate\n",
    "    except Exception as e:\n",
    "        print(\"Error in lr_schedule:\",str(e))\n",
    "        return float(1.0)\n"
   ]
  },
  {
   "source": [
    "Loading Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpstDF= pd.read_csv(\"mpst.csv\")\n",
    "mpstDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Split Function\n",
    "def get_partition_Embeddings(x_t1,x_t2,y,df,partition_nm):\n",
    "    _df=df[df[\"split\"]==partition_nm]\n",
    "    index_list=list(_df.index)\n",
    "    temp_array_x_t1=[]\n",
    "    temp_array_x_t2=[]\n",
    "    temp_array_y=[]\n",
    "    for index in index_list:\n",
    "        temp_array_x_t1.append(x_t1[index,:])\n",
    "        temp_array_x_t2.append(x_t2[index,:])\n",
    "        temp_array_y.append(y[index,:])\n",
    "    temp_array_x_t1=np.array(temp_array_x_t1)\n",
    "    temp_array_x_t2=np.array(temp_array_x_t2)\n",
    "    temp_array_y=np.array(temp_array_y)\n",
    "    return temp_array_x_t1,temp_array_x_t2, temp_array_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING BERT  EMBEDDINGS\n",
    "bert_embedding=np.load(r\"D:\\CodeRepo\\Thesis\\Thesis\\XLNet\\xl_embeddings.npz\")\n",
    "# LOADING XLnet EMBEDDINGS\n",
    "xl_embedding=np.load(r\"D:\\CodeRepo\\Thesis\\Thesis\\XLNet\\xl_embeddings.npz\")\n",
    "# LOADING LABELS Y\n",
    "label_values=np.load(r\"D:\\CodeRepo\\Thesis\\Thesis\\EDA\\Y.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT EMBEDDINGS T1 & T2\n",
    "type1_BERT_Embeddings=bert_embedding[\"t1\"]\n",
    "type2_BERT_Embeddings=bert_embedding[\"t2\"]\n",
    "# XLNet EMBEDDINGS T1 & T2\n",
    "type1_XL_Embeddings=xl_embedding[\"t1\"]\n",
    "type2_XL_Embeddings=xl_embedding[\"t2\"]\n",
    "# LABLES Y\n",
    "label_values=label_values[\"arr_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT\n",
    "\n",
    "# FOR TRAIN\n",
    "type1_BERT_Embeddings_Train,type2_BERT_Embeddings_Train,BERT_label_values_Train=get_partition_Embeddings(type1_BERT_Embeddings,type2_BERT_Embeddings,label_values,mpstDF,\"train\")\n",
    "# FOR VALIDATION\n",
    "type1_BERT_Embeddings_Val,type2_BERT_Embeddings_Val,BERT_label_values_Val=get_partition_Embeddings(type1_BERT_Embeddings,type2_BERT_Embeddings,label_values,mpstDF,\"val\")\n",
    "# FOR TEST\n",
    "type1_BERT_Embeddings_Test,type2_BERT_Embeddings_Test,BERT_label_values_Test=get_partition_Embeddings(type1_BERT_Embeddings,type2_BERT_Embeddings,label_values,mpstDF,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XLNET\n",
    "\n",
    "# FOR TRAIN\n",
    "type1_XL_Embeddings_Train,type2_XL_Embeddings_Train,XLNET_label_values_Train=get_partition_Embeddings(type1_XL_Embeddings,type2_XL_Embeddings,label_values,mpstDF,\"train\")\n",
    "# FOR VALIDATION\n",
    "type1_XL_Embeddings_Val,type2_XL_Embeddings_Val,XLNET_label_values_Val=get_partition_Embeddings(type1_XL_Embeddings,type2_XL_Embeddings,label_values,mpstDF,\"val\")\n",
    "# FOR TEST\n",
    "type1_XL_Embeddings_Test,type2_XL_Embeddings_Test,XLNET_label_values_Test=get_partition_Embeddings(type1_XL_Embeddings,type2_XL_Embeddings,label_values,mpstDF,\"test\")"
   ]
  },
  {
   "source": [
    "HAVING A LOOK AT THE SHAPES OF EACH PARTITION CREATED:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SHAPES OF EACH PARTITION _ BERT\\n\")\n",
    "print(\"type1_BERT_Embeddings_Train.shape: \", type1_BERT_Embeddings_Train.shape)\n",
    "print(\"type2_BERT_Embeddings_Train.shape: \", type2_BERT_Embeddings_Train.shape)\n",
    "print(\"BERT_label_values_Train.shape: \"    , BERT_label_values_Train.shape)\n",
    "\n",
    "print(\"type1_BERT_Embeddings_Val.shape: \", type1_BERT_Embeddings_Val.shape)\n",
    "print(\"type2_BERT_Embeddings_Val.shape: \", type2_BERT_Embeddings_Val.shape)\n",
    "print(\"BERT_label_values_Val.shape: \"    , BERT_label_values_Val.shape)\n",
    "\n",
    "print(\"type1_BERT_Embeddings_Test.shape: \", type1_BERT_Embeddings_Test.shape)\n",
    "print(\"type2_BERT_Embeddings_Test.shape: \", type2_BERT_Embeddings_Test.shape)\n",
    "print(\"BERT_label_values_Test.shape: \"    , BERT_label_values_Test.shape)\n",
    "\n",
    "print(\"SHAPES OF EACH PARTITION _ XLNET\\n\")\n",
    "\n",
    "print(\"type1_XL_Embeddings_Train.shape: \", type1_XL_Embeddings_Train.shape)\n",
    "print(\"type2_XL_Embeddings_Train.shape: \", type2_XL_Embeddings_Train.shape)\n",
    "print(\"XLNET_label_values_Train.shape: \" , XLNET_label_values_Train.shape)\n",
    "\n",
    "print(\"type1_XL_Embeddings_Val.shape: \", type1_XL_Embeddings_Val.shape)\n",
    "print(\"type2_XL_Embeddings_Val.shape: \", type2_XL_Embeddings_Val.shape)\n",
    "print(\"XLNET_label_values_Val.shape: \" , XLNET_label_values_Val.shape)\n",
    "\n",
    "print(\"type1_XL_Embeddings_Test.shape: \", type1_XL_Embeddings_Test.shape)\n",
    "print(\"type2_XL_Embeddings_Test.shape: \", type2_XL_Embeddings_Test.shape)\n",
    "print(\"XLNET_label_values_Test.shape: \" , XLNET_label_values_Test.shape)\n",
    "\n",
    "print(\"SHAPES OF EACH PARTITION _ BERT\\n\")\n",
    "print(\"type1_BERT_Embeddings_Train.: \", type1_BERT_Embeddings_Train)\n",
    "print(\"type2_BERT_Embeddings_Train.: \", type2_BERT_Embeddings_Train)\n",
    "print(\"BERT_label_values_Train.: \"    , BERT_label_values_Train)\n",
    "\n",
    "print(\"type1_BERT_Embeddings_Val.: \", type1_BERT_Embeddings_Val)\n",
    "print(\"type2_BERT_Embeddings_Val.: \", type2_BERT_Embeddings_Val)\n",
    "print(\"BERT_label_values_Val.: \"    , BERT_label_values_Val)\n",
    "\n",
    "print(\"type1_BERT_Embeddings_Test.shape: \", type1_BERT_Embeddings_Test)\n",
    "print(\"type2_BERT_Embeddings_Test.shape: \", type2_BERT_Embeddings_Test)\n",
    "print(\"BERT_label_values_Test.shape: \"    , BERT_label_values_Test)\n",
    "\n",
    "print(\"SHAPES OF EACH PARTITION _ XLNET\\n\")\n",
    "\n",
    "print(\"type1_XL_Embeddings_Train: \", type1_XL_Embeddings_Train)\n",
    "print(\"type2_XL_Embeddings_Train: \", type2_XL_Embeddings_Train)\n",
    "print(\"XLNET_label_values_Train: \" , XLNET_label_values_Train)\n",
    "\n",
    "print(\"type1_XL_Embeddings_Val: \", type1_XL_Embeddings_Val)\n",
    "print(\"type2_XL_Embeddings_Val: \", type2_XL_Embeddings_Val)\n",
    "print(\"XLNET_label_values_Val: \" , XLNET_label_values_Val)\n",
    "\n",
    "print(\"type1_XL_Embeddings_Test: \", type1_XL_Embeddings_Test)\n",
    "print(\"type2_XL_Embeddings_Test: \", type2_XL_Embeddings_Test)\n",
    "print(\"XLNET_label_values_Test: \" , XLNET_label_values_Test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reshape my input\n",
    "def tensor_reshape(input, timestep, features):\n",
    "  reshaped= input.reshape(type1_BERT_Embeddings_Train.shape[0], timestep, features)\n",
    "  return reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STARTING THE MODEL\n",
    "possible combination in inputs:\n",
    "(timestep, features)\n",
    "- (1, 768)\n",
    "- (2, 384)\n",
    "- (3, 256)\n",
    "- (4, 192)\n",
    "- (6, 128)\n",
    "- (12, 64)"
   ]
  },
  {
   "source": [
    "## MODEL (1, 768):\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE =(1,768)\n",
    "EM_L_F_UNITS= 768\n",
    "EM_L_T_UNITS= 768\n",
    "# LEFT CHANNEL\n",
    "LSTM_1F_UNITS= 768\n",
    "LSTM_1T_UNITS= 768\n",
    "\n",
    "CONV_2_FILTER= 24\n",
    "CONV_2_KERNEL= 2\n",
    "CONV_3_FILTER= 24\n",
    "CONV_3_KERNEL= 2\n",
    "CONV_5_FILTER= 24\n",
    "CONV_5_KERNEL= 2\n",
    "CONV_6_FILTER= 24\n",
    "CONV_6_KERNEL= 2\n",
    "CONV_8_FILTER= 24\n",
    "CONV_8_KERNEL= 2\n",
    "\n",
    "# RIGHT CHANNEL \n",
    "CONV_4F_FILTERS = 12\n",
    "CONV_4F_KERNEL = 2\n",
    "CONV_4T_FILTERS = 12\n",
    "CONV_4T_KERNEL = 2\n",
    "\n",
    "CONV_3F_FILTERS = 12\n",
    "CONV_3F_KERNEL = 2\n",
    "CONV_3T_FILTERS = 12\n",
    "CONV_3T_KERNEL = 2\n",
    "\n",
    "CONV_2F_FILTERS = 12\n",
    "CONV_2F_KERNEL = 2\n",
    "CONV_2T_FILTERS = 12\n",
    "CONV_2T_KERNEL = 2\n",
    "\n",
    "LSTM_2_C_L_UNITS = 128\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_layer = Input(shape=INPUT_SHAPE, dtype=\"float32\")\n",
    "embedding_layer_frozen=TimeDistributed(Dense(EM_L_F_UNITS,  trainable= False))(inp_layer)\n",
    "embedding_layer_train= TimeDistributed(Dense(EM_L_T_UNITS,  trainable= True))(inp_layer)\n",
    "print(\"inp_layer\",inp_layer.shape)\n",
    "print(\"embedding_layer_frozen\",embedding_layer_frozen.shape)\n",
    "print(\"embedding_layer_train\",embedding_layer_train.shape)"
   ]
  },
  {
   "source": [
    "### LSTM TO CNN LEFT CHANNEL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### LEFT LSTM PART"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_lstm_1f =Bidirectional(LSTM(LSTM_1F_UNITS, return_sequences=True, dropout=0.3, recurrent_dropout=0.0))(embedding_layer_frozen)\n",
    "l_lstm_1t =Bidirectional(LSTM(LSTM_1T_UNITS, return_sequences=True, dropout=0.3, recurrent_dropout=0.0))(embedding_layer_train)\n",
    "\n",
    "l_lstm1 = Concatenate(axis=1)([l_lstm_1f, l_lstm_1t])\n",
    "print(\"l_lstm_1f\",l_lstm_1f.shape)\n",
    "print(\"l_lstm_1t\",l_lstm_1t.shape)\n",
    "print(\"l_lstm1\",l_lstm1.shape)\n"
   ]
  },
  {
   "source": [
    "### LEFT CNN PART"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l_conv_2 = Conv1D(filters=CONV_2_FILTER, kernel_size=CONV_2_KERNEL, activation='relu')(l_lstm1)\n",
    "l_conv_2 = Dropout(0.3)(l_conv_2)\n",
    "\n",
    "# l_conv_3 = Conv1D(filters=CONV_3_FILTER, kernel_size=CONV_3_KERNEL, activation='relu')(l_lstm1)\n",
    "# l_conv_3 = Dropout(0.3)(l_conv_3)\n",
    "\n",
    "# l_conv_5 = Conv1D(filters=CONV_5_FILTER, kernel_size=CONV_5_KERNEL, activation='relu')(l_lstm1)\n",
    "# l_conv_5 = Dropout(0.3)(l_conv_5)\n",
    "\n",
    "l_conv_6 = Conv1D(filters=CONV_6_FILTER, kernel_size=CONV_6_KERNEL, kernel_regularizer=regularizers.l2(0.001) ,activation='relu')(l_lstm1)\n",
    "l_conv_6 = Dropout(0.3)(l_conv_6)\n",
    "\n",
    "# l_conv_8 = Conv1D(filters=CONV_8_FILTER, kernel_size=CONV_8_KERNEL, kernel_regularizer=regularizers.l2(0.001) ,activation='relu')(l_lstm1)\n",
    "# l_conv_8 = Dropout(0.3)(l_conv_8)\n",
    "\n",
    "# conv_1 =[l_conv_6, l_conv_5, l_conv_8, l_conv_2, l_conv_3 ]\n",
    "conv_1 =[l_conv_6, l_conv_2 ]\n",
    "\n",
    "l_lstm_c = Concatenate(axis =1)(conv_1)\n",
    "print(\"l_conv_2\",l_conv_2.shape)\n",
    "print(\"l_conv_6\",l_conv_6.shape)\n",
    "print(\"l_lstm_c\",l_lstm_c.shape)"
   ]
  },
  {
   "source": [
    "### CNN TO LSTM RIGHT CHANNEL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### RIGHT CNN PART"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN TO LSTM\n",
    "l_conv_4f = Conv1D(filters= CONV_4F_FILTERS, kernel_size=CONV_4F_KERNEL, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(embedding_layer_frozen)\n",
    "l_conv_4f = Dropout(0.3)(l_conv_4f)\n",
    "\n",
    "l_conv_4t = Conv1D(filters= CONV_4T_FILTERS, kernel_size=CONV_4T_KERNEL, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(embedding_layer_train)\n",
    "l_conv_4t = Dropout(0.3)(l_conv_4t)\n",
    "\n",
    "l_conv_3f = Conv1D(filters= CONV_3F_FILTERS, kernel_size=CONV_3F_KERNEL, activation='relu')(embedding_layer_frozen)\n",
    "l_conv_3f = Dropout(0.3)(l_conv_3f)\n",
    "\n",
    "l_conv_3t = Conv1D(filters= CONV_3T_FILTERS, kernel_size=CONV_3T_KERNEL, activation='relu')(embedding_layer_train)\n",
    "l_conv_3t = Dropout(0.3)(l_conv_3t)\n",
    "\n",
    "# l_conv_2f = Conv1D(filters= CONV_2F_FILTERS, kernel_size=CONV_2F_KERNEL, activation='relu')(embedding_layer_frozen)\n",
    "# l_conv_2f = Dropout(0.3)(l_conv_2f)\n",
    "\n",
    "# l_conv_2t = Conv1D(filters= CONV_2T_FILTERS, kernel_size=CONV_2T_KERNEL, activation='relu')(embedding_layer_train)\n",
    "# l_conv_2t = Dropout(0.3)(l_conv_2t)\n",
    "\n",
    "# conv_2 = [l_conv_4f, l_conv_4t, l_conv_3f, l_conv_3t, l_conv_2f, l_conv_2t]\n",
    "conv_2 = [l_conv_4f, l_conv_4t, l_conv_3f, l_conv_3t, ]\n",
    "\n",
    "l_merge_2 = Concatenate(axis=1)(conv_2)\n",
    "print(\"l_conv_4f\",l_conv_4f.shape)\n",
    "print(\"l_conv_4t\",l_conv_4t.shape)\n",
    "print(\"l_conv_3f\",l_conv_3f.shape)\n",
    "print(\"l_conv_3t\",l_conv_3t.shape)\n",
    "print(\"l_merge_2\",l_merge_2.shape)"
   ]
  },
  {
   "source": [
    "### RIGHT LSTM PART"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_c_lstm = Bidirectional(LSTM(LSTM_2_C_L_UNITS, return_sequences=True, dropout=0.3, recurrent_dropout=0.0))(l_merge_2)\n",
    "print(\"l_c_lstm\",l_c_lstm.shape)\n"
   ]
  },
  {
   "source": [
    "###  FINAL CONCAT"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l_merge = Concatenate(axis=1)([l_lstm_c, l_c_lstm])\n",
    "l_pool = MaxPooling1D(4)(l_merge)\n",
    "l_drop = Dropout(0.5)(l_pool)\n",
    "l_flat = Flatten()(l_drop)\n",
    "l_dense = Dense(128, activation='sigmoid')(l_flat)\n",
    "preds= Dense(71, activation='sigmoid')(l_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('LatestTensor': conda)",
   "display_name": "Python 3.7.9 64-bit ('LatestTensor': conda)",
   "metadata": {
    "interpreter": {
     "hash": "0a81886b5eca8297b0be132dcbdde71b7b9ccd4a2b9beb608173c0b9df0b440d"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}