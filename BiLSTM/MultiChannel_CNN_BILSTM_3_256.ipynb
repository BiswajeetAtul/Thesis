{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import prettytable\n",
    "import tensorflow as tf\n",
    "from keras import callbacks, initializers, optimizers, regularizers\n",
    "from keras.layers import (LSTM, Bidirectional, Concatenate, Conv1D, Dense,\n",
    "                          Dropout, Flatten, Input, MaxPooling1D,\n",
    "                          TimeDistributed)\n",
    "from keras.models import Model, Sequential\n",
    "from sklearn.metrics import (accuracy_score, f1_score, hamming_loss,\n",
    "                             precision_recall_curve, precision_score,\n",
    "                             recall_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Tensorboard Extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MultiChannelBiLSTMCNN import BalanceNet, time_logger_save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics Calculator Function\n",
    "def evaluate_model(real, predicted):\n",
    "    accuracy = accuracy_score(real, predicted)\n",
    "    hamLoss = hamming_loss(real, predicted)\n",
    "    # element wise correctness\n",
    "    term_wise_accuracy = np.sum(np.logical_not(\n",
    "        np.logical_xor(real, predicted)))/real.size\n",
    "\n",
    "    macro_precision = precision_score(real, predicted, average='macro')\n",
    "    macro_recall = recall_score(real, predicted, average='macro')\n",
    "    macro_f1 = f1_score(real, predicted, average='macro')\n",
    "\n",
    "    micro_precision = precision_score(real, predicted, average='micro')\n",
    "    micro_recall = recall_score(real, predicted, average='micro')\n",
    "    micro_f1 = f1_score(real, predicted, average='micro')\n",
    "\n",
    "    metricTable = prettytable.PrettyTable()\n",
    "    metricTable.field_names = [\"Metric\", \"Macro Value\", \"Micro Value\"]\n",
    "    metricTable.add_row([\"Hamming Loss\", \"{0:.3f}\".format(hamLoss), \"\"])\n",
    "    metricTable.add_row(\n",
    "        [\"Term Wise Accuracy\", \"{0:.3f}\".format(term_wise_accuracy), \"\"])\n",
    "\n",
    "    metricTable.add_row([\"Accuracy\", \"{0:.3f}\".format(accuracy), \"\"])\n",
    "    metricTable.add_row([\"Precision\", \"{0:.3f}\".format(\n",
    "        macro_precision), \"{0:.3f}\".format(micro_precision)])\n",
    "    metricTable.add_row([\"Recall\", \"{0:.3f}\".format(\n",
    "        macro_recall), \"{0:.3f}\".format(micro_recall)])\n",
    "    metricTable.add_row(\n",
    "        [\"F1-measure\", \"{0:.3f}\".format(macro_f1), \"{0:.3f}\".format(micro_f1)])\n",
    "\n",
    "    print(metricTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "  \n",
    "def initial_boost(epoch):\n",
    "    if epoch==0: return float(8.0)\n",
    "    elif epoch==1: return float(4.0)\n",
    "    elif epoch==2: return float(2.0)\n",
    "    elif epoch==3: return float(1.5)\n",
    "    else: return float(1.0)\n",
    "\n",
    "def step_cyclic(epoch):\n",
    "    try:\n",
    "        l_r, decay = 1.0, 0.0001\n",
    "        if epoch%33==0:multiplier = 10\n",
    "        else:multiplier = 1\n",
    "        rate = float(multiplier * l_r * 1/(1 + decay * epoch))\n",
    "        #print(\"Epoch\",epoch+1,\"- learning_rate\",rate)\n",
    "        return rate\n",
    "    except Exception as e:\n",
    "        print(\"Error in lr_schedule:\",str(e))\n",
    "        return float(1.0)\n"
   ]
  },
  {
   "source": [
    "Loading Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         imdb_id                                          title  \\\n",
       "0      tt0057603                        I tre volti della paura   \n",
       "1      tt1733125  Dungeons & Dragons: The Book of Vile Darkness   \n",
       "2      tt0033045                     The Shop Around the Corner   \n",
       "3      tt0113862                             Mr. Holland's Opus   \n",
       "4      tt0086250                                       Scarface   \n",
       "...          ...                                            ...   \n",
       "14823  tt0219952                                  Lucky Numbers   \n",
       "14824  tt1371159                                     Iron Man 2   \n",
       "14825  tt0063443                                     Play Dirty   \n",
       "14826  tt0039464                                      High Wall   \n",
       "14827  tt0235166                               Against All Hope   \n",
       "\n",
       "                                           plot_synopsis  \\\n",
       "0      Note: this synopsis is for the orginal Italian...   \n",
       "1      Two thousand years ago, Nhagruul the Foul, a s...   \n",
       "2      Matuschek's, a gift store in Budapest, is the ...   \n",
       "3      Glenn Holland, not a morning person by anyone'...   \n",
       "4      In May 1980, a Cuban man named Tony Montana (A...   \n",
       "...                                                  ...   \n",
       "14823  In 1988 Russ Richards (John Travolta), the wea...   \n",
       "14824  In Russia, the media covers Tony Stark's discl...   \n",
       "14825  During the North African Campaign in World War...   \n",
       "14826  Steven Kenet catches his unfaithful wife in th...   \n",
       "14827  Sometime in the 1950s in Chicago a man, Cecil ...   \n",
       "\n",
       "                                                    tags  split  \\\n",
       "0              cult, horror, gothic, murder, atmospheric  train   \n",
       "1                                               violence  train   \n",
       "2                                               romantic   test   \n",
       "3                 inspiring, romantic, stupid, feel-good  train   \n",
       "4      cruelty, murder, dramatic, cult, violence, atm...    val   \n",
       "...                                                  ...    ...   \n",
       "14823                                     comedy, murder   test   \n",
       "14824                         good versus evil, violence  train   \n",
       "14825                                           anti war  train   \n",
       "14826                                             murder   test   \n",
       "14827                                     christian film   test   \n",
       "\n",
       "      synopsis_source  \n",
       "0                imdb  \n",
       "1                imdb  \n",
       "2                imdb  \n",
       "3                imdb  \n",
       "4                imdb  \n",
       "...               ...  \n",
       "14823       wikipedia  \n",
       "14824       wikipedia  \n",
       "14825       wikipedia  \n",
       "14826       wikipedia  \n",
       "14827       wikipedia  \n",
       "\n",
       "[14828 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>imdb_id</th>\n      <th>title</th>\n      <th>plot_synopsis</th>\n      <th>tags</th>\n      <th>split</th>\n      <th>synopsis_source</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>tt0057603</td>\n      <td>I tre volti della paura</td>\n      <td>Note: this synopsis is for the orginal Italian...</td>\n      <td>cult, horror, gothic, murder, atmospheric</td>\n      <td>train</td>\n      <td>imdb</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>tt1733125</td>\n      <td>Dungeons &amp; Dragons: The Book of Vile Darkness</td>\n      <td>Two thousand years ago, Nhagruul the Foul, a s...</td>\n      <td>violence</td>\n      <td>train</td>\n      <td>imdb</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tt0033045</td>\n      <td>The Shop Around the Corner</td>\n      <td>Matuschek's, a gift store in Budapest, is the ...</td>\n      <td>romantic</td>\n      <td>test</td>\n      <td>imdb</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tt0113862</td>\n      <td>Mr. Holland's Opus</td>\n      <td>Glenn Holland, not a morning person by anyone'...</td>\n      <td>inspiring, romantic, stupid, feel-good</td>\n      <td>train</td>\n      <td>imdb</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tt0086250</td>\n      <td>Scarface</td>\n      <td>In May 1980, a Cuban man named Tony Montana (A...</td>\n      <td>cruelty, murder, dramatic, cult, violence, atm...</td>\n      <td>val</td>\n      <td>imdb</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14823</th>\n      <td>tt0219952</td>\n      <td>Lucky Numbers</td>\n      <td>In 1988 Russ Richards (John Travolta), the wea...</td>\n      <td>comedy, murder</td>\n      <td>test</td>\n      <td>wikipedia</td>\n    </tr>\n    <tr>\n      <th>14824</th>\n      <td>tt1371159</td>\n      <td>Iron Man 2</td>\n      <td>In Russia, the media covers Tony Stark's discl...</td>\n      <td>good versus evil, violence</td>\n      <td>train</td>\n      <td>wikipedia</td>\n    </tr>\n    <tr>\n      <th>14825</th>\n      <td>tt0063443</td>\n      <td>Play Dirty</td>\n      <td>During the North African Campaign in World War...</td>\n      <td>anti war</td>\n      <td>train</td>\n      <td>wikipedia</td>\n    </tr>\n    <tr>\n      <th>14826</th>\n      <td>tt0039464</td>\n      <td>High Wall</td>\n      <td>Steven Kenet catches his unfaithful wife in th...</td>\n      <td>murder</td>\n      <td>test</td>\n      <td>wikipedia</td>\n    </tr>\n    <tr>\n      <th>14827</th>\n      <td>tt0235166</td>\n      <td>Against All Hope</td>\n      <td>Sometime in the 1950s in Chicago a man, Cecil ...</td>\n      <td>christian film</td>\n      <td>test</td>\n      <td>wikipedia</td>\n    </tr>\n  </tbody>\n</table>\n<p>14828 rows × 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "mpstDF= pd.read_csv(\"mpst.csv\")\n",
    "mpstDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Split Function\n",
    "def get_partition_Embeddings(x_t1,x_t2,y,df,partition_nm):\n",
    "    _df=df[df[\"split\"]==partition_nm]\n",
    "    index_list=list(_df.index)\n",
    "    temp_array_x_t1=[]\n",
    "    temp_array_x_t2=[]\n",
    "    temp_array_y=[]\n",
    "    for index in index_list:\n",
    "        temp_array_x_t1.append(x_t1[index,:])\n",
    "        temp_array_x_t2.append(x_t2[index,:])\n",
    "        temp_array_y.append(y[index,:])\n",
    "    temp_array_x_t1=np.array(temp_array_x_t1)\n",
    "    temp_array_x_t2=np.array(temp_array_x_t2)\n",
    "    temp_array_y=np.array(temp_array_y)\n",
    "    return temp_array_x_t1,temp_array_x_t2, temp_array_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING BERT  EMBEDDINGS\n",
    "bert_embedding=np.load(r\"D:\\CodeRepo\\Thesis\\Thesis\\XLNet\\xl_embeddings.npz\")\n",
    "# LOADING XLnet EMBEDDINGS\n",
    "xl_embedding=np.load(r\"D:\\CodeRepo\\Thesis\\Thesis\\XLNet\\xl_embeddings.npz\")\n",
    "# LOADING LABELS Y\n",
    "label_values=np.load(r\"D:\\CodeRepo\\Thesis\\Thesis\\EDA\\Y.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT EMBEDDINGS T1 & T2\n",
    "type1_BERT_Embeddings=bert_embedding[\"t1\"]\n",
    "type2_BERT_Embeddings=bert_embedding[\"t2\"]\n",
    "# XLNet EMBEDDINGS T1 & T2\n",
    "type1_XL_Embeddings=xl_embedding[\"t1\"]\n",
    "type2_XL_Embeddings=xl_embedding[\"t2\"]\n",
    "# LABLES Y\n",
    "label_values=label_values[\"arr_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT\n",
    "\n",
    "# FOR TRAIN\n",
    "type1_BERT_Embeddings_Train,type2_BERT_Embeddings_Train,BERT_label_values_Train=get_partition_Embeddings(type1_BERT_Embeddings,type2_BERT_Embeddings,label_values,mpstDF,\"train\")\n",
    "# FOR VALIDATION\n",
    "type1_BERT_Embeddings_Val,type2_BERT_Embeddings_Val,BERT_label_values_Val=get_partition_Embeddings(type1_BERT_Embeddings,type2_BERT_Embeddings,label_values,mpstDF,\"val\")\n",
    "# FOR TEST\n",
    "type1_BERT_Embeddings_Test,type2_BERT_Embeddings_Test,BERT_label_values_Test=get_partition_Embeddings(type1_BERT_Embeddings,type2_BERT_Embeddings,label_values,mpstDF,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XLNET\n",
    "\n",
    "# FOR TRAIN\n",
    "type1_XL_Embeddings_Train,type2_XL_Embeddings_Train,XLNET_label_values_Train=get_partition_Embeddings(type1_XL_Embeddings,type2_XL_Embeddings,label_values,mpstDF,\"train\")\n",
    "# FOR VALIDATION\n",
    "type1_XL_Embeddings_Val,type2_XL_Embeddings_Val,XLNET_label_values_Val=get_partition_Embeddings(type1_XL_Embeddings,type2_XL_Embeddings,label_values,mpstDF,\"val\")\n",
    "# FOR TEST\n",
    "type1_XL_Embeddings_Test,type2_XL_Embeddings_Test,XLNET_label_values_Test=get_partition_Embeddings(type1_XL_Embeddings,type2_XL_Embeddings,label_values,mpstDF,\"test\")"
   ]
  },
  {
   "source": [
    "HAVING A LOOK AT THE SHAPES OF EACH PARTITION CREATED:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SHAPES OF EACH PARTITION _ BERT\n\ntype1_BERT_Embeddings_Train.shape:  (9489, 768)\ntype2_BERT_Embeddings_Train.shape:  (9489, 768)\nBERT_label_values_Train.shape:  (9489, 71)\ntype1_BERT_Embeddings_Val.shape:  (2373, 768)\ntype2_BERT_Embeddings_Val.shape:  (2373, 768)\nBERT_label_values_Val.shape:  (2373, 71)\ntype1_BERT_Embeddings_Test.shape:  (2966, 768)\ntype2_BERT_Embeddings_Test.shape:  (2966, 768)\nBERT_label_values_Test.shape:  (2966, 71)\nSHAPES OF EACH PARTITION _ XLNET\n\ntype1_XL_Embeddings_Train.shape:  (9489, 768)\ntype2_XL_Embeddings_Train.shape:  (9489, 768)\nXLNET_label_values_Train.shape:  (9489, 71)\ntype1_XL_Embeddings_Val.shape:  (2373, 768)\ntype2_XL_Embeddings_Val.shape:  (2373, 768)\nXLNET_label_values_Val.shape:  (2373, 71)\ntype1_XL_Embeddings_Test.shape:  (2966, 768)\ntype2_XL_Embeddings_Test.shape:  (2966, 768)\nXLNET_label_values_Test.shape:  (2966, 71)\nSHAPES OF EACH PARTITION _ BERT\n\ntype1_BERT_Embeddings_Train.:  [[-2.333117    0.7328038   0.04426328 ... -0.08736744 -0.7796799\n   0.91549385]\n [-0.68435717  0.20561107  1.0846754  ... -0.5544154   1.3279868\n  -0.5279333 ]\n [-0.8616366  -0.07106075 -1.6272864  ...  0.43291882 -1.1531446\n   0.96043503]\n ...\n [ 0.13103236 -1.8318506  -1.6702073  ...  0.48938644 -1.1472857\n   0.73014414]\n [-2.1046846   0.9153419   0.45613348 ...  0.35717207 -0.38135093\n   0.65046066]\n [-2.0119467  -0.61891806 -0.2853785  ...  1.3546127   0.17829654\n  -0.32963297]]\ntype2_BERT_Embeddings_Train.:  [[-1.1041279   0.7312169  -0.7160296  ... -1.1096342   0.02258597\n  -0.22847919]\n [-0.6814843   0.40997314 -0.00450579 ... -0.7261082   0.871102\n   0.28894395]\n [-0.880342   -0.31377012 -0.87731165 ... -0.47135696 -0.25688243\n   0.8662912 ]\n ...\n [-0.74574816 -0.36092088 -1.2522244  ... -0.19444613 -0.00248033\n   0.84975207]\n [-1.6853124   0.982764    0.45230147 ...  0.00419476  0.09003887\n   1.2138213 ]\n [-1.0978851  -0.07546298 -0.09644943 ...  0.35488805  0.1416101\n   1.1022444 ]]\nBERT_label_values_Train.:  [[0 0 0 ... 0 0 0]\n [0 0 0 ... 1 0 0]\n [0 0 0 ... 0 0 0]\n ...\n [0 0 0 ... 1 0 0]\n [0 0 0 ... 1 0 0]\n [0 0 0 ... 0 0 0]]\ntype1_BERT_Embeddings_Val.:  [[-1.724195   -0.18644059 -1.3847002  ... -0.24220115 -0.47373167\n   0.17687573]\n [-1.7328922  -0.75544524 -1.3409745  ... -0.73608744 -0.47683832\n   0.9812624 ]\n [-0.4690799  -0.7823237  -0.89326704 ... -0.6372853  -0.42456573\n  -0.3892136 ]\n ...\n [-2.047429    0.84689385 -1.6092843  ...  0.47031114  0.6824576\n  -2.0910456 ]\n [-2.1610858  -0.42343566  0.0896145  ...  0.08766028  0.6301933\n  -1.5156782 ]\n [-1.2949383  -0.45608175 -0.9925543  ... -0.5866869   0.08331414\n   0.31308964]]\ntype2_BERT_Embeddings_Val.:  [[-1.4168882   0.15406662 -1.7007791  ... -0.12171233 -0.13148104\n  -0.5208332 ]\n [-0.33846205 -0.2642498  -1.1163353  ... -0.8021653  -0.563\n   0.72895736]\n [-0.85696316 -0.67706174 -1.1916689  ... -0.65651685 -0.5815179\n   1.0469415 ]\n ...\n [-1.0883361   1.1182543  -0.11477457 ... -0.95007193 -0.9402632\n  -1.0461214 ]\n [-2.4710774   0.04263473 -0.8014267  ... -0.51679814  0.9243769\n  -0.9391736 ]\n [-0.33632323  0.23742555 -0.89315057 ... -0.90124476 -0.06967218\n  -0.1662782 ]]\nBERT_label_values_Val.:  [[0 1 0 ... 1 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n ...\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 1 0 0]\n [0 0 0 ... 0 0 0]]\ntype1_BERT_Embeddings_Test.shape:  [[-1.9809484  -0.6992686  -0.91347814 ...  0.7089055   0.11894006\n   0.4480172 ]\n [-0.84975183 -0.538029   -1.391866   ...  0.47141784 -0.7222437\n  -0.06520037]\n [-2.6995983  -1.0260197  -0.6370995  ... -0.67485505  0.34770787\n  -0.80995077]\n ...\n [-2.499969   -0.24800475 -0.38243118 ...  0.500359    0.17817856\n   0.63274205]\n [-1.9518135   0.0488037  -1.7838176  ...  0.37025616 -0.43593258\n   0.49770826]\n [-0.53094137 -0.5506314   0.09211962 ... -0.5106418   1.4054636\n  -0.46292305]]\ntype2_BERT_Embeddings_Test.shape:  [[-1.5265968  -0.2902775  -0.6303203  ... -0.4950492   0.20074049\n   0.84848535]\n [-1.1269717   0.40846175 -0.01210781 ...  0.2974643  -0.21717305\n  -0.43774125]\n [-1.6852893  -0.33794993 -1.1118177  ... -0.8046879  -0.24153566\n   0.53618044]\n ...\n [-1.054332    0.25229695 -0.7077129  ... -0.33052695  0.41456184\n   0.72335166]\n [-1.1982068   1.1937346  -0.8980867  ... -0.77720964 -1.092974\n  -0.07756492]\n [-0.00220318  0.16499077 -1.3319939  ... -0.99019504 -0.71211934\n  -0.1459935 ]]\nBERT_label_values_Test.shape:  [[0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n ...\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]]\nSHAPES OF EACH PARTITION _ XLNET\n\ntype1_XL_Embeddings_Train:  [[-2.333117    0.7328038   0.04426328 ... -0.08736744 -0.7796799\n   0.91549385]\n [-0.68435717  0.20561107  1.0846754  ... -0.5544154   1.3279868\n  -0.5279333 ]\n [-0.8616366  -0.07106075 -1.6272864  ...  0.43291882 -1.1531446\n   0.96043503]\n ...\n [ 0.13103236 -1.8318506  -1.6702073  ...  0.48938644 -1.1472857\n   0.73014414]\n [-2.1046846   0.9153419   0.45613348 ...  0.35717207 -0.38135093\n   0.65046066]\n [-2.0119467  -0.61891806 -0.2853785  ...  1.3546127   0.17829654\n  -0.32963297]]\ntype2_XL_Embeddings_Train:  [[-1.1041279   0.7312169  -0.7160296  ... -1.1096342   0.02258597\n  -0.22847919]\n [-0.6814843   0.40997314 -0.00450579 ... -0.7261082   0.871102\n   0.28894395]\n [-0.880342   -0.31377012 -0.87731165 ... -0.47135696 -0.25688243\n   0.8662912 ]\n ...\n [-0.74574816 -0.36092088 -1.2522244  ... -0.19444613 -0.00248033\n   0.84975207]\n [-1.6853124   0.982764    0.45230147 ...  0.00419476  0.09003887\n   1.2138213 ]\n [-1.0978851  -0.07546298 -0.09644943 ...  0.35488805  0.1416101\n   1.1022444 ]]\nXLNET_label_values_Train:  [[0 0 0 ... 0 0 0]\n [0 0 0 ... 1 0 0]\n [0 0 0 ... 0 0 0]\n ...\n [0 0 0 ... 1 0 0]\n [0 0 0 ... 1 0 0]\n [0 0 0 ... 0 0 0]]\ntype1_XL_Embeddings_Val:  [[-1.724195   -0.18644059 -1.3847002  ... -0.24220115 -0.47373167\n   0.17687573]\n [-1.7328922  -0.75544524 -1.3409745  ... -0.73608744 -0.47683832\n   0.9812624 ]\n [-0.4690799  -0.7823237  -0.89326704 ... -0.6372853  -0.42456573\n  -0.3892136 ]\n ...\n [-2.047429    0.84689385 -1.6092843  ...  0.47031114  0.6824576\n  -2.0910456 ]\n [-2.1610858  -0.42343566  0.0896145  ...  0.08766028  0.6301933\n  -1.5156782 ]\n [-1.2949383  -0.45608175 -0.9925543  ... -0.5866869   0.08331414\n   0.31308964]]\ntype2_XL_Embeddings_Val:  [[-1.4168882   0.15406662 -1.7007791  ... -0.12171233 -0.13148104\n  -0.5208332 ]\n [-0.33846205 -0.2642498  -1.1163353  ... -0.8021653  -0.563\n   0.72895736]\n [-0.85696316 -0.67706174 -1.1916689  ... -0.65651685 -0.5815179\n   1.0469415 ]\n ...\n [-1.0883361   1.1182543  -0.11477457 ... -0.95007193 -0.9402632\n  -1.0461214 ]\n [-2.4710774   0.04263473 -0.8014267  ... -0.51679814  0.9243769\n  -0.9391736 ]\n [-0.33632323  0.23742555 -0.89315057 ... -0.90124476 -0.06967218\n  -0.1662782 ]]\nXLNET_label_values_Val:  [[0 1 0 ... 1 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n ...\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 1 0 0]\n [0 0 0 ... 0 0 0]]\ntype1_XL_Embeddings_Test:  [[-1.9809484  -0.6992686  -0.91347814 ...  0.7089055   0.11894006\n   0.4480172 ]\n [-0.84975183 -0.538029   -1.391866   ...  0.47141784 -0.7222437\n  -0.06520037]\n [-2.6995983  -1.0260197  -0.6370995  ... -0.67485505  0.34770787\n  -0.80995077]\n ...\n [-2.499969   -0.24800475 -0.38243118 ...  0.500359    0.17817856\n   0.63274205]\n [-1.9518135   0.0488037  -1.7838176  ...  0.37025616 -0.43593258\n   0.49770826]\n [-0.53094137 -0.5506314   0.09211962 ... -0.5106418   1.4054636\n  -0.46292305]]\ntype2_XL_Embeddings_Test:  [[-1.5265968  -0.2902775  -0.6303203  ... -0.4950492   0.20074049\n   0.84848535]\n [-1.1269717   0.40846175 -0.01210781 ...  0.2974643  -0.21717305\n  -0.43774125]\n [-1.6852893  -0.33794993 -1.1118177  ... -0.8046879  -0.24153566\n   0.53618044]\n ...\n [-1.054332    0.25229695 -0.7077129  ... -0.33052695  0.41456184\n   0.72335166]\n [-1.1982068   1.1937346  -0.8980867  ... -0.77720964 -1.092974\n  -0.07756492]\n [-0.00220318  0.16499077 -1.3319939  ... -0.99019504 -0.71211934\n  -0.1459935 ]]\nXLNET_label_values_Test:  [[0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n ...\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]\n [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(\"SHAPES OF EACH PARTITION _ BERT\\n\")\n",
    "print(\"type1_BERT_Embeddings_Train.shape: \", type1_BERT_Embeddings_Train.shape)\n",
    "print(\"type2_BERT_Embeddings_Train.shape: \", type2_BERT_Embeddings_Train.shape)\n",
    "print(\"BERT_label_values_Train.shape: \"    , BERT_label_values_Train.shape)\n",
    "\n",
    "print(\"type1_BERT_Embeddings_Val.shape: \", type1_BERT_Embeddings_Val.shape)\n",
    "print(\"type2_BERT_Embeddings_Val.shape: \", type2_BERT_Embeddings_Val.shape)\n",
    "print(\"BERT_label_values_Val.shape: \"    , BERT_label_values_Val.shape)\n",
    "\n",
    "print(\"type1_BERT_Embeddings_Test.shape: \", type1_BERT_Embeddings_Test.shape)\n",
    "print(\"type2_BERT_Embeddings_Test.shape: \", type2_BERT_Embeddings_Test.shape)\n",
    "print(\"BERT_label_values_Test.shape: \"    , BERT_label_values_Test.shape)\n",
    "\n",
    "print(\"SHAPES OF EACH PARTITION _ XLNET\\n\")\n",
    "\n",
    "print(\"type1_XL_Embeddings_Train.shape: \", type1_XL_Embeddings_Train.shape)\n",
    "print(\"type2_XL_Embeddings_Train.shape: \", type2_XL_Embeddings_Train.shape)\n",
    "print(\"XLNET_label_values_Train.shape: \" , XLNET_label_values_Train.shape)\n",
    "\n",
    "print(\"type1_XL_Embeddings_Val.shape: \", type1_XL_Embeddings_Val.shape)\n",
    "print(\"type2_XL_Embeddings_Val.shape: \", type2_XL_Embeddings_Val.shape)\n",
    "print(\"XLNET_label_values_Val.shape: \" , XLNET_label_values_Val.shape)\n",
    "\n",
    "print(\"type1_XL_Embeddings_Test.shape: \", type1_XL_Embeddings_Test.shape)\n",
    "print(\"type2_XL_Embeddings_Test.shape: \", type2_XL_Embeddings_Test.shape)\n",
    "print(\"XLNET_label_values_Test.shape: \" , XLNET_label_values_Test.shape)\n",
    "\n",
    "print(\"SHAPES OF EACH PARTITION _ BERT\\n\")\n",
    "print(\"type1_BERT_Embeddings_Train.: \", type1_BERT_Embeddings_Train)\n",
    "print(\"type2_BERT_Embeddings_Train.: \", type2_BERT_Embeddings_Train)\n",
    "print(\"BERT_label_values_Train.: \"    , BERT_label_values_Train)\n",
    "\n",
    "print(\"type1_BERT_Embeddings_Val.: \", type1_BERT_Embeddings_Val)\n",
    "print(\"type2_BERT_Embeddings_Val.: \", type2_BERT_Embeddings_Val)\n",
    "print(\"BERT_label_values_Val.: \"    , BERT_label_values_Val)\n",
    "\n",
    "print(\"type1_BERT_Embeddings_Test.shape: \", type1_BERT_Embeddings_Test)\n",
    "print(\"type2_BERT_Embeddings_Test.shape: \", type2_BERT_Embeddings_Test)\n",
    "print(\"BERT_label_values_Test.shape: \"    , BERT_label_values_Test)\n",
    "\n",
    "print(\"SHAPES OF EACH PARTITION _ XLNET\\n\")\n",
    "\n",
    "print(\"type1_XL_Embeddings_Train: \", type1_XL_Embeddings_Train)\n",
    "print(\"type2_XL_Embeddings_Train: \", type2_XL_Embeddings_Train)\n",
    "print(\"XLNET_label_values_Train: \" , XLNET_label_values_Train)\n",
    "\n",
    "print(\"type1_XL_Embeddings_Val: \", type1_XL_Embeddings_Val)\n",
    "print(\"type2_XL_Embeddings_Val: \", type2_XL_Embeddings_Val)\n",
    "print(\"XLNET_label_values_Val: \" , XLNET_label_values_Val)\n",
    "\n",
    "print(\"type1_XL_Embeddings_Test: \", type1_XL_Embeddings_Test)\n",
    "print(\"type2_XL_Embeddings_Test: \", type2_XL_Embeddings_Test)\n",
    "print(\"XLNET_label_values_Test: \" , XLNET_label_values_Test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reshape my input\n",
    "def tensor_reshape(input, timestep, features):\n",
    "  reshaped= input.reshape(type1_BERT_Embeddings_Train.shape[0], timestep, features)\n",
    "  return reshaped"
   ]
  },
  {
   "source": [
    "STARTING THE MODEL\n",
    "possible combination in inputs:\n",
    "(timestep, features)\n",
    "- (1, 768)\n",
    "- (2, 384)\n",
    "- (3, 256)\n",
    "- (4, 192)\n",
    "- (6, 128)\n",
    "- (12, 64)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## MODEL (3, 256):\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE =(3, 256)\n",
    "EM_L_F_UNITS= 256\n",
    "EM_L_T_UNITS= 256\n",
    "# LEFT CHANNEL\n",
    "LSTM_1F_UNITS= 256\n",
    "LSTM_1T_UNITS= 256\n",
    "\n",
    "CONV_2_FILTER= 64\n",
    "CONV_2_KERNEL= 2\n",
    "CONV_3_FILTER= 64\n",
    "CONV_3_KERNEL= 3\n",
    "CONV_5_FILTER= 64\n",
    "CONV_5_KERNEL= 4\n",
    "CONV_6_FILTER= 64\n",
    "CONV_6_KERNEL= 5\n",
    "CONV_8_FILTER= 64\n",
    "CONV_8_KERNEL= 6\n",
    "\n",
    "# RIGHT CHANNEL \n",
    "CONV_4F_FILTERS = 64\n",
    "CONV_4F_KERNEL = 3\n",
    "CONV_4T_FILTERS = 64\n",
    "CONV_4T_KERNEL = 3\n",
    "\n",
    "CONV_3F_FILTERS = 64\n",
    "CONV_3F_KERNEL = 3\n",
    "CONV_3T_FILTERS = 64\n",
    "CONV_3T_KERNEL = 3\n",
    "\n",
    "CONV_2F_FILTERS = 64\n",
    "CONV_2F_KERNEL = 3\n",
    "CONV_2T_FILTERS = 64\n",
    "CONV_2T_KERNEL = 3\n",
    "\n",
    "LSTM_2_C_L_UNITS = 32\n",
    "\n",
    "OUTPUT_DENSE_UNIT =128\n",
    "OUTPUT_SIZE =71\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_list = ['adam']\n",
    "dataset_X={\n",
    "    \"bert_t1\":[\n",
    "        type1_BERT_Embeddings_Train,\n",
    "        type1_BERT_Embeddings_Val,\n",
    "        type1_BERT_Embeddings_Test\n",
    "        ],\n",
    "    \"bert_t2\":[\n",
    "        type2_BERT_Embeddings_Train,\n",
    "        type2_BERT_Embeddings_Val,\n",
    "        type2_BERT_Embeddings_Test\n",
    "        ],\n",
    "    \"xlnet_t1\":[\n",
    "        type1_XL_Embeddings_Train,\n",
    "        type1_XL_Embeddings_Val,\n",
    "        type1_XL_Embeddings_Test\n",
    "        ],\n",
    "    \"xlnet_t2\":[\n",
    "        type2_XL_Embeddings_Train,\n",
    "        type2_XL_Embeddings_Val,\n",
    "        type2_XL_Embeddings_Test\n",
    "    ]\n",
    "}\n",
    "dataset_Y ={\n",
    "    \"bert\":[\n",
    "        BERT_label_values_Train,\n",
    "        BERT_label_values_Val,\n",
    "        BERT_label_values_Test\n",
    "        ],\n",
    "    \"xlnet\":[\n",
    "        XLNET_label_values_Train,\n",
    "        XLNET_label_values_Val,\n",
    "        XLNET_label_values_Test\n",
    "        ]\n",
    "}\n",
    "\n",
    "inp_shape_str = \"3_256\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "FOR DATASET:  bert_t1\n",
      "FOR OPTIMIZER:  adam\n",
      "\n",
      "###############\n",
      "KEY= model_3_256_adam_bert_t1\n",
      "#############\n",
      "\n",
      "###############\n",
      "model_type= bert_t1_adam\n",
      "#############\n",
      "inp_layer (None, 3, 256)\n",
      "embedding_layer_frozen (None, 3, 256)\n",
      "embedding_layer_train (None, 3, 256)\n",
      "l_lstm_1f (None, 3, 512)\n",
      "l_lstm_1t (None, 3, 512)\n",
      "l_lstm1 (None, 6, 512)\n",
      "l_conv_2 (None, 5, 64)\n",
      "l_conv_3 (None, 4, 64)\n",
      "l_conv_5 (None, 3, 64)\n",
      "l_conv_6 (None, 2, 64)\n",
      "l_conv_8 (None, 1, 64)\n",
      "l_lstm_c (None, 15, 64)\n",
      "l_conv_4f (None, 1, 64)\n",
      "l_conv_4t (None, 1, 64)\n",
      "l_conv_3f (None, 1, 64)\n",
      "l_conv_3t (None, 1, 64)\n",
      "l_conv_2f (None, 1, 64)\n",
      "l_conv_2t (None, 1, 64)\n",
      "l_merge_2 (None, 6, 64)\n",
      "l_c_lstm (None, 6, 64)\n",
      "Training Progress for: bert_t1_adam\n",
      "Reshaping inputs\n",
      "Reshaped Into Shape:  (9489, 3, 256)\n",
      "Reshaped Into Shape:  (2373, 3, 256)\n",
      "Reshaped Successfully!\n",
      "Train on 9489 samples, validate on 2373 samples\n",
      "Epoch 1/20\n",
      "9489/9489 [==============================] - 11s 1ms/step - loss: 10.6528 - acc: 0.0424 - categorical_accuracy: 0.0424 - top_k_categorical_accuracy: 0.4069 - precision: 0.1758 - recall: 0.5788 - true_positives: 8032.7046 - true_negatives: 291650.5312 - false_positives: 34958.0664 - false_negatives: 6136.2417 - val_loss: 10.7638 - val_acc: 0.0367 - val_categorical_accuracy: 0.0367 - val_top_k_categorical_accuracy: 0.4412 - val_precision: 0.2037 - val_recall: 0.5469 - val_true_positives: 17687.3691 - val_true_negatives: 660758.9375 - val_false_positives: 69108.7656 - val_false_negatives: 14661.7109\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.03666, saving model to logs/save/best_model_3_256_2020_10_25_19_50_40_bert_t1_adam.h5\n",
      "Epoch 2/20\n",
      "9489/9489 [==============================] - 5s 539us/step - loss: 10.5346 - acc: 0.0813 - categorical_accuracy: 0.0813 - top_k_categorical_accuracy: 0.3951 - precision: 0.2075 - recall: 0.5402 - true_positives: 26662.9062 - true_negatives: 1031901.6250 - false_positives: 101632.9609 - false_negatives: 22782.0605 - val_loss: 10.7269 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.3801 - val_precision: 0.2128 - val_recall: 0.5266 - val_true_positives: 35558.7617 - val_true_negatives: 1405353.6250 - val_false_positives: 131531.9219 - val_false_negatives: 31974.3164\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.03666 to 0.15339, saving model to logs/save/best_model_3_256_2020_10_25_19_50_40_bert_t1_adam.h5\n",
      "Epoch 3/20\n",
      "9489/9489 [==============================] - 5s 540us/step - loss: 10.5494 - acc: 0.1442 - categorical_accuracy: 0.1442 - top_k_categorical_accuracy: 0.4013 - precision: 0.2137 - recall: 0.5247 - true_positives: 44263.3633 - true_negatives: 1778003.6250 - false_positives: 162804.3281 - false_negatives: 40110.3086 - val_loss: 10.8785 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.4412 - val_precision: 0.2167 - val_recall: 0.5180 - val_true_positives: 53203.9727 - val_true_negatives: 2151540.5000 - val_false_positives: 192363.2656 - val_false_negatives: 49513.1055\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.15339\n",
      "Epoch 4/20\n",
      "9489/9489 [==============================] - 5s 534us/step - loss: 10.6016 - acc: 0.1066 - categorical_accuracy: 0.1066 - top_k_categorical_accuracy: 0.4049 - precision: 0.2172 - recall: 0.5151 - true_positives: 61646.3945 - true_negatives: 2525501.7500 - false_positives: 222188.0469 - false_negatives: 58046.6172 - val_loss: 10.8171 - val_acc: 0.0603 - val_categorical_accuracy: 0.0603 - val_top_k_categorical_accuracy: 0.3552 - val_precision: 0.2186 - val_recall: 0.5125 - val_true_positives: 70679.7656 - val_true_negatives: 2898238.5000 - val_false_positives: 252682.9219 - val_false_negatives: 67221.3125\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.15339\n",
      "Epoch 5/20\n",
      "9489/9489 [==============================] - 5s 546us/step - loss: 10.6082 - acc: 0.0555 - categorical_accuracy: 0.0555 - top_k_categorical_accuracy: 0.3902 - precision: 0.2176 - recall: 0.5147 - true_positives: 79720.1016 - true_negatives: 3268056.0000 - false_positives: 286674.1562 - false_negatives: 75134.9297 - val_loss: 10.8393 - val_acc: 0.0603 - val_categorical_accuracy: 0.0603 - val_top_k_categorical_accuracy: 0.3801 - val_precision: 0.2181 - val_recall: 0.5164 - val_true_positives: 89384.3672 - val_true_negatives: 3637466.5000 - val_false_positives: 320472.7500 - val_false_negatives: 83700.7109\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.15339\n",
      "Epoch 6/20\n",
      "9489/9489 [==============================] - 5s 533us/step - loss: 10.6122 - acc: 0.0660 - categorical_accuracy: 0.0660 - top_k_categorical_accuracy: 0.4070 - precision: 0.2177 - recall: 0.5175 - true_positives: 98369.3438 - true_negatives: 4008253.7500 - false_positives: 353456.8750 - false_negatives: 91706.7734 - val_loss: 10.9055 - val_acc: 0.0598 - val_categorical_accuracy: 0.0598 - val_top_k_categorical_accuracy: 0.4395 - val_precision: 0.2180 - val_recall: 0.5182 - val_true_positives: 107927.5781 - val_true_negatives: 4377777.5000 - val_false_positives: 387181.0000 - val_false_negatives: 100341.5000\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.15339\n",
      "Epoch 7/20\n",
      "9489/9489 [==============================] - 5s 532us/step - loss: 10.6265 - acc: 0.1251 - categorical_accuracy: 0.1251 - top_k_categorical_accuracy: 0.4083 - precision: 0.2173 - recall: 0.5201 - true_positives: 117191.6250 - true_negatives: 4746545.5000 - false_positives: 422133.4375 - false_negatives: 108119.2578 - val_loss: 10.7742 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.3801 - val_precision: 0.2178 - val_recall: 0.5192 - val_true_positives: 126389.7656 - val_true_negatives: 5118113.5000 - val_false_positives: 453862.9375 - val_false_negatives: 117063.3125\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.15339\n",
      "Epoch 8/20\n",
      "9489/9489 [==============================] - 5s 538us/step - loss: 10.5785 - acc: 0.1445 - categorical_accuracy: 0.1445 - top_k_categorical_accuracy: 0.4059 - precision: 0.2177 - recall: 0.5191 - true_positives: 135151.1719 - true_negatives: 5490337.5000 - false_positives: 485525.5938 - false_negatives: 125177.7188 - val_loss: 10.8259 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.4412 - val_precision: 0.2177 - val_recall: 0.5199 - val_true_positives: 144873.8125 - val_true_negatives: 5858356.0000 - val_false_positives: 520637.1562 - val_false_negatives: 133763.2656\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.15339\n",
      "Epoch 9/20\n",
      "9489/9489 [==============================] - 5s 534us/step - loss: 10.5681 - acc: 0.1445 - categorical_accuracy: 0.1445 - top_k_categorical_accuracy: 0.4083 - precision: 0.2169 - recall: 0.5212 - true_positives: 154067.3281 - true_negatives: 6226682.0000 - false_positives: 556102.7500 - false_negatives: 141542.3125 - val_loss: 10.8337 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.3721 - val_precision: 0.2172 - val_recall: 0.5217 - val_true_positives: 163729.5781 - val_true_negatives: 6595955.0000 - val_false_positives: 590057.0625 - val_false_negatives: 150091.5000\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.15339\n",
      "Epoch 10/20\n",
      "9489/9489 [==============================] - 5s 534us/step - loss: 10.5543 - acc: 0.1445 - categorical_accuracy: 0.1445 - top_k_categorical_accuracy: 0.3996 - precision: 0.2170 - recall: 0.5220 - true_positives: 172669.3594 - true_negatives: 6966798.0000 - false_positives: 623038.0625 - false_negatives: 158089.3906 - val_loss: 10.7731 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.3801 - val_precision: 0.2177 - val_recall: 0.5210 - val_true_positives: 181816.7656 - val_true_negatives: 7339539.5000 - val_false_positives: 653489.8125 - val_false_negatives: 167188.3125\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.15339\n",
      "Epoch 11/20\n",
      "9489/9489 [==============================] - 5s 529us/step - loss: 10.5284 - acc: 0.1444 - categorical_accuracy: 0.1444 - top_k_categorical_accuracy: 0.4057 - precision: 0.2178 - recall: 0.5202 - true_positives: 190415.2500 - true_negatives: 7713038.5000 - false_positives: 683742.6875 - false_negatives: 175599.5781 - val_loss: 10.7627 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.4412 - val_precision: 0.2183 - val_recall: 0.5193 - val_true_positives: 199497.7656 - val_true_negatives: 8085670.5000 - val_false_positives: 714378.8125 - val_false_negatives: 184691.3125\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.15339\n",
      "Epoch 12/20\n",
      "9489/9489 [==============================] - 5s 533us/step - loss: 10.5326 - acc: 0.1424 - categorical_accuracy: 0.1424 - top_k_categorical_accuracy: 0.4095 - precision: 0.2181 - recall: 0.5192 - true_positives: 208295.9531 - true_negatives: 8457164.0000 - false_positives: 746670.3125 - false_negatives: 192868.9531 - val_loss: 10.7796 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.3801 - val_precision: 0.2186 - val_recall: 0.5186 - val_true_positives: 217496.7656 - val_true_negatives: 8829719.0000 - val_false_positives: 777345.8125 - val_false_negatives: 201876.3125\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.15339\n",
      "Epoch 13/20\n",
      "9489/9489 [==============================] - 5s 534us/step - loss: 10.4942 - acc: 0.1440 - categorical_accuracy: 0.1440 - top_k_categorical_accuracy: 0.3981 - precision: 0.2187 - recall: 0.5179 - true_positives: 226048.8594 - true_negatives: 9203301.0000 - false_positives: 807404.5625 - false_negatives: 210444.0469 - val_loss: 10.6868 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.4412 - val_precision: 0.2193 - val_recall: 0.5160 - val_true_positives: 234567.9688 - val_true_negatives: 9578935.0000 - val_false_positives: 835148.1875 - val_false_negatives: 219989.1094\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.15339\n",
      "Epoch 14/20\n",
      "9489/9489 [==============================] - 5s 534us/step - loss: 10.4642 - acc: 0.1444 - categorical_accuracy: 0.1444 - top_k_categorical_accuracy: 0.3958 - precision: 0.2198 - recall: 0.5139 - true_positives: 242346.5000 - true_negatives: 9957359.0000 - false_positives: 860435.6250 - false_negatives: 229265.0781 - val_loss: 10.7198 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.3801 - val_precision: 0.2204 - val_recall: 0.5116 - val_true_positives: 250570.7656 - val_true_negatives: 10335026.0000 - val_false_positives: 886075.8750 - val_false_negatives: 239170.3125\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.15339\n",
      "Epoch 15/20\n",
      "9489/9489 [==============================] - 5s 536us/step - loss: 10.4581 - acc: 0.1447 - categorical_accuracy: 0.1447 - top_k_categorical_accuracy: 0.3953 - precision: 0.2208 - recall: 0.5098 - true_positives: 258361.9844 - true_negatives: 10712865.0000 - false_positives: 911936.9375 - false_negatives: 248444.0781 - val_loss: 10.7142 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.3552 - val_precision: 0.2214 - val_recall: 0.5078 - val_true_positives: 266570.7500 - val_true_negatives: 11090552.0000 - val_false_positives: 937568.9375 - val_false_negatives: 258354.3125\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.15339\n",
      "Epoch 16/20\n",
      "9489/9489 [==============================] - 5s 536us/step - loss: 10.4389 - acc: 0.1443 - categorical_accuracy: 0.1443 - top_k_categorical_accuracy: 0.3964 - precision: 0.2216 - recall: 0.5064 - true_positives: 274381.7188 - true_negatives: 11468401.0000 - false_positives: 963597.9375 - false_negatives: 267427.5000 - val_loss: 10.6896 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.4412 - val_precision: 0.2222 - val_recall: 0.5050 - val_true_positives: 282833.3750 - val_true_negatives: 11844916.0000 - val_false_positives: 990220.7500 - val_false_negatives: 277275.7188\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.15339\n",
      "Epoch 17/20\n",
      "9489/9489 [==============================] - 5s 536us/step - loss: 10.4393 - acc: 0.1445 - categorical_accuracy: 0.1445 - top_k_categorical_accuracy: 0.3973 - precision: 0.2222 - recall: 0.5044 - true_positives: 291132.7812 - true_negatives: 12219950.0000 - false_positives: 1018895.6875 - false_negatives: 286030.0625 - val_loss: 10.6686 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.4412 - val_precision: 0.2227 - val_recall: 0.5031 - val_true_positives: 299484.7500 - val_true_negatives: 12596839.0000 - val_false_positives: 1045319.0625 - val_false_negatives: 295808.3125\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.15339\n",
      "Epoch 18/20\n",
      "9489/9489 [==============================] - 5s 537us/step - loss: 10.4155 - acc: 0.1445 - categorical_accuracy: 0.1445 - top_k_categorical_accuracy: 0.4029 - precision: 0.2230 - recall: 0.5018 - true_positives: 307291.4062 - true_negatives: 12974969.0000 - false_positives: 1070846.8750 - false_negatives: 305104.1250 - val_loss: 10.6826 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.4412 - val_precision: 0.2236 - val_recall: 0.4992 - val_true_positives: 314744.4062 - val_true_negatives: 13356002.0000 - val_false_positives: 1093173.3750 - val_false_negatives: 315732.6562\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.15339\n",
      "Epoch 19/20\n",
      "9489/9489 [==============================] - 5s 540us/step - loss: 10.4112 - acc: 0.1445 - categorical_accuracy: 0.1445 - top_k_categorical_accuracy: 0.3951 - precision: 0.2239 - recall: 0.4976 - true_positives: 322220.3750 - true_negatives: 13735866.0000 - false_positives: 1116948.1250 - false_negatives: 325380.0312 - val_loss: 10.6639 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.4412 - val_precision: 0.2243 - val_recall: 0.4962 - val_true_positives: 330287.5938 - val_true_negatives: 14113912.0000 - val_false_positives: 1142280.2500 - val_false_negatives: 335373.5000\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.15339\n",
      "Epoch 20/20\n",
      "9489/9489 [==============================] - 5s 544us/step - loss: 10.3964 - acc: 0.1445 - categorical_accuracy: 0.1445 - top_k_categorical_accuracy: 0.4007 - precision: 0.2245 - recall: 0.4949 - true_positives: 337850.5000 - true_negatives: 14492797.0000 - false_positives: 1167143.8750 - false_negatives: 344822.3125 - val_loss: 10.6432 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.3801 - val_precision: 0.2250 - val_recall: 0.4937 - val_true_positives: 345985.7500 - val_true_negatives: 14871409.0000 - val_false_positives: 1191800.8750 - val_false_negatives: 354859.3125\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.15339\n",
      "Reshaped Into Shape:  (2966, 3, 256)\n",
      "At threshold of 0.1\n",
      "count_1_as_1, TP 6967\n",
      "count_1_as_0, FN 2055\n",
      "count_0_as_1, FP 55319\n",
      "count_0_as_0, TN 146245\n",
      "total_real_1s 9022\n",
      "total_real_0s 201564\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.272    |             |\n",
      "| Term Wise Accuracy |    0.728    |             |\n",
      "|      Accuracy      |    0.000    |             |\n",
      "|     Precision      |    0.033    |    0.112    |\n",
      "|       Recall       |    0.296    |    0.772    |\n",
      "|     F1-measure     |    0.056    |    0.195    |\n",
      "+--------------------+-------------+-------------+\n",
      "+-------------------------------+--------+\n",
      "|             Metric            | Value  |\n",
      "+-------------------------------+--------+\n",
      "|  True Positives, count_1_as_1 |  6967  |\n",
      "| False Negatives, count_1_as_0 |  2055  |\n",
      "| False Positives, count_0_as_1 | 55319  |\n",
      "|  True Negatives, count_0_as_0 | 146245 |\n",
      "|            Real 1s            |  9022  |\n",
      "|            Real 0s            | 201564 |\n",
      "+-------------------------------+--------+\n",
      "At threshold of 0.2\n",
      "count_1_as_1, TP 5242\n",
      "count_1_as_0, FN 3780\n",
      "count_0_as_1, FP 21452\n",
      "count_0_as_0, TN 180112\n",
      "total_real_1s 9022\n",
      "total_real_0s 201564\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.120    |             |\n",
      "| Term Wise Accuracy |    0.880    |             |\n",
      "|      Accuracy      |    0.000    |             |\n",
      "|     Precision      |    0.025    |    0.196    |\n",
      "|       Recall       |    0.127    |    0.581    |\n",
      "|     F1-measure     |    0.040    |    0.294    |\n",
      "+--------------------+-------------+-------------+\n",
      "+-------------------------------+--------+\n",
      "|             Metric            | Value  |\n",
      "+-------------------------------+--------+\n",
      "|  True Positives, count_1_as_1 |  5242  |\n",
      "| False Negatives, count_1_as_0 |  3780  |\n",
      "| False Positives, count_0_as_1 | 21452  |\n",
      "|  True Negatives, count_0_as_0 | 180112 |\n",
      "|            Real 1s            |  9022  |\n",
      "|            Real 0s            | 201564 |\n",
      "+-------------------------------+--------+\n",
      "At threshold of 0.3\n",
      "count_1_as_1, TP 4675\n",
      "count_1_as_0, FN 4347\n",
      "count_0_as_1, FP 16087\n",
      "count_0_as_0, TN 185477\n",
      "total_real_1s 9022\n",
      "total_real_0s 201564\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.097    |             |\n",
      "| Term Wise Accuracy |    0.903    |             |\n",
      "|      Accuracy      |    0.000    |             |\n",
      "|     Precision      |    0.022    |    0.225    |\n",
      "|       Recall       |    0.099    |    0.518    |\n",
      "|     F1-measure     |    0.036    |    0.314    |\n",
      "+--------------------+-------------+-------------+\n",
      "+-------------------------------+--------+\n",
      "|             Metric            | Value  |\n",
      "+-------------------------------+--------+\n",
      "|  True Positives, count_1_as_1 |  4675  |\n",
      "| False Negatives, count_1_as_0 |  4347  |\n",
      "| False Positives, count_0_as_1 | 16087  |\n",
      "|  True Negatives, count_0_as_0 | 185477 |\n",
      "|            Real 1s            |  9022  |\n",
      "|            Real 0s            | 201564 |\n",
      "+-------------------------------+--------+\n",
      "At threshold of 0.4\n",
      "count_1_as_1, TP 4307\n",
      "count_1_as_0, FN 4715\n",
      "count_0_as_1, FP 13489\n",
      "count_0_as_0, TN 188075\n",
      "total_real_1s 9022\n",
      "total_real_0s 201564\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.086    |             |\n",
      "| Term Wise Accuracy |    0.914    |             |\n",
      "|      Accuracy      |    0.000    |             |\n",
      "|     Precision      |    0.020    |    0.242    |\n",
      "|       Recall       |    0.085    |    0.477    |\n",
      "|     F1-measure     |    0.032    |    0.321    |\n",
      "+--------------------+-------------+-------------+\n",
      "+-------------------------------+--------+\n",
      "|             Metric            | Value  |\n",
      "+-------------------------------+--------+\n",
      "|  True Positives, count_1_as_1 |  4307  |\n",
      "| False Negatives, count_1_as_0 |  4715  |\n",
      "| False Positives, count_0_as_1 | 13489  |\n",
      "|  True Negatives, count_0_as_0 | 188075 |\n",
      "|            Real 1s            |  9022  |\n",
      "|            Real 0s            | 201564 |\n",
      "+-------------------------------+--------+\n",
      "At threshold of 0.5\n",
      "count_1_as_1, TP 4307\n",
      "count_1_as_0, FN 4715\n",
      "count_0_as_1, FP 13489\n",
      "count_0_as_0, TN 188075\n",
      "total_real_1s 9022\n",
      "total_real_0s 201564\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.086    |             |\n",
      "| Term Wise Accuracy |    0.914    |             |\n",
      "|      Accuracy      |    0.000    |             |\n",
      "|     Precision      |    0.020    |    0.242    |\n",
      "|       Recall       |    0.085    |    0.477    |\n",
      "|     F1-measure     |    0.032    |    0.321    |\n",
      "+--------------------+-------------+-------------+\n",
      "+-------------------------------+--------+\n",
      "|             Metric            | Value  |\n",
      "+-------------------------------+--------+\n",
      "|  True Positives, count_1_as_1 |  4307  |\n",
      "| False Negatives, count_1_as_0 |  4715  |\n",
      "| False Positives, count_0_as_1 | 13489  |\n",
      "|  True Negatives, count_0_as_0 | 188075 |\n",
      "|            Real 1s            |  9022  |\n",
      "|            Real 0s            | 201564 |\n",
      "+-------------------------------+--------+\n",
      "At threshold of 0.6\n",
      "count_1_as_1, TP 2662\n",
      "count_1_as_0, FN 6360\n",
      "count_0_as_1, FP 6236\n",
      "count_0_as_0, TN 195328\n",
      "total_real_1s 9022\n",
      "total_real_0s 201564\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.060    |             |\n",
      "| Term Wise Accuracy |    0.940    |             |\n",
      "|      Accuracy      |    0.003    |             |\n",
      "|     Precision      |    0.013    |    0.299    |\n",
      "|       Recall       |    0.042    |    0.295    |\n",
      "|     F1-measure     |    0.019    |    0.297    |\n",
      "+--------------------+-------------+-------------+\n",
      "+-------------------------------+--------+\n",
      "|             Metric            | Value  |\n",
      "+-------------------------------+--------+\n",
      "|  True Positives, count_1_as_1 |  2662  |\n",
      "| False Negatives, count_1_as_0 |  6360  |\n",
      "| False Positives, count_0_as_1 |  6236  |\n",
      "|  True Negatives, count_0_as_0 | 195328 |\n",
      "|            Real 1s            |  9022  |\n",
      "|            Real 0s            | 201564 |\n",
      "+-------------------------------+--------+\n",
      "At threshold of 0.7\n",
      "count_1_as_1, TP 2066\n",
      "count_1_as_0, FN 6956\n",
      "count_0_as_1, FP 3866\n",
      "count_0_as_0, TN 197698\n",
      "total_real_1s 9022\n",
      "total_real_0s 201564\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.051    |             |\n",
      "| Term Wise Accuracy |    0.949    |             |\n",
      "|      Accuracy      |    0.018    |             |\n",
      "|     Precision      |    0.010    |    0.348    |\n",
      "|       Recall       |    0.028    |    0.229    |\n",
      "|     F1-measure     |    0.015    |    0.276    |\n",
      "+--------------------+-------------+-------------+\n",
      "+-------------------------------+--------+\n",
      "|             Metric            | Value  |\n",
      "+-------------------------------+--------+\n",
      "|  True Positives, count_1_as_1 |  2066  |\n",
      "| False Negatives, count_1_as_0 |  6956  |\n",
      "| False Positives, count_0_as_1 |  3866  |\n",
      "|  True Negatives, count_0_as_0 | 197698 |\n",
      "|            Real 1s            |  9022  |\n",
      "|            Real 0s            | 201564 |\n",
      "+-------------------------------+--------+\n",
      "At threshold of 0.8\n",
      "count_1_as_1, TP 2066\n",
      "count_1_as_0, FN 6956\n",
      "count_0_as_1, FP 3866\n",
      "count_0_as_0, TN 197698\n",
      "total_real_1s 9022\n",
      "total_real_0s 201564\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.051    |             |\n",
      "| Term Wise Accuracy |    0.949    |             |\n",
      "|      Accuracy      |    0.018    |             |\n",
      "|     Precision      |    0.010    |    0.348    |\n",
      "|       Recall       |    0.028    |    0.229    |\n",
      "|     F1-measure     |    0.015    |    0.276    |\n",
      "+--------------------+-------------+-------------+\n",
      "+-------------------------------+--------+\n",
      "|             Metric            | Value  |\n",
      "+-------------------------------+--------+\n",
      "|  True Positives, count_1_as_1 |  2066  |\n",
      "| False Negatives, count_1_as_0 |  6956  |\n",
      "| False Positives, count_0_as_1 |  3866  |\n",
      "|  True Negatives, count_0_as_0 | 197698 |\n",
      "|            Real 1s            |  9022  |\n",
      "|            Real 0s            | 201564 |\n",
      "+-------------------------------+--------+\n",
      "At threshold of 0.9\n",
      "count_1_as_1, TP 2066\n",
      "count_1_as_0, FN 6956\n",
      "count_0_as_1, FP 3866\n",
      "count_0_as_0, TN 197698\n",
      "total_real_1s 9022\n",
      "total_real_0s 201564\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.051    |             |\n",
      "| Term Wise Accuracy |    0.949    |             |\n",
      "|      Accuracy      |    0.018    |             |\n",
      "|     Precision      |    0.010    |    0.348    |\n",
      "|       Recall       |    0.028    |    0.229    |\n",
      "|     F1-measure     |    0.015    |    0.276    |\n",
      "+--------------------+-------------+-------------+\n",
      "+-------------------------------+--------+\n",
      "|             Metric            | Value  |\n",
      "+-------------------------------+--------+\n",
      "|  True Positives, count_1_as_1 |  2066  |\n",
      "| False Negatives, count_1_as_0 |  6956  |\n",
      "| False Positives, count_0_as_1 |  3866  |\n",
      "|  True Negatives, count_0_as_0 | 197698 |\n",
      "|            Real 1s            |  9022  |\n",
      "|            Real 0s            | 201564 |\n",
      "+-------------------------------+--------+\n",
      "\n",
      "FOR DATASET:  bert_t2\n",
      "FOR OPTIMIZER:  adam\n",
      "\n",
      "###############\n",
      "KEY= model_3_256_adam_bert_t2\n",
      "#############\n",
      "\n",
      "###############\n",
      "model_type= bert_t2_adam\n",
      "#############\n",
      "inp_layer (None, 3, 256)\n",
      "embedding_layer_frozen (None, 3, 256)\n",
      "embedding_layer_train (None, 3, 256)\n",
      "l_lstm_1f (None, 3, 512)\n",
      "l_lstm_1t (None, 3, 512)\n",
      "l_lstm1 (None, 6, 512)\n",
      "l_conv_2 (None, 5, 64)\n",
      "l_conv_3 (None, 4, 64)\n",
      "l_conv_5 (None, 3, 64)\n",
      "l_conv_6 (None, 2, 64)\n",
      "l_conv_8 (None, 1, 64)\n",
      "l_lstm_c (None, 15, 64)\n",
      "l_conv_4f (None, 1, 64)\n",
      "l_conv_4t (None, 1, 64)\n",
      "l_conv_3f (None, 1, 64)\n",
      "l_conv_3t (None, 1, 64)\n",
      "l_conv_2f (None, 1, 64)\n",
      "l_conv_2t (None, 1, 64)\n",
      "l_merge_2 (None, 6, 64)\n",
      "l_c_lstm (None, 6, 64)\n",
      "Training Progress for: bert_t2_adam\n",
      "Reshaping inputs\n",
      "Reshaped Into Shape:  (9489, 3, 256)\n",
      "Reshaped Into Shape:  (2373, 3, 256)\n",
      "Reshaped Successfully!\n",
      "Train on 9489 samples, validate on 2373 samples\n",
      "Epoch 1/20\n",
      "9489/9489 [==============================] - 8s 877us/step - loss: 10.6519 - acc: 0.1313 - categorical_accuracy: 0.1313 - top_k_categorical_accuracy: 0.4253 - precision_1: 0.1760 - recall_1: 0.5747 - true_positives_1: 7892.1812 - true_negatives_1: 292646.7500 - false_positives_1: 33965.4883 - false_negatives_1: 6273.1880 - val_loss: 10.8033 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.4412 - val_precision_1: 0.2034 - val_recall_1: 0.5491 - val_true_positives_1: 17764.5781 - val_true_negatives_1: 660301.6250 - val_false_positives_1: 69566.0000 - val_false_negatives_1: 14584.5000\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.15339, saving model to logs/save/best_model_3_256_2020_10_25_19_52_42_bert_t2_adam.h5\n",
      "Epoch 2/20\n",
      "9489/9489 [==============================] - 5s 555us/step - loss: 10.5558 - acc: 0.1338 - categorical_accuracy: 0.1338 - top_k_categorical_accuracy: 0.4174 - precision_1: 0.2046 - recall_1: 0.5495 - true_positives_1: 27127.8789 - true_negatives_1: 1028237.9375 - false_positives_1: 105347.0703 - false_negatives_1: 22266.4023 - val_loss: 10.8102 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.4412 - val_precision_1: 0.2086 - val_recall_1: 0.5420 - val_true_positives_1: 36603.3672 - val_true_negatives_1: 1397983.0000 - val_false_positives_1: 138902.7656 - val_false_negatives_1: 30929.7109\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.15339\n",
      "Epoch 3/20\n",
      "9489/9489 [==============================] - 5s 543us/step - loss: 10.5561 - acc: 0.1444 - categorical_accuracy: 0.1444 - top_k_categorical_accuracy: 0.4028 - precision_1: 0.2095 - recall_1: 0.5383 - true_positives_1: 45462.4023 - true_negatives_1: 1769240.0000 - false_positives_1: 171452.6562 - false_negatives_1: 39026.2344 - val_loss: 10.7768 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.3801 - val_precision_1: 0.2126 - val_recall_1: 0.5323 - val_true_positives_1: 54670.7617 - val_true_negatives_1: 2141462.0000 - val_false_positives_1: 202441.9219 - val_false_negatives_1: 48046.3164\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.15339\n",
      "Epoch 4/20\n",
      "9489/9489 [==============================] - 5s 544us/step - loss: 10.5907 - acc: 0.1444 - categorical_accuracy: 0.1444 - top_k_categorical_accuracy: 0.3965 - precision_1: 0.2130 - recall_1: 0.5311 - true_positives_1: 63524.2695 - true_negatives_1: 2513126.7500 - false_positives_1: 234638.7188 - false_negatives_1: 56093.9453 - val_loss: 10.8520 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.3801 - val_precision_1: 0.2147 - val_recall_1: 0.5281 - val_true_positives_1: 72826.9766 - val_true_negatives_1: 2884568.7500 - val_false_positives_1: 266353.1562 - val_false_negatives_1: 65074.1055\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.15339\n",
      "Epoch 5/20\n",
      "9489/9489 [==============================] - 5s 543us/step - loss: 10.5881 - acc: 0.1143 - categorical_accuracy: 0.1143 - top_k_categorical_accuracy: 0.4087 - precision_1: 0.2143 - recall_1: 0.5295 - true_positives_1: 81972.2500 - true_negatives_1: 3254290.5000 - false_positives_1: 300497.6562 - false_negatives_1: 72826.2500 - val_loss: 10.8152 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.4412 - val_precision_1: 0.2149 - val_recall_1: 0.5291 - val_true_positives_1: 91581.9766 - val_true_negatives_1: 3623359.2500 - val_false_positives_1: 334580.1562 - val_false_negatives_1: 81503.1016\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.15339\n",
      "Epoch 6/20\n",
      "9489/9489 [==============================] - 5s 559us/step - loss: 10.6065 - acc: 0.1309 - categorical_accuracy: 0.1309 - top_k_categorical_accuracy: 0.4086 - precision_1: 0.2146 - recall_1: 0.5296 - true_positives_1: 100680.7812 - true_negatives_1: 3993136.0000 - false_positives_1: 368527.3125 - false_negatives_1: 89443.0781 - val_loss: 10.8641 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.4412 - val_precision_1: 0.2149 - val_recall_1: 0.5300 - val_true_positives_1: 110380.5781 - val_true_negatives_1: 4361590.0000 - val_false_positives_1: 403367.0000 - val_false_negatives_1: 97888.5000\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.15339\n",
      "Epoch 7/20\n",
      "9489/9489 [==============================] - 5s 557us/step - loss: 10.6518 - acc: 0.1396 - categorical_accuracy: 0.1396 - top_k_categorical_accuracy: 0.3919 - precision_1: 0.2144 - recall_1: 0.5314 - true_positives_1: 119696.6172 - true_negatives_1: 4730119.5000 - false_positives_1: 438615.2500 - false_negatives_1: 105558.2109 - val_loss: 10.9074 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.4412 - val_precision_1: 0.2147 - val_recall_1: 0.5313 - val_true_positives_1: 129337.5781 - val_true_negatives_1: 5099009.5000 - val_false_positives_1: 472966.9375 - val_false_negatives_1: 114115.5000\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.15339\n",
      "Epoch 8/20\n",
      "9489/9489 [==============================] - 5s 551us/step - loss: 10.5989 - acc: 0.1395 - categorical_accuracy: 0.1395 - top_k_categorical_accuracy: 0.4144 - precision_1: 0.2141 - recall_1: 0.5327 - true_positives_1: 138697.9062 - true_negatives_1: 5466715.5000 - false_positives_1: 509095.0312 - false_negatives_1: 121684.4531 - val_loss: 10.8520 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.3970 - val_precision_1: 0.2145 - val_recall_1: 0.5322 - val_true_positives_1: 148279.9688 - val_true_negatives_1: 5835893.5000 - val_false_positives_1: 543100.1250 - val_false_negatives_1: 130357.1016\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.15339\n",
      "Epoch 9/20\n",
      "9489/9489 [==============================] - 5s 552us/step - loss: 10.6258 - acc: 0.1444 - categorical_accuracy: 0.1444 - top_k_categorical_accuracy: 0.3956 - precision_1: 0.2141 - recall_1: 0.5331 - true_positives_1: 157618.0938 - true_negatives_1: 6204204.5000 - false_positives_1: 578554.1250 - false_negatives_1: 138015.4062 - val_loss: 10.8522 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.4412 - val_precision_1: 0.2144 - val_recall_1: 0.5328 - val_true_positives_1: 167211.7656 - val_true_negatives_1: 6573471.5000 - val_false_positives_1: 612539.8750 - val_false_negatives_1: 146609.3125\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.15339\n",
      "Epoch 10/20\n",
      "9489/9489 [==============================] - 5s 549us/step - loss: 10.5686 - acc: 0.1446 - categorical_accuracy: 0.1446 - top_k_categorical_accuracy: 0.4010 - precision_1: 0.2146 - recall_1: 0.5324 - true_positives_1: 176194.1719 - true_negatives_1: 6944812.0000 - false_positives_1: 644855.3750 - false_negatives_1: 154732.8594 - val_loss: 10.8120 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.3801 - val_precision_1: 0.2146 - val_recall_1: 0.5325 - val_true_positives_1: 185861.8125 - val_true_negatives_1: 7312715.0000 - val_false_positives_1: 680314.1250 - val_false_negatives_1: 163143.2656\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.15339\n",
      "Epoch 11/20\n",
      "9489/9489 [==============================] - 5s 546us/step - loss: 10.5591 - acc: 0.1432 - categorical_accuracy: 0.1432 - top_k_categorical_accuracy: 0.4106 - precision_1: 0.2141 - recall_1: 0.5333 - true_positives_1: 195181.3750 - true_negatives_1: 7680410.0000 - false_positives_1: 716367.4375 - false_negatives_1: 170836.8594 - val_loss: 10.8632 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.4412 - val_precision_1: 0.2146 - val_recall_1: 0.5318 - val_true_positives_1: 204324.9688 - val_true_negatives_1: 8052311.5000 - val_false_positives_1: 747735.1875 - val_false_negatives_1: 179864.1094\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.15339\n",
      "Epoch 12/20\n",
      "9489/9489 [==============================] - 5s 548us/step - loss: 10.5299 - acc: 0.1444 - categorical_accuracy: 0.1444 - top_k_categorical_accuracy: 0.3928 - precision_1: 0.2148 - recall_1: 0.5309 - true_positives_1: 213049.6875 - true_negatives_1: 8425067.0000 - false_positives_1: 778616.0000 - false_negatives_1: 188268.3281 - val_loss: 10.7576 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.3801 - val_precision_1: 0.2152 - val_recall_1: 0.5303 - val_true_positives_1: 222406.9688 - val_true_negatives_1: 8795833.0000 - val_false_positives_1: 811232.1250 - val_false_negatives_1: 196966.1094\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.15339\n",
      "Epoch 13/20\n",
      "9489/9489 [==============================] - 5s 546us/step - loss: 10.5229 - acc: 0.0665 - categorical_accuracy: 0.0665 - top_k_categorical_accuracy: 0.4014 - precision_1: 0.2152 - recall_1: 0.5300 - true_positives_1: 231247.2188 - true_negatives_1: 9167739.0000 - false_positives_1: 843145.6875 - false_negatives_1: 205070.5156 - val_loss: 10.7422 - val_acc: 0.0603 - val_categorical_accuracy: 0.0603 - val_top_k_categorical_accuracy: 0.3801 - val_precision_1: 0.2158 - val_recall_1: 0.5291 - val_true_positives_1: 240498.7656 - val_true_negatives_1: 9539931.0000 - val_false_positives_1: 874151.8750 - val_false_negatives_1: 214058.3125\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.15339\n",
      "Epoch 14/20\n",
      "9489/9489 [==============================] - 5s 552us/step - loss: 10.4875 - acc: 0.0669 - categorical_accuracy: 0.0669 - top_k_categorical_accuracy: 0.3913 - precision_1: 0.2159 - recall_1: 0.5285 - true_positives_1: 249214.0156 - true_negatives_1: 9912694.0000 - false_positives_1: 905138.8750 - false_negatives_1: 222356.4375 - val_loss: 10.6959 - val_acc: 0.0607 - val_categorical_accuracy: 0.0607 - val_top_k_categorical_accuracy: 0.4412 - val_precision_1: 0.2164 - val_recall_1: 0.5274 - val_true_positives_1: 258281.3750 - val_true_negatives_1: 10285747.0000 - val_false_positives_1: 935354.7500 - val_false_negatives_1: 231459.7031\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.15339\n",
      "Epoch 15/20\n",
      "9489/9489 [==============================] - 5s 558us/step - loss: 10.4880 - acc: 0.0868 - categorical_accuracy: 0.0868 - top_k_categorical_accuracy: 0.4038 - precision_1: 0.2164 - recall_1: 0.5271 - true_positives_1: 267185.6562 - true_negatives_1: 10657357.0000 - false_positives_1: 967371.1875 - false_negatives_1: 239690.7188 - val_loss: 10.7389 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.4412 - val_precision_1: 0.2167 - val_recall_1: 0.5261 - val_true_positives_1: 276153.2188 - val_true_negatives_1: 11030123.0000 - val_false_positives_1: 997997.2500 - val_false_negatives_1: 248771.8750\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.15339\n",
      "Epoch 16/20\n",
      "9489/9489 [==============================] - 5s 557us/step - loss: 10.4680 - acc: 0.1239 - categorical_accuracy: 0.1239 - top_k_categorical_accuracy: 0.3969 - precision_1: 0.2169 - recall_1: 0.5250 - true_positives_1: 284491.1562 - true_negatives_1: 11404780.0000 - false_positives_1: 1027152.5625 - false_negatives_1: 257385.2812 - val_loss: 10.7085 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.4412 - val_precision_1: 0.2173 - val_recall_1: 0.5244 - val_true_positives_1: 293702.3750 - val_true_negatives_1: 11777274.0000 - val_false_positives_1: 1057865.6250 - val_false_negatives_1: 266406.7188\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.15339\n",
      "Epoch 17/20\n",
      "9489/9489 [==============================] - 5s 560us/step - loss: 10.4669 - acc: 0.1363 - categorical_accuracy: 0.1363 - top_k_categorical_accuracy: 0.4063 - precision_1: 0.2174 - recall_1: 0.5237 - true_positives_1: 302254.6562 - true_negatives_1: 12150623.0000 - false_positives_1: 1088257.8750 - false_negatives_1: 274869.5312 - val_loss: 10.6612 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.4412 - val_precision_1: 0.2178 - val_recall_1: 0.5227 - val_true_positives_1: 311148.7500 - val_true_negatives_1: 12524647.0000 - val_false_positives_1: 1117509.0000 - val_false_negatives_1: 284144.3125\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.15339\n",
      "Epoch 18/20\n",
      "9489/9489 [==============================] - 5s 550us/step - loss: 10.4457 - acc: 0.1415 - categorical_accuracy: 0.1415 - top_k_categorical_accuracy: 0.3968 - precision_1: 0.2179 - recall_1: 0.5220 - true_positives_1: 319542.5625 - true_negatives_1: 12899265.0000 - false_positives_1: 1146746.8750 - false_negatives_1: 292654.3750 - val_loss: 10.7081 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.4412 - val_precision_1: 0.2183 - val_recall_1: 0.5209 - val_true_positives_1: 328387.1875 - val_true_negatives_1: 13273456.0000 - val_false_positives_1: 1175717.6250 - val_false_negatives_1: 302089.9062\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.15339\n",
      "Epoch 19/20\n",
      "9489/9489 [==============================] - 5s 549us/step - loss: 10.4402 - acc: 0.1416 - categorical_accuracy: 0.1416 - top_k_categorical_accuracy: 0.4045 - precision_1: 0.2185 - recall_1: 0.5202 - true_positives_1: 336804.0625 - true_negatives_1: 13648604.0000 - false_positives_1: 1204345.1250 - false_negatives_1: 310657.7812 - val_loss: 10.6664 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.4412 - val_precision_1: 0.2189 - val_recall_1: 0.5193 - val_true_positives_1: 345646.7500 - val_true_negatives_1: 14022963.0000 - val_false_positives_1: 1233229.0000 - val_false_negatives_1: 320014.3125\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.15339\n",
      "Epoch 20/20\n",
      "9489/9489 [==============================] - 5s 549us/step - loss: 10.4273 - acc: 0.1425 - categorical_accuracy: 0.1425 - top_k_categorical_accuracy: 0.4001 - precision_1: 0.2190 - recall_1: 0.5188 - true_positives_1: 354218.3438 - true_negatives_1: 14396937.0000 - false_positives_1: 1262929.0000 - false_negatives_1: 328530.3750 - val_loss: 10.6509 - val_acc: 0.1534 - val_categorical_accuracy: 0.1534 - val_top_k_categorical_accuracy: 0.3801 - val_precision_1: 0.2194 - val_recall_1: 0.5180 - val_true_positives_1: 363042.7500 - val_true_negatives_1: 14771582.0000 - val_false_positives_1: 1291627.7500 - val_false_negatives_1: 337802.3125\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.15339\n",
      "Reshaped Into Shape:  (2966, 3, 256)\n",
      "At threshold of 0.1\n",
      "count_1_as_1, TP 7354\n",
      "count_1_as_0, FN 1668\n",
      "count_0_as_1, FP 66796\n",
      "count_0_as_0, TN 134768\n",
      "total_real_1s 9022\n",
      "total_real_0s 201564\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.325    |             |\n",
      "| Term Wise Accuracy |    0.675    |             |\n",
      "|      Accuracy      |    0.000    |             |\n",
      "|     Precision      |    0.035    |    0.099    |\n",
      "|       Recall       |    0.352    |    0.815    |\n",
      "|     F1-measure     |    0.060    |    0.177    |\n",
      "+--------------------+-------------+-------------+\n",
      "+-------------------------------+--------+\n",
      "|             Metric            | Value  |\n",
      "+-------------------------------+--------+\n",
      "|  True Positives, count_1_as_1 |  7354  |\n",
      "| False Negatives, count_1_as_0 |  1668  |\n",
      "| False Positives, count_0_as_1 | 66796  |\n",
      "|  True Negatives, count_0_as_0 | 134768 |\n",
      "|            Real 1s            |  9022  |\n",
      "|            Real 0s            | 201564 |\n",
      "+-------------------------------+--------+\n",
      "At threshold of 0.2\n",
      "count_1_as_1, TP 5488\n",
      "count_1_as_0, FN 3534\n",
      "count_0_as_1, FP 24172\n",
      "count_0_as_0, TN 177392\n",
      "total_real_1s 9022\n",
      "total_real_0s 201564\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.132    |             |\n",
      "| Term Wise Accuracy |    0.868    |             |\n",
      "|      Accuracy      |    0.000    |             |\n",
      "|     Precision      |    0.026    |    0.185    |\n",
      "|       Recall       |    0.141    |    0.608    |\n",
      "|     F1-measure     |    0.043    |    0.284    |\n",
      "+--------------------+-------------+-------------+\n",
      "+-------------------------------+--------+\n",
      "|             Metric            | Value  |\n",
      "+-------------------------------+--------+\n",
      "|  True Positives, count_1_as_1 |  5488  |\n",
      "| False Negatives, count_1_as_0 |  3534  |\n",
      "| False Positives, count_0_as_1 | 24172  |\n",
      "|  True Negatives, count_0_as_0 | 177392 |\n",
      "|            Real 1s            |  9022  |\n",
      "|            Real 0s            | 201564 |\n",
      "+-------------------------------+--------+\n",
      "At threshold of 0.3\n",
      "count_1_as_1, TP 5298\n",
      "count_1_as_0, FN 3724\n",
      "count_0_as_1, FP 21396\n",
      "count_0_as_0, TN 180168\n",
      "total_real_1s 9022\n",
      "total_real_0s 201564\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.119    |             |\n",
      "| Term Wise Accuracy |    0.881    |             |\n",
      "|      Accuracy      |    0.000    |             |\n",
      "|     Precision      |    0.025    |    0.198    |\n",
      "|       Recall       |    0.127    |    0.587    |\n",
      "|     F1-measure     |    0.041    |    0.297    |\n",
      "+--------------------+-------------+-------------+\n",
      "+-------------------------------+--------+\n",
      "|             Metric            | Value  |\n",
      "+-------------------------------+--------+\n",
      "|  True Positives, count_1_as_1 |  5298  |\n",
      "| False Negatives, count_1_as_0 |  3724  |\n",
      "| False Positives, count_0_as_1 | 21396  |\n",
      "|  True Negatives, count_0_as_0 | 180168 |\n",
      "|            Real 1s            |  9022  |\n",
      "|            Real 0s            | 201564 |\n",
      "+-------------------------------+--------+\n",
      "At threshold of 0.4\n",
      "count_1_as_1, TP 4702\n",
      "count_1_as_0, FN 4320\n",
      "count_0_as_1, FP 16060\n",
      "count_0_as_0, TN 185504\n",
      "total_real_1s 9022\n",
      "total_real_0s 201564\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.097    |             |\n",
      "| Term Wise Accuracy |    0.903    |             |\n",
      "|      Accuracy      |    0.000    |             |\n",
      "|     Precision      |    0.022    |    0.226    |\n",
      "|       Recall       |    0.099    |    0.521    |\n",
      "|     F1-measure     |    0.036    |    0.316    |\n",
      "+--------------------+-------------+-------------+\n",
      "+-------------------------------+--------+\n",
      "|             Metric            | Value  |\n",
      "+-------------------------------+--------+\n",
      "|  True Positives, count_1_as_1 |  4702  |\n",
      "| False Negatives, count_1_as_0 |  4320  |\n",
      "| False Positives, count_0_as_1 | 16060  |\n",
      "|  True Negatives, count_0_as_0 | 185504 |\n",
      "|            Real 1s            |  9022  |\n",
      "|            Real 0s            | 201564 |\n",
      "+-------------------------------+--------+\n",
      "At threshold of 0.5\n",
      "count_1_as_1, TP 4307\n",
      "count_1_as_0, FN 4715\n",
      "count_0_as_1, FP 13489\n",
      "count_0_as_0, TN 188075\n",
      "total_real_1s 9022\n",
      "total_real_0s 201564\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.086    |             |\n",
      "| Term Wise Accuracy |    0.914    |             |\n",
      "|      Accuracy      |    0.000    |             |\n",
      "|     Precision      |    0.020    |    0.242    |\n",
      "|       Recall       |    0.085    |    0.477    |\n",
      "|     F1-measure     |    0.032    |    0.321    |\n",
      "+--------------------+-------------+-------------+\n",
      "+-------------------------------+--------+\n",
      "|             Metric            | Value  |\n",
      "+-------------------------------+--------+\n",
      "|  True Positives, count_1_as_1 |  4307  |\n",
      "| False Negatives, count_1_as_0 |  4715  |\n",
      "| False Positives, count_0_as_1 | 13489  |\n",
      "|  True Negatives, count_0_as_0 | 188075 |\n",
      "|            Real 1s            |  9022  |\n",
      "|            Real 0s            | 201564 |\n",
      "+-------------------------------+--------+\n",
      "At threshold of 0.6\n",
      "count_1_as_1, TP 3756\n",
      "count_1_as_0, FN 5266\n",
      "count_0_as_1, FP 11074\n",
      "count_0_as_0, TN 190490\n",
      "total_real_1s 9022\n",
      "total_real_0s 201564\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.078    |             |\n",
      "| Term Wise Accuracy |    0.922    |             |\n",
      "|      Accuracy      |    0.000    |             |\n",
      "|     Precision      |    0.018    |    0.253    |\n",
      "|       Recall       |    0.070    |    0.416    |\n",
      "|     F1-measure     |    0.028    |    0.315    |\n",
      "+--------------------+-------------+-------------+\n",
      "+-------------------------------+--------+\n",
      "|             Metric            | Value  |\n",
      "+-------------------------------+--------+\n",
      "|  True Positives, count_1_as_1 |  3756  |\n",
      "| False Negatives, count_1_as_0 |  5266  |\n",
      "| False Positives, count_0_as_1 | 11074  |\n",
      "|  True Negatives, count_0_as_0 | 190490 |\n",
      "|            Real 1s            |  9022  |\n",
      "|            Real 0s            | 201564 |\n",
      "+-------------------------------+--------+\n",
      "At threshold of 0.7\n",
      "count_1_as_1, TP 2653\n",
      "count_1_as_0, FN 6369\n",
      "count_0_as_1, FP 6245\n",
      "count_0_as_0, TN 195319\n",
      "total_real_1s 9022\n",
      "total_real_0s 201564\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.060    |             |\n",
      "| Term Wise Accuracy |    0.940    |             |\n",
      "|      Accuracy      |    0.002    |             |\n",
      "|     Precision      |    0.013    |    0.298    |\n",
      "|       Recall       |    0.042    |    0.294    |\n",
      "|     F1-measure     |    0.019    |    0.296    |\n",
      "+--------------------+-------------+-------------+\n",
      "+-------------------------------+--------+\n",
      "|             Metric            | Value  |\n",
      "+-------------------------------+--------+\n",
      "|  True Positives, count_1_as_1 |  2653  |\n",
      "| False Negatives, count_1_as_0 |  6369  |\n",
      "| False Positives, count_0_as_1 |  6245  |\n",
      "|  True Negatives, count_0_as_0 | 195319 |\n",
      "|            Real 1s            |  9022  |\n",
      "|            Real 0s            | 201564 |\n",
      "+-------------------------------+--------+\n",
      "At threshold of 0.8\n",
      "count_1_as_1, TP 2653\n",
      "count_1_as_0, FN 6369\n",
      "count_0_as_1, FP 6245\n",
      "count_0_as_0, TN 195319\n",
      "total_real_1s 9022\n",
      "total_real_0s 201564\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.060    |             |\n",
      "| Term Wise Accuracy |    0.940    |             |\n",
      "|      Accuracy      |    0.002    |             |\n",
      "|     Precision      |    0.013    |    0.298    |\n",
      "|       Recall       |    0.042    |    0.294    |\n",
      "|     F1-measure     |    0.019    |    0.296    |\n",
      "+--------------------+-------------+-------------+\n",
      "+-------------------------------+--------+\n",
      "|             Metric            | Value  |\n",
      "+-------------------------------+--------+\n",
      "|  True Positives, count_1_as_1 |  2653  |\n",
      "| False Negatives, count_1_as_0 |  6369  |\n",
      "| False Positives, count_0_as_1 |  6245  |\n",
      "|  True Negatives, count_0_as_0 | 195319 |\n",
      "|            Real 1s            |  9022  |\n",
      "|            Real 0s            | 201564 |\n",
      "+-------------------------------+--------+\n",
      "At threshold of 0.9\n",
      "count_1_as_1, TP 2653\n",
      "count_1_as_0, FN 6369\n",
      "count_0_as_1, FP 6245\n",
      "count_0_as_0, TN 195319\n",
      "total_real_1s 9022\n",
      "total_real_0s 201564\n",
      "+--------------------+-------------+-------------+\n",
      "|       Metric       | Macro Value | Micro Value |\n",
      "+--------------------+-------------+-------------+\n",
      "|    Hamming Loss    |    0.060    |             |\n",
      "| Term Wise Accuracy |    0.940    |             |\n",
      "|      Accuracy      |    0.002    |             |\n",
      "|     Precision      |    0.013    |    0.298    |\n",
      "|       Recall       |    0.042    |    0.294    |\n",
      "|     F1-measure     |    0.019    |    0.296    |\n",
      "+--------------------+-------------+-------------+\n",
      "+-------------------------------+--------+\n",
      "|             Metric            | Value  |\n",
      "+-------------------------------+--------+\n",
      "|  True Positives, count_1_as_1 |  2653  |\n",
      "| False Negatives, count_1_as_0 |  6369  |\n",
      "| False Positives, count_0_as_1 |  6245  |\n",
      "|  True Negatives, count_0_as_0 | 195319 |\n",
      "|            Real 1s            |  9022  |\n",
      "|            Real 0s            | 201564 |\n",
      "+-------------------------------+--------+\n",
      "\n",
      "FOR DATASET:  xlnet_t1\n",
      "FOR OPTIMIZER:  adam\n",
      "\n",
      "###############\n",
      "KEY= model_3_256_adam_xlnet_t1\n",
      "#############\n",
      "\n",
      "###############\n",
      "model_type= xlnet_t1_adam\n",
      "#############\n",
      "inp_layer (None, 3, 256)\n",
      "embedding_layer_frozen (None, 3, 256)\n",
      "embedding_layer_train (None, 3, 256)\n",
      "l_lstm_1f (None, 3, 512)\n",
      "l_lstm_1t (None, 3, 512)\n",
      "l_lstm1 (None, 6, 512)\n",
      "l_conv_2 (None, 5, 64)\n",
      "l_conv_3 (None, 4, 64)\n",
      "l_conv_5 (None, 3, 64)\n",
      "l_conv_6 (None, 2, 64)\n",
      "l_conv_8 (None, 1, 64)\n",
      "l_lstm_c (None, 15, 64)\n",
      "l_conv_4f (None, 1, 64)\n",
      "l_conv_4t (None, 1, 64)\n",
      "l_conv_3f (None, 1, 64)\n",
      "l_conv_3t (None, 1, 64)\n",
      "l_conv_2f (None, 1, 64)\n",
      "l_conv_2t (None, 1, 64)\n",
      "l_merge_2 (None, 6, 64)\n",
      "l_c_lstm (None, 6, 64)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "fitModel() missing 2 required positional arguments: 'time_dict' and 'key'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-710c4f917d25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     58\u001b[0m                                                 \u001b[0mmodel_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                                                 \u001b[0mepochs_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m                                                 batch_count = 64)\n\u001b[0m\u001b[0;32m     61\u001b[0m             \u001b[0mmodel_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset_X\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset_Y\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'xlnet'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mt_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[0mtime_logger_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minp_shape_str\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"_time\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fitModel() missing 2 required positional arguments: 'time_dict' and 'key'"
     ]
    }
   ],
   "source": [
    "model_dict ={}\n",
    "t_list =[x/10 for x in range(1,10)]\n",
    "time_dict=[]\n",
    "\n",
    "for ds in dataset_X.keys():\n",
    "    print(\"\\nFOR DATASET: \", ds)\n",
    "    for opt in optimizer_list:\n",
    "        print(\"FOR OPTIMIZER: \",opt)\n",
    "        key= \"model_\"+inp_shape_str+\"_\"+opt+\"_\"+ds\n",
    "        model_type = ds+\"_\"+opt\n",
    "        print(\"\\n###############\\nKEY= \"+key+\"\\n#############\")\n",
    "        print(\"\\n###############\\nmodel_type= \"+model_type+\"\\n#############\")\n",
    "        model_dict[key] = BalanceNet(INPUT_SHAPE,\n",
    "                                    EM_L_F_UNITS,\n",
    "                                    EM_L_T_UNITS,\n",
    "                                    LSTM_1F_UNITS,\n",
    "                                    LSTM_1T_UNITS,\n",
    "                                    CONV_2_FILTER,\n",
    "                                    CONV_2_KERNEL,\n",
    "                                    CONV_3_FILTER,\n",
    "                                    CONV_3_KERNEL,\n",
    "                                    CONV_5_FILTER,\n",
    "                                    CONV_5_KERNEL,\n",
    "                                    CONV_6_FILTER,\n",
    "                                    CONV_6_KERNEL,\n",
    "                                    CONV_8_FILTER,\n",
    "                                    CONV_8_KERNEL,\n",
    "                                    CONV_4F_FILTERS,\n",
    "                                    CONV_4F_KERNEL,\n",
    "                                    CONV_4T_FILTERS,\n",
    "                                    CONV_4T_KERNEL,\n",
    "                                    CONV_3F_FILTERS,\n",
    "                                    CONV_3F_KERNEL,\n",
    "                                    CONV_3T_FILTERS,\n",
    "                                    CONV_3T_KERNEL,\n",
    "                                    CONV_2F_FILTERS,\n",
    "                                    CONV_2F_KERNEL,\n",
    "                                    CONV_2T_FILTERS,\n",
    "                                    CONV_2T_KERNEL,\n",
    "                                    LSTM_2_C_L_UNITS,\n",
    "                                    OUTPUT_DENSE_UNIT,\n",
    "                                    OUTPUT_SIZE,\n",
    "                                    optimizer_name= opt)\n",
    "        \n",
    "        if 'bert' in ds:\n",
    "            em_type='bert'\n",
    "        if 'xlnet' in ds:\n",
    "            em_type='xlnet'\n",
    "        model_dict[key].fitModel(train_x =dataset_X[ds][0], \n",
    "                                            train_y=dataset_Y[em_type][0], \n",
    "                                            val_x= dataset_X[ds][1], \n",
    "                                            val_y = dataset_Y[em_type][1], \n",
    "                                            model_type = model_type, \n",
    "                                            epochs_count = 20 , \n",
    "                                            batch_count = 64,  time_dict=time_dict, key=key)\n",
    "        model_dict[key].predictModel(test_x=dataset_X[ds][2], test_y=dataset_Y[em_type][2], threshold_list=t_list,  time_dict=time_dict, key=key)\n",
    "        \n",
    "time_logger_save(time_dict,inp_shape_str+\"_time\")\n"
   ]
  },
  {
   "source": [
    "# END"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict={}\n",
    "model_dict[\"model_1_768_adam_bert_t1\"]= BalanceNet(INPUT_SHAPE,\n",
    "                                                    EM_L_F_UNITS,\n",
    "                                                    EM_L_T_UNITS,\n",
    "                                                    LSTM_1F_UNITS,\n",
    "                                                    LSTM_1T_UNITS,\n",
    "                                                    CONV_2_FILTER,\n",
    "                                                    CONV_2_KERNEL,\n",
    "                                                    CONV_3_FILTER,\n",
    "                                                    CONV_3_KERNEL,\n",
    "                                                    CONV_5_FILTER,\n",
    "                                                    CONV_5_KERNEL,\n",
    "                                                    CONV_6_FILTER,\n",
    "                                                    CONV_6_KERNEL,\n",
    "                                                    CONV_8_FILTER,\n",
    "                                                    CONV_8_KERNEL,\n",
    "                                                    CONV_4F_FILTERS,\n",
    "                                                    CONV_4F_KERNEL,\n",
    "                                                    CONV_4T_FILTERS,\n",
    "                                                    CONV_4T_KERNEL,\n",
    "                                                    CONV_3F_FILTERS,\n",
    "                                                    CONV_3F_KERNEL,\n",
    "                                                    CONV_3T_FILTERS,\n",
    "                                                    CONV_3T_KERNEL,\n",
    "                                                    CONV_2F_FILTERS,\n",
    "                                                    CONV_2F_KERNEL,\n",
    "                                                    CONV_2T_FILTERS,\n",
    "                                                    CONV_2T_KERNEL,\n",
    "                                                    LSTM_2_C_L_UNITS,\n",
    "                                                    OUTPUT_DENSE_UNIT,\n",
    "                                                    OUTPUT_SIZE,\n",
    "                                                    optimizer_name= 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[\"model_1_768_adam_bert_t1\"].fitModel(train_x =dataset_X[\"bert_t1\"][0], \n",
    "                                                train_y=dataset_Y['bert'][0], \n",
    "                                                val_x= dataset_X[\"bert_t1\"][1], \n",
    "                                                val_y = dataset_Y['bert'][1], \n",
    "                                                model_type = \"bert_t1_adam\", \n",
    "                                                epochs_count = 20 , \n",
    "                                                batch_count = 64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('LatestTensor': conda)",
   "display_name": "Python 3.7.9 64-bit ('LatestTensor': conda)",
   "metadata": {
    "interpreter": {
     "hash": "0a81886b5eca8297b0be132dcbdde71b7b9ccd4a2b9beb608173c0b9df0b440d"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}