{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prettytable\n",
    "import tensorflow as tf\n",
    "from keras import callbacks, initializers, optimizers, regularizers\n",
    "from keras.layers import (LSTM, Bidirectional, Concatenate, Conv1D, Dense,\n",
    "                          Dropout, Flatten, Input, MaxPooling1D,\n",
    "                          TimeDistributed)\n",
    "from keras.models import Model, Sequential\n",
    "from sklearn.metrics import (accuracy_score, f1_score, hamming_loss,\n",
    "                             precision_recall_curve, precision_score,\n",
    "                             recall_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.test.gpu_device_name(): \n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))\n",
    "else:\n",
    "    print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Tensorboard Extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MultiChannelBiLSTMCNN import BalanceNet, time_logger_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics Calculator Function\n",
    "def evaluate_model(real, predicted):\n",
    "    accuracy = accuracy_score(real, predicted)\n",
    "    hamLoss = hamming_loss(real, predicted)\n",
    "    # element wise correctness\n",
    "    term_wise_accuracy = np.sum(np.logical_not(\n",
    "        np.logical_xor(real, predicted)))/real.size\n",
    "\n",
    "    macro_precision = precision_score(real, predicted, average='macro')\n",
    "    macro_recall = recall_score(real, predicted, average='macro')\n",
    "    macro_f1 = f1_score(real, predicted, average='macro')\n",
    "\n",
    "    micro_precision = precision_score(real, predicted, average='micro')\n",
    "    micro_recall = recall_score(real, predicted, average='micro')\n",
    "    micro_f1 = f1_score(real, predicted, average='micro')\n",
    "\n",
    "    metricTable = prettytable.PrettyTable()\n",
    "    metricTable.field_names = [\"Metric\", \"Macro Value\", \"Micro Value\"]\n",
    "    metricTable.add_row([\"Hamming Loss\", \"{0:.3f}\".format(hamLoss), \"\"])\n",
    "    metricTable.add_row(\n",
    "        [\"Term Wise Accuracy\", \"{0:.3f}\".format(term_wise_accuracy), \"\"])\n",
    "\n",
    "    metricTable.add_row([\"Accuracy\", \"{0:.3f}\".format(accuracy), \"\"])\n",
    "    metricTable.add_row([\"Precision\", \"{0:.3f}\".format(\n",
    "        macro_precision), \"{0:.3f}\".format(micro_precision)])\n",
    "    metricTable.add_row([\"Recall\", \"{0:.3f}\".format(\n",
    "        macro_recall), \"{0:.3f}\".format(micro_recall)])\n",
    "    metricTable.add_row(\n",
    "        [\"F1-measure\", \"{0:.3f}\".format(macro_f1), \"{0:.3f}\".format(micro_f1)])\n",
    "\n",
    "    print(metricTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "  \n",
    "def initial_boost(epoch):\n",
    "    if epoch==0: return float(8.0)\n",
    "    elif epoch==1: return float(4.0)\n",
    "    elif epoch==2: return float(2.0)\n",
    "    elif epoch==3: return float(1.5)\n",
    "    else: return float(1.0)\n",
    "\n",
    "def step_cyclic(epoch):\n",
    "    try:\n",
    "        l_r, decay = 1.0, 0.0001\n",
    "        if epoch%33==0:multiplier = 10\n",
    "        else:multiplier = 1\n",
    "        rate = float(multiplier * l_r * 1/(1 + decay * epoch))\n",
    "        #print(\"Epoch\",epoch+1,\"- learning_rate\",rate)\n",
    "        return rate\n",
    "    except Exception as e:\n",
    "        print(\"Error in lr_schedule:\",str(e))\n",
    "        return float(1.0)\n"
   ]
  },
  {
   "source": [
    "Loading Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpstDF= pd.read_csv(\"mpst.csv\")\n",
    "mpstDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Split Function\n",
    "def get_partition_Embeddings(x_t1,x_t2,y,df,partition_nm):\n",
    "    _df=df[df[\"split\"]==partition_nm]\n",
    "    index_list=list(_df.index)\n",
    "    temp_array_x_t1=[]\n",
    "    temp_array_x_t2=[]\n",
    "    temp_array_y=[]\n",
    "    for index in index_list:\n",
    "        temp_array_x_t1.append(x_t1[index,:])\n",
    "        temp_array_x_t2.append(x_t2[index,:])\n",
    "        temp_array_y.append(y[index,:])\n",
    "    temp_array_x_t1=np.array(temp_array_x_t1)\n",
    "    temp_array_x_t2=np.array(temp_array_x_t2)\n",
    "    temp_array_y=np.array(temp_array_y)\n",
    "    return temp_array_x_t1,temp_array_x_t2, temp_array_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING BERT  EMBEDDINGS\n",
    "bert_embedding=np.load(r\"D:\\CodeRepo\\Thesis\\Thesis\\XLNet\\xl_embeddings.npz\")\n",
    "# LOADING XLnet EMBEDDINGS\n",
    "xl_embedding=np.load(r\"D:\\CodeRepo\\Thesis\\Thesis\\XLNet\\xl_embeddings.npz\")\n",
    "# LOADING LABELS Y\n",
    "label_values=np.load(r\"D:\\CodeRepo\\Thesis\\Thesis\\EDA\\Y.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT EMBEDDINGS T1 & T2\n",
    "type1_BERT_Embeddings=bert_embedding[\"t1\"]\n",
    "type2_BERT_Embeddings=bert_embedding[\"t2\"]\n",
    "# XLNet EMBEDDINGS T1 & T2\n",
    "type1_XL_Embeddings=xl_embedding[\"t1\"]\n",
    "type2_XL_Embeddings=xl_embedding[\"t2\"]\n",
    "# LABLES Y\n",
    "label_values=label_values[\"arr_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT\n",
    "\n",
    "# FOR TRAIN\n",
    "type1_BERT_Embeddings_Train,type2_BERT_Embeddings_Train,BERT_label_values_Train=get_partition_Embeddings(type1_BERT_Embeddings,type2_BERT_Embeddings,label_values,mpstDF,\"train\")\n",
    "# FOR VALIDATION\n",
    "type1_BERT_Embeddings_Val,type2_BERT_Embeddings_Val,BERT_label_values_Val=get_partition_Embeddings(type1_BERT_Embeddings,type2_BERT_Embeddings,label_values,mpstDF,\"val\")\n",
    "# FOR TEST\n",
    "type1_BERT_Embeddings_Test,type2_BERT_Embeddings_Test,BERT_label_values_Test=get_partition_Embeddings(type1_BERT_Embeddings,type2_BERT_Embeddings,label_values,mpstDF,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XLNET\n",
    "\n",
    "# FOR TRAIN\n",
    "type1_XL_Embeddings_Train,type2_XL_Embeddings_Train,XLNET_label_values_Train=get_partition_Embeddings(type1_XL_Embeddings,type2_XL_Embeddings,label_values,mpstDF,\"train\")\n",
    "# FOR VALIDATION\n",
    "type1_XL_Embeddings_Val,type2_XL_Embeddings_Val,XLNET_label_values_Val=get_partition_Embeddings(type1_XL_Embeddings,type2_XL_Embeddings,label_values,mpstDF,\"val\")\n",
    "# FOR TEST\n",
    "type1_XL_Embeddings_Test,type2_XL_Embeddings_Test,XLNET_label_values_Test=get_partition_Embeddings(type1_XL_Embeddings,type2_XL_Embeddings,label_values,mpstDF,\"test\")"
   ]
  },
  {
   "source": [
    "HAVING A LOOK AT THE SHAPES OF EACH PARTITION CREATED:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SHAPES OF EACH PARTITION _ BERT\\n\")\n",
    "print(\"type1_BERT_Embeddings_Train.shape: \", type1_BERT_Embeddings_Train.shape)\n",
    "print(\"type2_BERT_Embeddings_Train.shape: \", type2_BERT_Embeddings_Train.shape)\n",
    "print(\"BERT_label_values_Train.shape: \"    , BERT_label_values_Train.shape)\n",
    "\n",
    "print(\"type1_BERT_Embeddings_Val.shape: \", type1_BERT_Embeddings_Val.shape)\n",
    "print(\"type2_BERT_Embeddings_Val.shape: \", type2_BERT_Embeddings_Val.shape)\n",
    "print(\"BERT_label_values_Val.shape: \"    , BERT_label_values_Val.shape)\n",
    "\n",
    "print(\"type1_BERT_Embeddings_Test.shape: \", type1_BERT_Embeddings_Test.shape)\n",
    "print(\"type2_BERT_Embeddings_Test.shape: \", type2_BERT_Embeddings_Test.shape)\n",
    "print(\"BERT_label_values_Test.shape: \"    , BERT_label_values_Test.shape)\n",
    "\n",
    "print(\"SHAPES OF EACH PARTITION _ XLNET\\n\")\n",
    "\n",
    "print(\"type1_XL_Embeddings_Train.shape: \", type1_XL_Embeddings_Train.shape)\n",
    "print(\"type2_XL_Embeddings_Train.shape: \", type2_XL_Embeddings_Train.shape)\n",
    "print(\"XLNET_label_values_Train.shape: \" , XLNET_label_values_Train.shape)\n",
    "\n",
    "print(\"type1_XL_Embeddings_Val.shape: \", type1_XL_Embeddings_Val.shape)\n",
    "print(\"type2_XL_Embeddings_Val.shape: \", type2_XL_Embeddings_Val.shape)\n",
    "print(\"XLNET_label_values_Val.shape: \" , XLNET_label_values_Val.shape)\n",
    "\n",
    "print(\"type1_XL_Embeddings_Test.shape: \", type1_XL_Embeddings_Test.shape)\n",
    "print(\"type2_XL_Embeddings_Test.shape: \", type2_XL_Embeddings_Test.shape)\n",
    "print(\"XLNET_label_values_Test.shape: \" , XLNET_label_values_Test.shape)\n",
    "\n",
    "print(\"SHAPES OF EACH PARTITION _ BERT\\n\")\n",
    "print(\"type1_BERT_Embeddings_Train.: \", type1_BERT_Embeddings_Train)\n",
    "print(\"type2_BERT_Embeddings_Train.: \", type2_BERT_Embeddings_Train)\n",
    "print(\"BERT_label_values_Train.: \"    , BERT_label_values_Train)\n",
    "\n",
    "print(\"type1_BERT_Embeddings_Val.: \", type1_BERT_Embeddings_Val)\n",
    "print(\"type2_BERT_Embeddings_Val.: \", type2_BERT_Embeddings_Val)\n",
    "print(\"BERT_label_values_Val.: \"    , BERT_label_values_Val)\n",
    "\n",
    "print(\"type1_BERT_Embeddings_Test.shape: \", type1_BERT_Embeddings_Test)\n",
    "print(\"type2_BERT_Embeddings_Test.shape: \", type2_BERT_Embeddings_Test)\n",
    "print(\"BERT_label_values_Test.shape: \"    , BERT_label_values_Test)\n",
    "\n",
    "print(\"SHAPES OF EACH PARTITION _ XLNET\\n\")\n",
    "\n",
    "print(\"type1_XL_Embeddings_Train: \", type1_XL_Embeddings_Train)\n",
    "print(\"type2_XL_Embeddings_Train: \", type2_XL_Embeddings_Train)\n",
    "print(\"XLNET_label_values_Train: \" , XLNET_label_values_Train)\n",
    "\n",
    "print(\"type1_XL_Embeddings_Val: \", type1_XL_Embeddings_Val)\n",
    "print(\"type2_XL_Embeddings_Val: \", type2_XL_Embeddings_Val)\n",
    "print(\"XLNET_label_values_Val: \" , XLNET_label_values_Val)\n",
    "\n",
    "print(\"type1_XL_Embeddings_Test: \", type1_XL_Embeddings_Test)\n",
    "print(\"type2_XL_Embeddings_Test: \", type2_XL_Embeddings_Test)\n",
    "print(\"XLNET_label_values_Test: \" , XLNET_label_values_Test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reshape my input\n",
    "def tensor_reshape(input, timestep, features):\n",
    "  reshaped= input.reshape(type1_BERT_Embeddings_Train.shape[0], timestep, features)\n",
    "  return reshaped"
   ]
  },
  {
   "source": [
    "STARTING THE MODEL\n",
    "possible combination in inputs:\n",
    "(timestep, features)\n",
    "- (1, 768)\n",
    "- (2, 384)\n",
    "- (3, 256)\n",
    "- (4, 192)\n",
    "- (6, 128)\n",
    "- (12, 64)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## MODEL (4, 192):\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE =(4, 192)\n",
    "EM_L_F_UNITS= 192\n",
    "EM_L_T_UNITS= 192\n",
    "# LEFT CHANNEL\n",
    "LSTM_1F_UNITS= 128\n",
    "LSTM_1T_UNITS= 128\n",
    "\n",
    "CONV_2_FILTER= 24\n",
    "CONV_2_KERNEL= 2\n",
    "CONV_3_FILTER= 24\n",
    "CONV_3_KERNEL= 2\n",
    "CONV_5_FILTER= 24\n",
    "CONV_5_KERNEL= 2\n",
    "CONV_6_FILTER= 24\n",
    "CONV_6_KERNEL= 2\n",
    "CONV_8_FILTER= 24\n",
    "CONV_8_KERNEL= 2\n",
    "\n",
    "# RIGHT CHANNEL \n",
    "CONV_4F_FILTERS = 12\n",
    "CONV_4F_KERNEL = 1\n",
    "CONV_4T_FILTERS = 12\n",
    "CONV_4T_KERNEL = 1\n",
    "\n",
    "CONV_3F_FILTERS = 12\n",
    "CONV_3F_KERNEL = 1\n",
    "CONV_3T_FILTERS = 12\n",
    "CONV_3T_KERNEL = 1\n",
    "\n",
    "CONV_2F_FILTERS = 12\n",
    "CONV_2F_KERNEL = 1\n",
    "CONV_2T_FILTERS = 12\n",
    "CONV_2T_KERNEL = 1\n",
    "\n",
    "LSTM_2_C_L_UNITS = 12\n",
    "\n",
    "OUTPUT_DENSE_UNIT =128\n",
    "OUTPUT_SIZE =71\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_list = ['adam']\n",
    "\n",
    "dataset_X={\n",
    "    \"bert_t1\":[\n",
    "        type1_BERT_Embeddings_Train,\n",
    "        type1_BERT_Embeddings_Val,\n",
    "        type1_BERT_Embeddings_Test\n",
    "        ],\n",
    "    \"bert_t2\":[\n",
    "        type2_BERT_Embeddings_Train,\n",
    "        type2_BERT_Embeddings_Val,\n",
    "        type2_BERT_Embeddings_Test\n",
    "        ],\n",
    "    \"xlnet_t1\":[\n",
    "        type1_XL_Embeddings_Train,\n",
    "        type1_XL_Embeddings_Val,\n",
    "        type1_XL_Embeddings_Test\n",
    "        ],\n",
    "    \"xlnet_t2\":[\n",
    "        type2_XL_Embeddings_Train,\n",
    "        type2_XL_Embeddings_Val,\n",
    "        type2_XL_Embeddings_Test\n",
    "    ]\n",
    "}\n",
    "dataset_Y ={\n",
    "    \"bert\":[\n",
    "        BERT_label_values_Train,\n",
    "        BERT_label_values_Val,\n",
    "        BERT_label_values_Test\n",
    "        ],\n",
    "    \"xlnet\":[\n",
    "        XLNET_label_values_Train,\n",
    "        XLNET_label_values_Val,\n",
    "        XLNET_label_values_Test\n",
    "        ]\n",
    "}\n",
    "\n",
    "inp_shape_str = \"4_192\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict ={}\n",
    "t_list =[x/10 for x in range(1,10)]\n",
    "time_dict=[]\n",
    "\n",
    "for ds in dataset_X.keys():\n",
    "    for opt in optimizer_list:\n",
    "        print(\"\\nFOR OPTIMIZER: \",opt)\n",
    "        key= \"model_\"+inp_shape_str+\"_\"+opt+\"_\"+ds\n",
    "        model_type = ds+\"_\"+opt\n",
    "        print(\"\\n###############\\nKEY= \"+key+\"\\n#############\")\n",
    "        print(\"\\n###############\\nmodel_type= \"+model_type+\"\\n#############\")\n",
    "        model_dict[key] = BalanceNet(INPUT_SHAPE,\n",
    "                                    EM_L_F_UNITS,\n",
    "                                    EM_L_T_UNITS,\n",
    "                                    LSTM_1F_UNITS,\n",
    "                                    LSTM_1T_UNITS,\n",
    "                                    CONV_2_FILTER,\n",
    "                                    CONV_2_KERNEL,\n",
    "                                    CONV_3_FILTER,\n",
    "                                    CONV_3_KERNEL,\n",
    "                                    CONV_5_FILTER,\n",
    "                                    CONV_5_KERNEL,\n",
    "                                    CONV_6_FILTER,\n",
    "                                    CONV_6_KERNEL,\n",
    "                                    CONV_8_FILTER,\n",
    "                                    CONV_8_KERNEL,\n",
    "                                    CONV_4F_FILTERS,\n",
    "                                    CONV_4F_KERNEL,\n",
    "                                    CONV_4T_FILTERS,\n",
    "                                    CONV_4T_KERNEL,\n",
    "                                    CONV_3F_FILTERS,\n",
    "                                    CONV_3F_KERNEL,\n",
    "                                    CONV_3T_FILTERS,\n",
    "                                    CONV_3T_KERNEL,\n",
    "                                    CONV_2F_FILTERS,\n",
    "                                    CONV_2F_KERNEL,\n",
    "                                    CONV_2T_FILTERS,\n",
    "                                    CONV_2T_KERNEL,\n",
    "                                    LSTM_2_C_L_UNITS,\n",
    "                                    OUTPUT_DENSE_UNIT,\n",
    "                                    OUTPUT_SIZE,\n",
    "                                    optimizer_name= opt)\n",
    "        if 'bert' in ds:\n",
    "            em_type='bert'\n",
    "        if 'xlnet' in ds:\n",
    "            em_type='xlnet'\n",
    "        model_dict[key].fitModel(train_x =dataset_X[ds][0], \n",
    "                                            train_y=dataset_Y[em_type][0], \n",
    "                                            val_x= dataset_X[ds][1], \n",
    "                                            val_y = dataset_Y[em_type][1], \n",
    "                                            model_type = model_type, \n",
    "                                            epochs_count = 20 , \n",
    "                                            batch_count = 64,  time_dict=time_dict, key=key)\n",
    "        model_dict[key].predictModel(test_x=dataset_X[ds][2], test_y=dataset_Y[em_type][2], threshold_list=t_list,  time_dict=time_dict, key=key)\n",
    "time_logger_save(time_dict,inp_shape_str+\"_time\")\n"
   ]
  },
  {
   "source": [
    "# END"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict={}\n",
    "model_dict[\"model_1_768_adam_bert_t1\"]= BalanceNet(INPUT_SHAPE,\n",
    "                                                    EM_L_F_UNITS,\n",
    "                                                    EM_L_T_UNITS,\n",
    "                                                    LSTM_1F_UNITS,\n",
    "                                                    LSTM_1T_UNITS,\n",
    "                                                    CONV_2_FILTER,\n",
    "                                                    CONV_2_KERNEL,\n",
    "                                                    CONV_3_FILTER,\n",
    "                                                    CONV_3_KERNEL,\n",
    "                                                    CONV_5_FILTER,\n",
    "                                                    CONV_5_KERNEL,\n",
    "                                                    CONV_6_FILTER,\n",
    "                                                    CONV_6_KERNEL,\n",
    "                                                    CONV_8_FILTER,\n",
    "                                                    CONV_8_KERNEL,\n",
    "                                                    CONV_4F_FILTERS,\n",
    "                                                    CONV_4F_KERNEL,\n",
    "                                                    CONV_4T_FILTERS,\n",
    "                                                    CONV_4T_KERNEL,\n",
    "                                                    CONV_3F_FILTERS,\n",
    "                                                    CONV_3F_KERNEL,\n",
    "                                                    CONV_3T_FILTERS,\n",
    "                                                    CONV_3T_KERNEL,\n",
    "                                                    CONV_2F_FILTERS,\n",
    "                                                    CONV_2F_KERNEL,\n",
    "                                                    CONV_2T_FILTERS,\n",
    "                                                    CONV_2T_KERNEL,\n",
    "                                                    LSTM_2_C_L_UNITS,\n",
    "                                                    OUTPUT_DENSE_UNIT,\n",
    "                                                    OUTPUT_SIZE,\n",
    "                                                    optimizer_name= 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[\"model_1_768_adam_bert_t1\"].fitModel(train_x =dataset_X[\"bert_t1\"][0], \n",
    "                                                train_y=dataset_Y['bert'][0], \n",
    "                                                val_x= dataset_X[\"bert_t1\"][1], \n",
    "                                                val_y = dataset_Y['bert'][1], \n",
    "                                                model_type = \"bert_t1_adam\", \n",
    "                                                epochs_count = 20 , \n",
    "                                                batch_count = 64)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.7.9 64-bit ('LatestTensor': conda)",
   "display_name": "Python 3.7.9 64-bit ('LatestTensor': conda)",
   "metadata": {
    "interpreter": {
     "hash": "0a81886b5eca8297b0be132dcbdde71b7b9ccd4a2b9beb608173c0b9df0b440d"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}