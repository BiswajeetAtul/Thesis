{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import  Input, LSTM, Bidirectional, Concatenate, Conv1D, Dropout, MaxPooling1D, Flatten, Dense, TimeDistributed\n",
    "import prettytable\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_recall_curve, precision_score, recall_score, f1_score, hamming_loss, accuracy_score\n",
    "from keras import regularizers, initializers, optimizers, callbacks\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Tensorboard Extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics Calculator Function\n",
    "def evaluate_model(real, predicted):\n",
    "    accuracy = accuracy_score(real, predicted)\n",
    "    hamLoss = hamming_loss(real, predicted)\n",
    "    # element wise correctness\n",
    "    term_wise_accuracy = np.sum(np.logical_not(\n",
    "        np.logical_xor(real, predicted)))/real.size\n",
    "\n",
    "    macro_precision = precision_score(real, predicted, average='macro')\n",
    "    macro_recall = recall_score(real, predicted, average='macro')\n",
    "    macro_f1 = f1_score(real, predicted, average='macro')\n",
    "\n",
    "    micro_precision = precision_score(real, predicted, average='micro')\n",
    "    micro_recall = recall_score(real, predicted, average='micro')\n",
    "    micro_f1 = f1_score(real, predicted, average='micro')\n",
    "\n",
    "    metricTable = prettytable.PrettyTable()\n",
    "    metricTable.field_names = [\"Metric\", \"Macro Value\", \"Micro Value\"]\n",
    "    metricTable.add_row([\"Hamming Loss\", \"{0:.3f}\".format(hamLoss), \"\"])\n",
    "    metricTable.add_row(\n",
    "        [\"Term Wise Accuracy\", \"{0:.3f}\".format(term_wise_accuracy), \"\"])\n",
    "\n",
    "    metricTable.add_row([\"Accuracy\", \"{0:.3f}\".format(accuracy), \"\"])\n",
    "    metricTable.add_row([\"Precision\", \"{0:.3f}\".format(\n",
    "        macro_precision), \"{0:.3f}\".format(micro_precision)])\n",
    "    metricTable.add_row([\"Recall\", \"{0:.3f}\".format(\n",
    "        macro_recall), \"{0:.3f}\".format(micro_recall)])\n",
    "    metricTable.add_row(\n",
    "        [\"F1-measure\", \"{0:.3f}\".format(macro_f1), \"{0:.3f}\".format(micro_f1)])\n",
    "\n",
    "    print(metricTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "def get_lr_metric(optimizer):\n",
    "    def lr(y_true, y_pred):\n",
    "        return optimizer.lr\n",
    "    return lr\n",
    "  \n",
    "def initial_boost(epoch):\n",
    "    if epoch==0: return float(8.0)\n",
    "    elif epoch==1: return float(4.0)\n",
    "    elif epoch==2: return float(2.0)\n",
    "    elif epoch==3: return float(1.5)\n",
    "    else: return float(1.0)\n",
    "\n",
    "def step_cyclic(epoch):\n",
    "    try:\n",
    "        l_r, decay = 1.0, 0.0001\n",
    "        if epoch%33==0:multiplier = 10\n",
    "        else:multiplier = 1\n",
    "        rate = float(multiplier * l_r * 1/(1 + decay * epoch))\n",
    "        #print(\"Epoch\",epoch+1,\"- learning_rate\",rate)\n",
    "        return rate\n",
    "    except Exception as e:\n",
    "        print(\"Error in lr_schedule:\",str(e))\n",
    "        return float(1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "source": [
    "STARTING THE MODEL"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_layer= Input(shape=(768,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer_frozen=TimeDistributed(Dense(units=768, trainable= False))(inp_layer)\n",
    "embedding_layer_train= TimeDistributed(Dense(units=768, trainable= True))(inp_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_lstm_1f =Bidirectional(LSTM(24, return_sequences=True, dropout=0.3, recurrent_dropout=0.0))(embedding_layer_frozen)\n",
    "l_lstm_1t =Bidirectional(LSTM(24, return_sequences=True, dropout=0.3, recurrent_dropout=0.0))(embedding_layer_train)\n",
    "\n",
    "l_lstm1 = Concatenate(axis=1)([l_lstm_1f, l_lstm_1t])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_lstm1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_conv_2 = Conv1D(filters=24, kernel_size=2, activation='relu')(l_lstm1)\n",
    "l_conv_2 = Dropout(0.3)(l_conv_2)\n",
    "\n",
    "l_conv_3 = Conv1D(filters=24, kernel_size=3, activation='relu')(l_lstm1)\n",
    "l_conv_3 = Dropout(0.3)(l_conv_3)\n",
    "\n",
    "l_conv_5 = Conv1D(filters=24, kernel_size=5, activation='relu')(l_lstm1)\n",
    "l_conv_5 = Dropout(0.3)(l_conv_5)\n",
    "\n",
    "l_conv_6 = Conv1D(filters=24, kernel_size=6, kernel_regularizer=regularizers.l2(0.001) ,activation='relu')(l_lstm1)\n",
    "l_conv_6 = Dropout(0.3)(l_conv_6)\n",
    "\n",
    "l_conv_8 = Conv1D(filters=24, kernel_size=8, kernel_regularizer=regularizers.l2(0.001) ,activation='relu')(l_lstm1)\n",
    "l_conv_8 = Dropout(0.3)(l_conv_8)\n",
    "\n",
    "conv_1 =[l_conv_6, l_conv_5, l_conv_8, l_conv_2, l_conv_3 ]\n",
    "\n",
    "l_lstm_c = Concatenate(axis =1)(conv_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_lstm_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_conv_4f = Conv1D(filters= 12, kernel_size=4, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(embedding_layer_frozen)\n",
    "l_conv_4f = Dropout(0.3)(l_conv_4f)\n",
    "\n",
    "l_conv_4t = Conv1D(filters= 12, kernel_size=4, activation='relu', kernel_regularizer=regularizers.l2(0.0001))(embedding_layer_train)\n",
    "l_conv_4t = Dropout(0.3)(l_conv_4t)\n",
    "\n",
    "l_conv_3f = Conv1D(filters= 12, kernel_size=3, activation='relu')(embedding_layer_frozen)\n",
    "l_conv_3f = Dropout(0.3)(l_conv_3f)\n",
    "\n",
    "l_conv_3t = Conv1D(filters= 12, kernel_size=3, activation='relu')(embedding_layer_train)\n",
    "l_conv_3t = Dropout(0.3)(l_conv_3t)\n",
    "\n",
    "l_conv_2f = Conv1D(filters= 12, kernel_size=2, activation='relu')(embedding_layer_frozen)\n",
    "l_conv_2f = Dropout(0.3)(l_conv_2f)\n",
    "\n",
    "l_conv_2t = Conv1D(filters= 12, kernel_size=2, activation='relu')(embedding_layer_train)\n",
    "l_conv_2t = Dropout(0.3)(l_conv_2t)\n",
    "\n",
    "conv_2 = [l_conv_4f, l_conv_4t, l_conv_3f, l_conv_3t, l_conv_2f, l_conv_2t]\n",
    "\n",
    "l_merge_2 = Concatenate(axis=1)(conv_2)\n",
    "l_c_lstm = Bidirectional(LSTM(12, return_sequences=True, dropout=0.3, recurrent_dropout=0.0))(l_merge_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_merge_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_c_lstm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_merge = Concatenate(axis=1)([l_lstm_c, l_c_lstm])\n",
    "l_pool = MaxPooling1D(4)(l_merge)\n",
    "l_drop = Dropout(0.5)(l_pool)\n",
    "l_flat = Flatten()(l_drop)\n",
    "l_dense = Dense(26, activation='relu')(l_flat)\n",
    "preds= Dense(5, activation='softmax')(l_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Model(inp_layer,preds)\n",
    "ada_delta = optimizers.Adadelta(lr=0.9, rho= 0.95, epsilon= None, decay =0.002)\n",
    "\n",
    "lr_metric = get_lr_metric(ada_delta)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "source": [
    "**Tensorboard Callback** and checkpoint creation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "callback_tensorboard = callbacks.TensorBoard(log_dir='./logs', histogram_freq=1, batch_size=16, write_grads=True , write_graph=True)\n",
    "callback_model_checkpoints = callbacks.ModelCheckpoint(\"checkpoint-{val_loss:.3f}.h5\", monitor='val_loss', verbose=0, save_best_only=True, save_weights_only=False, mode='auto', period=0)\n",
    "callback_lr_schedule = callbacks.LearningRateScheduler(initial_boost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('BalanceNet.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Progress:\")\n",
    "model_log = model.fit(X_train, Y_train, validation_data=(X_test, Y_test),\n",
    "          epochs=50, batch_size=200)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}