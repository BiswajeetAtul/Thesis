The LSTM input layer must be 3D.
The meaning of the 3 input dimensions are: samples, time steps, and features.
The LSTM input layer is defined by the input_shape argument on the first hidden layer.
The input_shape argument takes a tuple of two values that define the number of time steps and features.
The number of samples is assumed to be 1 or more.
The reshape() function on NumPy arrays can be used to reshape your 1D or 2D data to be 3D.
The reshape() function takes a tuple as an argument that defines the new shape.


The input of the LSTM is always is a 3D array. (batch_size, time_steps, units)
The output of the LSTM could be a 2D array or 3D array depending upon the return_sequences argument.
If return_sequence is False, the output is a 2D array. (batch_size, units)
If return_sequence is True, the output is a 3D array. (batch_size, time_steps, units)
\

There are two key points to remember when using the TimeDistributed wrapper layer:


The input must be (at least) 3D. 
This often means that you will need to configure your last LSTM layer prior to your TimeDistributed wrapped Dense layer to return sequences 
(e.g. set the “return_sequences” argument to “True”).
The output will be 3D. This means that if your TimeDistributed wrapped Dense layer 
is your output layer and you are predicting a sequence, you will need to resize your y array into a 3D vector.


t's a bit too late but just in case;
A Sample may refer to individual training examples. A “batch_size” variable is hence the count of samples you sent to the neural network. That is, how many different examples you feed at once to the neural network.

TimeSteps are ticks of time. It is how long in time each of your samples is. For example, a sample can contain 128-time steps, where each time steps could be a 30th of a second for signal processing. In Natural Language Processing (NLP), a time step may be associated with a character, a word, or a sentence, depending on the setup.

Features are simply the number of dimensions we feed at each time steps. For example in NLP, a word could be represented by 300 features using word2vec. In the case of signal processing, let’s pretend that your signal is 3D. That is, you have an X, a Y and a Z signal, such as an accelerometer’s measurements on each axis. This means you would have 3 features sent at each time step for each sample.

2

My answer with an example: ["hello this is xyz","how are you doing","great man..."]

in this case "[samples, time steps, features]" means:

sample: 3 because there are 3 elements in the list
time steps: here you can take max_length = 4 length("hello this is xyz") = 4; length("how are you doing") = 4; length("great man...") = 2 (after removing punctuation "."). The reason of saying this is a time steps is, in first element "hello this is xyz" ==> t0("hello"), t1("this"), t2("is") and t3("xyz")
features: the size of embedding for each words. e.g, "hello": 50D array, "this": 50D array and so on


18

I found this just below the [samples, time_steps, features] you are concerned with.

X = numpy.reshape(dataX, (len(dataX), seq_length, 1))
Samples - This is the len(dataX), or the amount of data points you have.

Time steps - This is equivalent to the amount of time steps you run your recurrent neural network. If you want your network to have memory of 60 characters, this number should be 60.

Features - this is the amount of features in every time step. If you are processing pictures, this is the amount of pixels. In this case you seem to have 1 feature per time step.
https://stats.stackexchange.com/questions/264546/difference-between-samples-time-steps-and-features-in-neural-network